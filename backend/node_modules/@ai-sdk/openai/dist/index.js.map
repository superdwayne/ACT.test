{"version":3,"sources":["../src/index.ts","../src/openai-provider.ts","../src/chat/openai-chat-language-model.ts","../src/openai-error.ts","../src/chat/convert-to-openai-chat-messages.ts","../src/chat/get-response-metadata.ts","../src/chat/map-openai-finish-reason.ts","../src/chat/openai-chat-api.ts","../src/chat/openai-chat-options.ts","../src/chat/openai-chat-prepare-tools.ts","../src/completion/openai-completion-language-model.ts","../src/completion/convert-to-openai-completion-prompt.ts","../src/completion/get-response-metadata.ts","../src/completion/map-openai-finish-reason.ts","../src/completion/openai-completion-api.ts","../src/completion/openai-completion-options.ts","../src/embedding/openai-embedding-model.ts","../src/embedding/openai-embedding-options.ts","../src/embedding/openai-embedding-api.ts","../src/image/openai-image-model.ts","../src/image/openai-image-api.ts","../src/image/openai-image-options.ts","../src/tool/code-interpreter.ts","../src/tool/file-search.ts","../src/tool/image-generation.ts","../src/tool/local-shell.ts","../src/tool/web-search.ts","../src/tool/web-search-preview.ts","../src/openai-tools.ts","../src/responses/openai-responses-language-model.ts","../src/responses/convert-to-openai-responses-input.ts","../src/responses/map-openai-responses-finish-reason.ts","../src/responses/openai-responses-api.ts","../src/responses/openai-responses-options.ts","../src/responses/openai-responses-prepare-tools.ts","../src/speech/openai-speech-model.ts","../src/speech/openai-speech-options.ts","../src/transcription/openai-transcription-model.ts","../src/transcription/openai-transcription-api.ts","../src/transcription/openai-transcription-options.ts","../src/version.ts"],"sourcesContent":["export { createOpenAI, openai } from './openai-provider';\nexport type { OpenAIProvider, OpenAIProviderSettings } from './openai-provider';\nexport type { OpenAIResponsesProviderOptions } from './responses/openai-responses-options';\nexport type { OpenAIChatLanguageModelOptions } from './chat/openai-chat-options';\nexport { VERSION } from './version';\n","import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  ProviderV2,\n  SpeechModelV2,\n  TranscriptionModelV2,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  loadOptionalSetting,\n  withoutTrailingSlash,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIChatLanguageModel } from './chat/openai-chat-language-model';\nimport { OpenAIChatModelId } from './chat/openai-chat-options';\nimport { OpenAICompletionLanguageModel } from './completion/openai-completion-language-model';\nimport { OpenAICompletionModelId } from './completion/openai-completion-options';\nimport { OpenAIEmbeddingModel } from './embedding/openai-embedding-model';\nimport { OpenAIEmbeddingModelId } from './embedding/openai-embedding-options';\nimport { OpenAIImageModel } from './image/openai-image-model';\nimport { OpenAIImageModelId } from './image/openai-image-options';\nimport { openaiTools } from './openai-tools';\nimport { OpenAIResponsesLanguageModel } from './responses/openai-responses-language-model';\nimport { OpenAIResponsesModelId } from './responses/openai-responses-options';\nimport { OpenAISpeechModel } from './speech/openai-speech-model';\nimport { OpenAISpeechModelId } from './speech/openai-speech-options';\nimport { OpenAITranscriptionModel } from './transcription/openai-transcription-model';\nimport { OpenAITranscriptionModelId } from './transcription/openai-transcription-options';\nimport { VERSION } from './version';\n\nexport interface OpenAIProvider extends ProviderV2 {\n  (modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI model for text generation.\n   */\n  languageModel(modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI chat model for text generation.\n   */\n  chat(modelId: OpenAIChatModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI responses API model for text generation.\n   */\n  responses(modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI completion model for text generation.\n   */\n  completion(modelId: OpenAICompletionModelId): LanguageModelV2;\n\n  /**\nCreates a model for text embeddings.\n   */\n  embedding(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbedding(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbeddingModel(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for image generation.\n   */\n  image(modelId: OpenAIImageModelId): ImageModelV2;\n\n  /**\nCreates a model for image generation.\n   */\n  imageModel(modelId: OpenAIImageModelId): ImageModelV2;\n\n  /**\nCreates a model for transcription.\n   */\n  transcription(modelId: OpenAITranscriptionModelId): TranscriptionModelV2;\n\n  /**\nCreates a model for speech generation.\n   */\n  speech(modelId: OpenAISpeechModelId): SpeechModelV2;\n\n  /**\nOpenAI-specific tools.\n   */\n  tools: typeof openaiTools;\n}\n\nexport interface OpenAIProviderSettings {\n  /**\nBase URL for the OpenAI API calls.\n     */\n  baseURL?: string;\n\n  /**\nAPI key for authenticating requests.\n     */\n  apiKey?: string;\n\n  /**\nOpenAI Organization.\n     */\n  organization?: string;\n\n  /**\nOpenAI project.\n     */\n  project?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nProvider name. Overrides the `openai` default name for 3rd party providers.\n   */\n  name?: string;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n}\n\n/**\nCreate an OpenAI provider instance.\n */\nexport function createOpenAI(\n  options: OpenAIProviderSettings = {},\n): OpenAIProvider {\n  const baseURL =\n    withoutTrailingSlash(\n      loadOptionalSetting({\n        settingValue: options.baseURL,\n        environmentVariableName: 'OPENAI_BASE_URL',\n      }),\n    ) ?? 'https://api.openai.com/v1';\n\n  const providerName = options.name ?? 'openai';\n\n  const getHeaders = () =>\n    withUserAgentSuffix(\n      {\n        Authorization: `Bearer ${loadApiKey({\n          apiKey: options.apiKey,\n          environmentVariableName: 'OPENAI_API_KEY',\n          description: 'OpenAI',\n        })}`,\n        'OpenAI-Organization': options.organization,\n        'OpenAI-Project': options.project,\n        ...options.headers,\n      },\n      `ai-sdk/openai/${VERSION}`,\n    );\n\n  const createChatModel = (modelId: OpenAIChatModelId) =>\n    new OpenAIChatLanguageModel(modelId, {\n      provider: `${providerName}.chat`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createCompletionModel = (modelId: OpenAICompletionModelId) =>\n    new OpenAICompletionLanguageModel(modelId, {\n      provider: `${providerName}.completion`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (modelId: OpenAIEmbeddingModelId) =>\n    new OpenAIEmbeddingModel(modelId, {\n      provider: `${providerName}.embedding`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createImageModel = (modelId: OpenAIImageModelId) =>\n    new OpenAIImageModel(modelId, {\n      provider: `${providerName}.image`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createTranscriptionModel = (modelId: OpenAITranscriptionModelId) =>\n    new OpenAITranscriptionModel(modelId, {\n      provider: `${providerName}.transcription`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createSpeechModel = (modelId: OpenAISpeechModelId) =>\n    new OpenAISpeechModel(modelId, {\n      provider: `${providerName}.speech`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createLanguageModel = (modelId: OpenAIResponsesModelId) => {\n    if (new.target) {\n      throw new Error(\n        'The OpenAI model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createResponsesModel(modelId);\n  };\n\n  const createResponsesModel = (modelId: OpenAIResponsesModelId) => {\n    return new OpenAIResponsesLanguageModel(modelId, {\n      provider: `${providerName}.responses`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n      fileIdPrefixes: ['file-'],\n    });\n  };\n\n  const provider = function (modelId: OpenAIResponsesModelId) {\n    return createLanguageModel(modelId);\n  };\n\n  provider.languageModel = createLanguageModel;\n  provider.chat = createChatModel;\n  provider.completion = createCompletionModel;\n  provider.responses = createResponsesModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n\n  provider.transcription = createTranscriptionModel;\n  provider.transcriptionModel = createTranscriptionModel;\n\n  provider.speech = createSpeechModel;\n  provider.speechModel = createSpeechModel;\n\n  provider.tools = openaiTools;\n\n  return provider as OpenAIProvider;\n}\n\n/**\nDefault OpenAI provider instance.\n */\nexport const openai = createOpenAI();\n","import {\n  InvalidResponseDataError,\n  LanguageModelV2,\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  isParsableJson,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { convertToOpenAIChatMessages } from './convert-to-openai-chat-messages';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAIChatChunk,\n  openaiChatChunkSchema,\n  openaiChatResponseSchema,\n} from './openai-chat-api';\nimport {\n  OpenAIChatModelId,\n  openaiChatLanguageModelOptions,\n} from './openai-chat-options';\nimport { prepareChatTools } from './openai-chat-prepare-tools';\n\ntype OpenAIChatConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAIChatLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAIChatModelId;\n\n  readonly supportedUrls = {\n    'image/*': [/^https?:\\/\\/.*$/],\n  };\n\n  private readonly config: OpenAIChatConfig;\n\n  constructor(modelId: OpenAIChatModelId, config: OpenAIChatConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    tools,\n    toolChoice,\n    providerOptions,\n  }: LanguageModelV2CallOptions) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiChatLanguageModelOptions,\n      })) ?? {};\n\n    const structuredOutputs = openaiOptions.structuredOutputs ?? true;\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (\n      responseFormat?.type === 'json' &&\n      responseFormat.schema != null &&\n      !structuredOutputs\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details:\n          'JSON response format schema is only supported with structuredOutputs',\n      });\n    }\n\n    const { messages, warnings: messageWarnings } = convertToOpenAIChatMessages(\n      {\n        prompt,\n        systemMessageMode: getSystemMessageMode(this.modelId),\n      },\n    );\n\n    warnings.push(...messageWarnings);\n\n    const strictJsonSchema = openaiOptions.strictJsonSchema ?? false;\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      logit_bias: openaiOptions.logitBias,\n      logprobs:\n        openaiOptions.logprobs === true ||\n        typeof openaiOptions.logprobs === 'number'\n          ? true\n          : undefined,\n      top_logprobs:\n        typeof openaiOptions.logprobs === 'number'\n          ? openaiOptions.logprobs\n          : typeof openaiOptions.logprobs === 'boolean'\n            ? openaiOptions.logprobs\n              ? 0\n              : undefined\n            : undefined,\n      user: openaiOptions.user,\n      parallel_tool_calls: openaiOptions.parallelToolCalls,\n\n      // standardized settings:\n      max_tokens: maxOutputTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format:\n        responseFormat?.type === 'json'\n          ? structuredOutputs && responseFormat.schema != null\n            ? {\n                type: 'json_schema',\n                json_schema: {\n                  schema: responseFormat.schema,\n                  strict: strictJsonSchema,\n                  name: responseFormat.name ?? 'response',\n                  description: responseFormat.description,\n                },\n              }\n            : { type: 'json_object' }\n          : undefined,\n      stop: stopSequences,\n      seed,\n      verbosity: openaiOptions.textVerbosity,\n\n      // openai specific settings:\n      // TODO AI SDK 6: remove, we auto-map maxOutputTokens now\n      max_completion_tokens: openaiOptions.maxCompletionTokens,\n      store: openaiOptions.store,\n      metadata: openaiOptions.metadata,\n      prediction: openaiOptions.prediction,\n      reasoning_effort: openaiOptions.reasoningEffort,\n      service_tier: openaiOptions.serviceTier,\n      prompt_cache_key: openaiOptions.promptCacheKey,\n      safety_identifier: openaiOptions.safetyIdentifier,\n\n      // messages:\n      messages,\n    };\n\n    if (isReasoningModel(this.modelId)) {\n      // remove unsupported settings for reasoning models\n      // see https://platform.openai.com/docs/guides/reasoning#limitations\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details: 'temperature is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'topP',\n          details: 'topP is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.frequency_penalty != null) {\n        baseArgs.frequency_penalty = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'frequencyPenalty',\n          details: 'frequencyPenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.presence_penalty != null) {\n        baseArgs.presence_penalty = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'presencePenalty',\n          details: 'presencePenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logit_bias != null) {\n        baseArgs.logit_bias = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logitBias is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logprobs != null) {\n        baseArgs.logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logprobs is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.top_logprobs != null) {\n        baseArgs.top_logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'topLogprobs is not supported for reasoning models',\n        });\n      }\n\n      // reasoning models use max_completion_tokens instead of max_tokens:\n      if (baseArgs.max_tokens != null) {\n        if (baseArgs.max_completion_tokens == null) {\n          baseArgs.max_completion_tokens = baseArgs.max_tokens;\n        }\n        baseArgs.max_tokens = undefined;\n      }\n    } else if (\n      this.modelId.startsWith('gpt-4o-search-preview') ||\n      this.modelId.startsWith('gpt-4o-mini-search-preview')\n    ) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details:\n            'temperature is not supported for the search preview models and has been removed.',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions.serviceTier === 'flex' &&\n      !supportsFlexProcessing(this.modelId)\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions.serviceTier === 'priority' &&\n      !supportsPriorityProcessing(this.modelId)\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = prepareChatTools({\n      tools,\n      toolChoice,\n      structuredOutputs,\n      strictJsonSchema,\n    });\n\n    return {\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args: body, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n    const content: Array<LanguageModelV2Content> = [];\n\n    // text content:\n    const text = choice.message.content;\n    if (text != null && text.length > 0) {\n      content.push({ type: 'text', text });\n    }\n\n    // tool calls:\n    for (const toolCall of choice.message.tool_calls ?? []) {\n      content.push({\n        type: 'tool-call' as const,\n        toolCallId: toolCall.id ?? generateId(),\n        toolName: toolCall.function.name,\n        input: toolCall.function.arguments!,\n      });\n    }\n\n    // annotations/citations:\n    for (const annotation of choice.message.annotations ?? []) {\n      content.push({\n        type: 'source',\n        sourceType: 'url',\n        id: generateId(),\n        url: annotation.url,\n        title: annotation.title,\n      });\n    }\n\n    // provider metadata:\n    const completionTokenDetails = response.usage?.completion_tokens_details;\n    const promptTokenDetails = response.usage?.prompt_tokens_details;\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n    if (completionTokenDetails?.accepted_prediction_tokens != null) {\n      providerMetadata.openai.acceptedPredictionTokens =\n        completionTokenDetails?.accepted_prediction_tokens;\n    }\n    if (completionTokenDetails?.rejected_prediction_tokens != null) {\n      providerMetadata.openai.rejectedPredictionTokens =\n        completionTokenDetails?.rejected_prediction_tokens;\n    }\n    if (choice.logprobs?.content != null) {\n      providerMetadata.openai.logprobs = choice.logprobs.content;\n    }\n\n    return {\n      content,\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      usage: {\n        inputTokens: response.usage?.prompt_tokens ?? undefined,\n        outputTokens: response.usage?.completion_tokens ?? undefined,\n        totalTokens: response.usage?.total_tokens ?? undefined,\n        reasoningTokens: completionTokenDetails?.reasoning_tokens ?? undefined,\n        cachedInputTokens: promptTokenDetails?.cached_tokens ?? undefined,\n      },\n      request: { body },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      warnings,\n      providerMetadata,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiChatChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const toolCalls: Array<{\n      id: string;\n      type: 'function';\n      function: {\n        name: string;\n        arguments: string;\n      };\n      hasFinished: boolean;\n    }> = [];\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let isFirstChunk = true;\n    let isActiveText = false;\n\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<OpenAIChatChunk>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage.inputTokens = value.usage.prompt_tokens ?? undefined;\n              usage.outputTokens = value.usage.completion_tokens ?? undefined;\n              usage.totalTokens = value.usage.total_tokens ?? undefined;\n              usage.reasoningTokens =\n                value.usage.completion_tokens_details?.reasoning_tokens ??\n                undefined;\n              usage.cachedInputTokens =\n                value.usage.prompt_tokens_details?.cached_tokens ?? undefined;\n\n              if (\n                value.usage.completion_tokens_details\n                  ?.accepted_prediction_tokens != null\n              ) {\n                providerMetadata.openai.acceptedPredictionTokens =\n                  value.usage.completion_tokens_details?.accepted_prediction_tokens;\n              }\n              if (\n                value.usage.completion_tokens_details\n                  ?.rejected_prediction_tokens != null\n              ) {\n                providerMetadata.openai.rejectedPredictionTokens =\n                  value.usage.completion_tokens_details?.rejected_prediction_tokens;\n              }\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.logprobs?.content != null) {\n              providerMetadata.openai.logprobs = choice.logprobs.content;\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            if (delta.content != null) {\n              if (!isActiveText) {\n                controller.enqueue({ type: 'text-start', id: '0' });\n                isActiveText = true;\n              }\n\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: delta.content,\n              });\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCallDelta of delta.tool_calls) {\n                const index = toolCallDelta.index;\n\n                // Tool call start. OpenAI returns all information except the arguments in the first chunk.\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== 'function') {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`,\n                    });\n                  }\n\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`,\n                    });\n                  }\n\n                  if (toolCallDelta.function?.name == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`,\n                    });\n                  }\n\n                  controller.enqueue({\n                    type: 'tool-input-start',\n                    id: toolCallDelta.id,\n                    toolName: toolCallDelta.function.name,\n                  });\n\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: 'function',\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: toolCallDelta.function.arguments ?? '',\n                    },\n                    hasFinished: false,\n                  };\n\n                  const toolCall = toolCalls[index];\n\n                  if (\n                    toolCall.function?.name != null &&\n                    toolCall.function?.arguments != null\n                  ) {\n                    // send delta if the argument text has already started:\n                    if (toolCall.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: 'tool-input-delta',\n                        id: toolCall.id,\n                        delta: toolCall.function.arguments,\n                      });\n                    }\n\n                    // check if tool call is complete\n                    // (some providers send the full tool call in one chunk):\n                    if (isParsableJson(toolCall.function.arguments)) {\n                      controller.enqueue({\n                        type: 'tool-input-end',\n                        id: toolCall.id,\n                      });\n\n                      controller.enqueue({\n                        type: 'tool-call',\n                        toolCallId: toolCall.id ?? generateId(),\n                        toolName: toolCall.function.name,\n                        input: toolCall.function.arguments,\n                      });\n                      toolCall.hasFinished = true;\n                    }\n                  }\n\n                  continue;\n                }\n\n                // existing tool call, merge if not finished\n                const toolCall = toolCalls[index];\n\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n\n                if (toolCallDelta.function?.arguments != null) {\n                  toolCall.function!.arguments +=\n                    toolCallDelta.function?.arguments ?? '';\n                }\n\n                // send delta\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.id,\n                  delta: toolCallDelta.function.arguments ?? '',\n                });\n\n                // check if tool call is complete\n                if (\n                  toolCall.function?.name != null &&\n                  toolCall.function?.arguments != null &&\n                  isParsableJson(toolCall.function.arguments)\n                ) {\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.id,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.id ?? generateId(),\n                    toolName: toolCall.function.name,\n                    input: toolCall.function.arguments,\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n\n            // annotations/citations:\n            if (delta.annotations != null) {\n              for (const annotation of delta.annotations) {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              }\n            }\n          },\n\n          flush(controller) {\n            if (isActiveText) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              ...(providerMetadata != null ? { providerMetadata } : {}),\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nfunction isReasoningModel(modelId: string) {\n  return (\n    (modelId.startsWith('o') || modelId.startsWith('gpt-5')) &&\n    !modelId.startsWith('gpt-5-chat')\n  );\n}\n\nfunction supportsFlexProcessing(modelId: string) {\n  return (\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'))\n  );\n}\n\nfunction supportsPriorityProcessing(modelId: string) {\n  return (\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini')\n  );\n}\n\nfunction getSystemMessageMode(modelId: string) {\n  if (!isReasoningModel(modelId)) {\n    return 'system';\n  }\n\n  return (\n    reasoningModels[modelId as keyof typeof reasoningModels]\n      ?.systemMessageMode ?? 'developer'\n  );\n}\n\nconst reasoningModels = {\n  'o1-mini': {\n    systemMessageMode: 'remove',\n  },\n  'o1-mini-2024-09-12': {\n    systemMessageMode: 'remove',\n  },\n  'o1-preview': {\n    systemMessageMode: 'remove',\n  },\n  'o1-preview-2024-09-12': {\n    systemMessageMode: 'remove',\n  },\n  o3: {\n    systemMessageMode: 'developer',\n  },\n  'o3-2025-04-16': {\n    systemMessageMode: 'developer',\n  },\n  'o3-mini': {\n    systemMessageMode: 'developer',\n  },\n  'o3-mini-2025-01-31': {\n    systemMessageMode: 'developer',\n  },\n  'o4-mini': {\n    systemMessageMode: 'developer',\n  },\n  'o4-mini-2025-04-16': {\n    systemMessageMode: 'developer',\n  },\n} as const;\n","import { z } from 'zod/v4';\nimport { createJsonErrorResponseHandler } from '@ai-sdk/provider-utils';\n\nexport const openaiErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAIErrorData = z.infer<typeof openaiErrorDataSchema>;\n\nexport const openaiFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: openaiErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n","import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { OpenAIChatPrompt } from './openai-chat-prompt';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\nexport function convertToOpenAIChatMessages({\n  prompt,\n  systemMessageMode = 'system',\n}: {\n  prompt: LanguageModelV2Prompt;\n  systemMessageMode?: 'system' | 'developer' | 'remove';\n}): {\n  messages: OpenAIChatPrompt;\n  warnings: Array<LanguageModelV2CallWarning>;\n} {\n  const messages: OpenAIChatPrompt = [];\n  const warnings: Array<LanguageModelV2CallWarning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            messages.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            messages.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({ role: 'user', content: content[0].text });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'image_url',\n                    image_url: {\n                      url:\n                        part.data instanceof URL\n                          ? part.data.toString()\n                          : `data:${mediaType};base64,${convertToBase64(part.data)}`,\n\n                      // OpenAI specific extension: image detail\n                      detail: part.providerOptions?.openai?.imageDetail,\n                    },\n                  };\n                } else if (part.mediaType.startsWith('audio/')) {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'audio file parts with URLs',\n                    });\n                  }\n\n                  switch (part.mediaType) {\n                    case 'audio/wav': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'wav',\n                        },\n                      };\n                    }\n                    case 'audio/mp3':\n                    case 'audio/mpeg': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'mp3',\n                        },\n                      };\n                    }\n\n                    default: {\n                      throw new UnsupportedFunctionalityError({\n                        functionality: `audio content parts with media type ${part.mediaType}`,\n                      });\n                    }\n                  }\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'PDF file parts with URLs',\n                    });\n                  }\n\n                  return {\n                    type: 'file',\n                    file:\n                      typeof part.data === 'string' &&\n                      part.data.startsWith('file-')\n                        ? { file_id: part.data }\n                        : {\n                            filename: part.filename ?? `part-${index}.pdf`,\n                            file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                          },\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.input),\n                },\n              });\n              break;\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n        });\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          const output = toolResponse.output;\n\n          let contentValue: string;\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'content':\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n          }\n\n          messages.push({\n            role: 'tool',\n            tool_call_id: toolResponse.toolCallId,\n            content: contentValue,\n          });\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { messages, warnings };\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { JSONSchema7 } from '@ai-sdk/provider';\nimport {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { openaiErrorDataSchema } from '../openai-error';\n\nexport interface OpenAIChatFunctionTool {\n  type: 'function';\n  function: {\n    name: string;\n    description: string | undefined;\n    parameters: JSONSchema7;\n    strict?: boolean;\n  };\n}\n\nexport type OpenAIChatToolChoice =\n  | 'auto'\n  | 'none'\n  | 'required'\n  | { type: 'function'; function: { name: string } };\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiChatResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          message: z.object({\n            role: z.literal('assistant').nullish(),\n            content: z.string().nullish(),\n            tool_calls: z\n              .array(\n                z.object({\n                  id: z.string().nullish(),\n                  type: z.literal('function'),\n                  function: z.object({\n                    name: z.string(),\n                    arguments: z.string(),\n                  }),\n                }),\n              )\n              .nullish(),\n            annotations: z\n              .array(\n                z.object({\n                  type: z.literal('url_citation'),\n                  start_index: z.number(),\n                  end_index: z.number(),\n                  url: z.string(),\n                  title: z.string(),\n                }),\n              )\n              .nullish(),\n          }),\n          index: z.number(),\n          logprobs: z\n            .object({\n              content: z\n                .array(\n                  z.object({\n                    token: z.string(),\n                    logprob: z.number(),\n                    top_logprobs: z.array(\n                      z.object({\n                        token: z.string(),\n                        logprob: z.number(),\n                      }),\n                    ),\n                  }),\n                )\n                .nullish(),\n            })\n            .nullish(),\n          finish_reason: z.string().nullish(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number().nullish(),\n          completion_tokens: z.number().nullish(),\n          total_tokens: z.number().nullish(),\n          prompt_tokens_details: z\n            .object({\n              cached_tokens: z.number().nullish(),\n            })\n            .nullish(),\n          completion_tokens_details: z\n            .object({\n              reasoning_tokens: z.number().nullish(),\n              accepted_prediction_tokens: z.number().nullish(),\n              rejected_prediction_tokens: z.number().nullish(),\n            })\n            .nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiChatChunkSchema = lazyValidator(() =>\n  zodSchema(\n    z.union([\n      z.object({\n        id: z.string().nullish(),\n        created: z.number().nullish(),\n        model: z.string().nullish(),\n        choices: z.array(\n          z.object({\n            delta: z\n              .object({\n                role: z.enum(['assistant']).nullish(),\n                content: z.string().nullish(),\n                tool_calls: z\n                  .array(\n                    z.object({\n                      index: z.number(),\n                      id: z.string().nullish(),\n                      type: z.literal('function').nullish(),\n                      function: z.object({\n                        name: z.string().nullish(),\n                        arguments: z.string().nullish(),\n                      }),\n                    }),\n                  )\n                  .nullish(),\n                annotations: z\n                  .array(\n                    z.object({\n                      type: z.literal('url_citation'),\n                      start_index: z.number(),\n                      end_index: z.number(),\n                      url: z.string(),\n                      title: z.string(),\n                    }),\n                  )\n                  .nullish(),\n              })\n              .nullish(),\n            logprobs: z\n              .object({\n                content: z\n                  .array(\n                    z.object({\n                      token: z.string(),\n                      logprob: z.number(),\n                      top_logprobs: z.array(\n                        z.object({\n                          token: z.string(),\n                          logprob: z.number(),\n                        }),\n                      ),\n                    }),\n                  )\n                  .nullish(),\n              })\n              .nullish(),\n            finish_reason: z.string().nullish(),\n            index: z.number(),\n          }),\n        ),\n        usage: z\n          .object({\n            prompt_tokens: z.number().nullish(),\n            completion_tokens: z.number().nullish(),\n            total_tokens: z.number().nullish(),\n            prompt_tokens_details: z\n              .object({\n                cached_tokens: z.number().nullish(),\n              })\n              .nullish(),\n            completion_tokens_details: z\n              .object({\n                reasoning_tokens: z.number().nullish(),\n                accepted_prediction_tokens: z.number().nullish(),\n                rejected_prediction_tokens: z.number().nullish(),\n              })\n              .nullish(),\n          })\n          .nullish(),\n      }),\n      openaiErrorDataSchema,\n    ]),\n  ),\n);\n\nexport type OpenAIChatResponse = InferValidator<\n  typeof openaiChatResponseSchema\n>;\n\nexport type OpenAIChatChunk = InferValidator<typeof openaiChatChunkSchema>;\n","import {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAIChatModelId =\n  | 'o1'\n  | 'o1-2024-12-17'\n  | 'o3-mini'\n  | 'o3-mini-2025-01-31'\n  | 'o3'\n  | 'o3-2025-04-16'\n  | 'gpt-4.1'\n  | 'gpt-4.1-2025-04-14'\n  | 'gpt-4.1-mini'\n  | 'gpt-4.1-mini-2025-04-14'\n  | 'gpt-4.1-nano'\n  | 'gpt-4.1-nano-2025-04-14'\n  | 'gpt-4o'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-mini'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4'\n  | 'gpt-4-0613'\n  | 'gpt-4.5-preview'\n  | 'gpt-4.5-preview-2025-02-27'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-1106'\n  | 'chatgpt-4o-latest'\n  | 'gpt-5'\n  | 'gpt-5-2025-08-07'\n  | 'gpt-5-mini'\n  | 'gpt-5-mini-2025-08-07'\n  | 'gpt-5-nano'\n  | 'gpt-5-nano-2025-08-07'\n  | 'gpt-5-chat-latest'\n  | (string & {});\n\nexport const openaiChatLanguageModelOptions = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      /**\n       * Modify the likelihood of specified tokens appearing in the completion.\n       *\n       * Accepts a JSON object that maps tokens (specified by their token ID in\n       * the GPT tokenizer) to an associated bias value from -100 to 100.\n       */\n      logitBias: z.record(z.coerce.number<string>(), z.number()).optional(),\n\n      /**\n       * Return the log probabilities of the tokens.\n       *\n       * Setting to true will return the log probabilities of the tokens that\n       * were generated.\n       *\n       * Setting to a number will return the log probabilities of the top n\n       * tokens that were generated.\n       */\n      logprobs: z.union([z.boolean(), z.number()]).optional(),\n\n      /**\n       * Whether to enable parallel function calling during tool use. Default to true.\n       */\n      parallelToolCalls: z.boolean().optional(),\n\n      /**\n       * A unique identifier representing your end-user, which can help OpenAI to\n       * monitor and detect abuse.\n       */\n      user: z.string().optional(),\n\n      /**\n       * Reasoning effort for reasoning models. Defaults to `medium`.\n       */\n      reasoningEffort: z.enum(['minimal', 'low', 'medium', 'high']).optional(),\n\n      /**\n       * Maximum number of completion tokens to generate. Useful for reasoning models.\n       */\n      maxCompletionTokens: z.number().optional(),\n\n      /**\n       * Whether to enable persistence in responses API.\n       */\n      store: z.boolean().optional(),\n\n      /**\n       * Metadata to associate with the request.\n       */\n      metadata: z.record(z.string().max(64), z.string().max(512)).optional(),\n\n      /**\n       * Parameters for prediction mode.\n       */\n      prediction: z.record(z.string(), z.any()).optional(),\n\n      /**\n       * Whether to use structured outputs.\n       *\n       * @default true\n       */\n      structuredOutputs: z.boolean().optional(),\n\n      /**\n       * Service tier for the request.\n       * - 'auto': Default service tier. The request will be processed with the service tier configured in the\n       *           Project settings. Unless otherwise configured, the Project will use 'default'.\n       * - 'flex': 50% cheaper processing at the cost of increased latency. Only available for o3 and o4-mini models.\n       * - 'priority': Higher-speed processing with predictably low latency at premium cost. Available for Enterprise customers.\n       * - 'default': The request will be processed with the standard pricing and performance for the selected model.\n       *\n       * @default 'auto'\n       */\n      serviceTier: z.enum(['auto', 'flex', 'priority', 'default']).optional(),\n\n      /**\n       * Whether to use strict JSON schema validation.\n       *\n       * @default false\n       */\n      strictJsonSchema: z.boolean().optional(),\n\n      /**\n       * Controls the verbosity of the model's responses.\n       * Lower values will result in more concise responses, while higher values will result in more verbose responses.\n       */\n      textVerbosity: z.enum(['low', 'medium', 'high']).optional(),\n\n      /**\n       * A cache key for prompt caching. Allows manual control over prompt caching behavior.\n       * Useful for improving cache hit rates and working around automatic caching issues.\n       */\n      promptCacheKey: z.string().optional(),\n\n      /**\n       * A stable identifier used to help detect users of your application\n       * that may be violating OpenAI's usage policies. The IDs should be a\n       * string that uniquely identifies each user. We recommend hashing their\n       * username or email address, in order to avoid sending us any identifying\n       * information.\n       */\n      safetyIdentifier: z.string().optional(),\n    }),\n  ),\n);\n\nexport type OpenAIChatLanguageModelOptions = InferValidator<\n  typeof openaiChatLanguageModelOptions\n>;\n","import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  OpenAIChatToolChoice,\n  OpenAIChatFunctionTool,\n} from './openai-chat-api';\n\nexport function prepareChatTools({\n  tools,\n  toolChoice,\n  structuredOutputs,\n  strictJsonSchema,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  structuredOutputs: boolean;\n  strictJsonSchema: boolean;\n}): {\n  tools?: OpenAIChatFunctionTool[];\n  toolChoice?: OpenAIChatToolChoice;\n  toolWarnings: Array<LanguageModelV2CallWarning>;\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: OpenAIChatFunctionTool[] = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          function: {\n            name: tool.name,\n            description: tool.description,\n            parameters: tool.inputSchema,\n            strict: structuredOutputs ? strictJsonSchema : undefined,\n          },\n        });\n        break;\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import {\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { convertToOpenAICompletionPrompt } from './convert-to-openai-completion-prompt';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAICompletionChunk,\n  openaiCompletionChunkSchema,\n  openaiCompletionResponseSchema,\n} from './openai-completion-api';\nimport {\n  OpenAICompletionModelId,\n  openaiCompletionProviderOptions,\n} from './openai-completion-options';\n\ntype OpenAICompletionConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAICompletionLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAICompletionModelId;\n\n  private readonly config: OpenAICompletionConfig;\n\n  private get providerOptionsName(): string {\n    return this.config.provider.split('.')[0].trim();\n  }\n\n  constructor(\n    modelId: OpenAICompletionModelId,\n    config: OpenAICompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    // No URLs are supported for completion models.\n  };\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    tools,\n    toolChoice,\n    seed,\n    providerOptions,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openaiOptions = {\n      ...(await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n      ...(await parseProviderOptions({\n        provider: this.providerOptionsName,\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n    };\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'topK' });\n    }\n\n    if (tools?.length) {\n      warnings.push({ type: 'unsupported-setting', setting: 'tools' });\n    }\n\n    if (toolChoice != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'toolChoice' });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompletionPrompt({ prompt });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    return {\n      args: {\n        // model id:\n        model: this.modelId,\n\n        // model specific settings:\n        echo: openaiOptions.echo,\n        logit_bias: openaiOptions.logitBias,\n        logprobs:\n          openaiOptions?.logprobs === true\n            ? 0\n            : openaiOptions?.logprobs === false\n              ? undefined\n              : openaiOptions?.logprobs,\n        suffix: openaiOptions.suffix,\n        user: openaiOptions.user,\n\n        // standardized settings:\n        max_tokens: maxOutputTokens,\n        temperature,\n        top_p: topP,\n        frequency_penalty: frequencyPenalty,\n        presence_penalty: presencePenalty,\n        seed,\n\n        // prompt:\n        prompt: completionPrompt,\n\n        // stop sequences:\n        stop: stop.length > 0 ? stop : undefined,\n      },\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n\n    if (choice.logprobs != null) {\n      providerMetadata.openai.logprobs = choice.logprobs;\n    }\n\n    return {\n      content: [{ type: 'text', text: choice.text }],\n      usage: {\n        inputTokens: response.usage?.prompt_tokens,\n        outputTokens: response.usage?.completion_tokens,\n        totalTokens: response.usage?.total_tokens,\n      },\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      request: { body: args },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiCompletionChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<OpenAICompletionChunk>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n\n              controller.enqueue({ type: 'text-start', id: '0' });\n            }\n\n            if (value.usage != null) {\n              usage.inputTokens = value.usage.prompt_tokens;\n              usage.outputTokens = value.usage.completion_tokens;\n              usage.totalTokens = value.usage.total_tokens;\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.logprobs != null) {\n              providerMetadata.openai.logprobs = choice.logprobs;\n            }\n\n            if (choice?.text != null && choice.text.length > 0) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: choice.text,\n              });\n            }\n          },\n\n          flush(controller) {\n            if (!isFirstChunk) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              providerMetadata,\n              usage,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n","import {\n  InvalidPromptError,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompletionPrompt({\n  prompt,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV2Prompt;\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n            }\n          })\n          .filter(Boolean)\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { z } from 'zod/v4';\nimport { openaiErrorDataSchema } from '../openai-error';\nimport {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiCompletionResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          text: z.string(),\n          finish_reason: z.string(),\n          logprobs: z\n            .object({\n              tokens: z.array(z.string()),\n              token_logprobs: z.array(z.number()),\n              top_logprobs: z.array(z.record(z.string(), z.number())).nullish(),\n            })\n            .nullish(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number(),\n          completion_tokens: z.number(),\n          total_tokens: z.number(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiCompletionChunkSchema = lazyValidator(() =>\n  zodSchema(\n    z.union([\n      z.object({\n        id: z.string().nullish(),\n        created: z.number().nullish(),\n        model: z.string().nullish(),\n        choices: z.array(\n          z.object({\n            text: z.string(),\n            finish_reason: z.string().nullish(),\n            index: z.number(),\n            logprobs: z\n              .object({\n                tokens: z.array(z.string()),\n                token_logprobs: z.array(z.number()),\n                top_logprobs: z\n                  .array(z.record(z.string(), z.number()))\n                  .nullish(),\n              })\n              .nullish(),\n          }),\n        ),\n        usage: z\n          .object({\n            prompt_tokens: z.number(),\n            completion_tokens: z.number(),\n            total_tokens: z.number(),\n          })\n          .nullish(),\n      }),\n      openaiErrorDataSchema,\n    ]),\n  ),\n);\n\nexport type OpenAICompletionChunk = InferValidator<\n  typeof openaiCompletionChunkSchema\n>;\n\nexport type OpenAICompletionResponse = InferValidator<\n  typeof openaiCompletionResponseSchema\n>;\n","import {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAICompletionModelId = 'gpt-3.5-turbo-instruct' | (string & {});\n\nexport const openaiCompletionProviderOptions = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      /**\nEcho back the prompt in addition to the completion.\n   */\n      echo: z.boolean().optional(),\n\n      /**\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in\nthe GPT tokenizer) to an associated bias value from -100 to 100. You\ncan use this tokenizer tool to convert text to token IDs. Mathematically,\nthe bias is added to the logits generated by the model prior to sampling.\nThe exact effect will vary per model, but values between -1 and 1 should\ndecrease or increase likelihood of selection; values like -100 or 100\nshould result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass {\"50256\": -100} to prevent the <|endoftext|>\ntoken from being generated.\n */\n      logitBias: z.record(z.string(), z.number()).optional(),\n\n      /**\nThe suffix that comes after a completion of inserted text.\n */\n      suffix: z.string().optional(),\n\n      /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n */\n      user: z.string().optional(),\n\n      /**\nReturn the log probabilities of the tokens. Including logprobs will increase\nthe response size and can slow down response times. However, it can\nbe useful to better understand how the model is behaving.\nSetting to true will return the log probabilities of the tokens that\nwere generated.\nSetting to a number will return the log probabilities of the top n\ntokens that were generated.\n   */\n      logprobs: z.union([z.boolean(), z.number()]).optional(),\n    }),\n  ),\n);\n\nexport type OpenAICompletionProviderOptions = InferValidator<\n  typeof openaiCompletionProviderOptions\n>;\n","import {\n  EmbeddingModelV2,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAIEmbeddingModelId,\n  openaiEmbeddingProviderOptions,\n} from './openai-embedding-options';\nimport { openaiTextEmbeddingResponseSchema } from './openai-embedding-api';\n\nexport class OpenAIEmbeddingModel implements EmbeddingModelV2<string> {\n  readonly specificationVersion = 'v2';\n  readonly modelId: OpenAIEmbeddingModelId;\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  private readonly config: OpenAIConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(modelId: OpenAIEmbeddingModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV2<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV2<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiEmbeddingProviderOptions,\n      })) ?? {};\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: openaiOptions.dimensions,\n        user: openaiOptions.user,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      response: { headers: responseHeaders, body: rawValue },\n    };\n  }\n}\n","import {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAIEmbeddingModelId =\n  | 'text-embedding-3-small'\n  | 'text-embedding-3-large'\n  | 'text-embedding-ada-002'\n  | (string & {});\n\nexport const openaiEmbeddingProviderOptions = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      /**\nThe number of dimensions the resulting output embeddings should have.\nOnly supported in text-embedding-3 and later models.\n   */\n      dimensions: z.number().optional(),\n\n      /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n*/\n      user: z.string().optional(),\n    }),\n  ),\n);\n\nexport type OpenAIEmbeddingProviderOptions = InferValidator<\n  typeof openaiEmbeddingProviderOptions\n>;\n","import { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiTextEmbeddingResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      data: z.array(z.object({ embedding: z.array(z.number()) })),\n      usage: z.object({ prompt_tokens: z.number() }).nullish(),\n    }),\n  ),\n);\n","import { ImageModelV2, ImageModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { openaiImageResponseSchema } from './openai-image-api';\nimport {\n  OpenAIImageModelId,\n  hasDefaultResponseFormat,\n  modelMaxImagesPerCall,\n} from './openai-image-options';\n\ninterface OpenAIImageModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAIImageModel implements ImageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get maxImagesPerCall(): number {\n    return modelMaxImagesPerCall[this.modelId] ?? 1;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAIImageModelId,\n    private readonly config: OpenAIImageModelConfig,\n  ) {}\n\n  async doGenerate({\n    prompt,\n    n,\n    size,\n    aspectRatio,\n    seed,\n    providerOptions,\n    headers,\n    abortSignal,\n  }: Parameters<ImageModelV2['doGenerate']>[0]): Promise<\n    Awaited<ReturnType<ImageModelV2['doGenerate']>>\n  > {\n    const warnings: Array<ImageModelV2CallWarning> = [];\n\n    if (aspectRatio != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'aspectRatio',\n        details:\n          'This model does not support aspect ratio. Use `size` instead.',\n      });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'seed' });\n    }\n\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { value: response, responseHeaders } = await postJsonToApi({\n      url: this.config.url({\n        path: '/images/generations',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        prompt,\n        n,\n        size,\n        ...(providerOptions.openai ?? {}),\n        ...(!hasDefaultResponseFormat.has(this.modelId)\n          ? { response_format: 'b64_json' }\n          : {}),\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      images: response.data.map(item => item.b64_json),\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n      },\n      providerMetadata: {\n        openai: {\n          images: response.data.map(item =>\n            item.revised_prompt\n              ? {\n                  revisedPrompt: item.revised_prompt,\n                }\n              : null,\n          ),\n        },\n      },\n    };\n  }\n}\n","import { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiImageResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      data: z.array(\n        z.object({\n          b64_json: z.string(),\n          revised_prompt: z.string().optional(),\n        }),\n      ),\n    }),\n  ),\n);\n","export type OpenAIImageModelId =\n  | 'dall-e-3'\n  | 'dall-e-2'\n  | 'gpt-image-1'\n  | 'gpt-image-1-mini'\n  | (string & {});\n\n// https://platform.openai.com/docs/guides/images\nexport const modelMaxImagesPerCall: Record<OpenAIImageModelId, number> = {\n  'dall-e-3': 1,\n  'dall-e-2': 10,\n  'gpt-image-1': 10,\n  'gpt-image-1-mini': 10,\n};\n\nexport const hasDefaultResponseFormat = new Set([\n  'gpt-image-1',\n  'gpt-image-1-mini',\n]);\n","import {\n  createProviderDefinedToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const codeInterpreterInputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      code: z.string().nullish(),\n      containerId: z.string(),\n    }),\n  ),\n);\n\nexport const codeInterpreterOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      outputs: z\n        .array(\n          z.discriminatedUnion('type', [\n            z.object({ type: z.literal('logs'), logs: z.string() }),\n            z.object({ type: z.literal('image'), url: z.string() }),\n          ]),\n        )\n        .nullish(),\n    }),\n  ),\n);\n\nexport const codeInterpreterArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      container: z\n        .union([\n          z.string(),\n          z.object({\n            fileIds: z.array(z.string()).optional(),\n          }),\n        ])\n        .optional(),\n    }),\n  ),\n);\n\ntype CodeInterpreterArgs = {\n  /**\n   * The code interpreter container.\n   * Can be a container ID\n   * or an object that specifies uploaded file IDs to make available to your code.\n   */\n  container?: string | { fileIds?: string[] };\n};\n\nexport const codeInterpreterToolFactory =\n  createProviderDefinedToolFactoryWithOutputSchema<\n    {\n      /**\n       * The code to run, or null if not available.\n       */\n      code?: string | null;\n\n      /**\n       * The ID of the container used to run the code.\n       */\n      containerId: string;\n    },\n    {\n      /**\n       * The outputs generated by the code interpreter, such as logs or images.\n       * Can be null if no outputs are available.\n       */\n      outputs?: Array<\n        | {\n            type: 'logs';\n\n            /**\n             * The logs output from the code interpreter.\n             */\n            logs: string;\n          }\n        | {\n            type: 'image';\n\n            /**\n             * The URL of the image output from the code interpreter.\n             */\n            url: string;\n          }\n      > | null;\n    },\n    CodeInterpreterArgs\n  >({\n    id: 'openai.code_interpreter',\n    name: 'code_interpreter',\n    inputSchema: codeInterpreterInputSchema,\n    outputSchema: codeInterpreterOutputSchema,\n  });\n\nexport const codeInterpreter = (\n  args: CodeInterpreterArgs = {}, // default\n) => {\n  return codeInterpreterToolFactory(args);\n};\n","import {\n  createProviderDefinedToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  OpenAIResponsesFileSearchToolComparisonFilter,\n  OpenAIResponsesFileSearchToolCompoundFilter,\n} from '../responses/openai-responses-api';\n\nconst comparisonFilterSchema = z.object({\n  key: z.string(),\n  type: z.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']),\n  value: z.union([z.string(), z.number(), z.boolean()]),\n});\n\nconst compoundFilterSchema: z.ZodType<any> = z.object({\n  type: z.enum(['and', 'or']),\n  filters: z.array(\n    z.union([comparisonFilterSchema, z.lazy(() => compoundFilterSchema)]),\n  ),\n});\n\nexport const fileSearchArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      vectorStoreIds: z.array(z.string()),\n      maxNumResults: z.number().optional(),\n      ranking: z\n        .object({\n          ranker: z.string().optional(),\n          scoreThreshold: z.number().optional(),\n        })\n        .optional(),\n      filters: z\n        .union([comparisonFilterSchema, compoundFilterSchema])\n        .optional(),\n    }),\n  ),\n);\n\nexport const fileSearchOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      queries: z.array(z.string()),\n      results: z\n        .array(\n          z.object({\n            attributes: z.record(z.string(), z.unknown()),\n            fileId: z.string(),\n            filename: z.string(),\n            score: z.number(),\n            text: z.string(),\n          }),\n        )\n        .nullable(),\n    }),\n  ),\n);\n\nexport const fileSearch = createProviderDefinedToolFactoryWithOutputSchema<\n  {},\n  {\n    /**\n     * The search query to execute.\n     */\n    queries: string[];\n\n    /**\n     * The results of the file search tool call.\n     */\n    results:\n      | null\n      | {\n          /**\n           * Set of 16 key-value pairs that can be attached to an object.\n           * This can be useful for storing additional information about the object\n           * in a structured format, and querying for objects via API or the dashboard.\n           * Keys are strings with a maximum length of 64 characters.\n           * Values are strings with a maximum length of 512 characters, booleans, or numbers.\n           */\n          attributes: Record<string, unknown>;\n\n          /**\n           * The unique ID of the file.\n           */\n          fileId: string;\n\n          /**\n           * The name of the file.\n           */\n          filename: string;\n\n          /**\n           * The relevance score of the file - a value between 0 and 1.\n           */\n          score: number;\n\n          /**\n           * The text that was retrieved from the file.\n           */\n          text: string;\n        }[];\n  },\n  {\n    /**\n     * List of vector store IDs to search through.\n     */\n    vectorStoreIds: string[];\n\n    /**\n     * Maximum number of search results to return. Defaults to 10.\n     */\n    maxNumResults?: number;\n\n    /**\n     * Ranking options for the search.\n     */\n    ranking?: {\n      /**\n       * The ranker to use for the file search.\n       */\n      ranker?: string;\n\n      /**\n       * The score threshold for the file search, a number between 0 and 1.\n       * Numbers closer to 1 will attempt to return only the most relevant results,\n       * but may return fewer results.\n       */\n      scoreThreshold?: number;\n    };\n\n    /**\n     * A filter to apply.\n     */\n    filters?:\n      | OpenAIResponsesFileSearchToolComparisonFilter\n      | OpenAIResponsesFileSearchToolCompoundFilter;\n  }\n>({\n  id: 'openai.file_search',\n  name: 'file_search',\n  inputSchema: z.object({}),\n  outputSchema: fileSearchOutputSchema,\n});\n","import {\n  createProviderDefinedToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const imageGenerationArgsSchema = lazySchema(() =>\n  zodSchema(\n    z\n      .object({\n        background: z.enum(['auto', 'opaque', 'transparent']).optional(),\n        inputFidelity: z.enum(['low', 'high']).optional(),\n        inputImageMask: z\n          .object({\n            fileId: z.string().optional(),\n            imageUrl: z.string().optional(),\n          })\n          .optional(),\n        model: z.string().optional(),\n        moderation: z.enum(['auto']).optional(),\n        outputCompression: z.number().int().min(0).max(100).optional(),\n        outputFormat: z.enum(['png', 'jpeg', 'webp']).optional(),\n        partialImages: z.number().int().min(0).max(3).optional(),\n        quality: z.enum(['auto', 'low', 'medium', 'high']).optional(),\n        size: z\n          .enum(['1024x1024', '1024x1536', '1536x1024', 'auto'])\n          .optional(),\n      })\n      .strict(),\n  ),\n);\n\nconst imageGenerationInputSchema = lazySchema(() => zodSchema(z.object({})));\n\nexport const imageGenerationOutputSchema = lazySchema(() =>\n  zodSchema(z.object({ result: z.string() })),\n);\n\ntype ImageGenerationArgs = {\n  /**\n   * Background type for the generated image. Default is 'auto'.\n   */\n  background?: 'auto' | 'opaque' | 'transparent';\n\n  /**\n   * Input fidelity for the generated image. Default is 'low'.\n   */\n  inputFidelity?: 'low' | 'high';\n\n  /**\n   * Optional mask for inpainting.\n   * Contains image_url (string, optional) and file_id (string, optional).\n   */\n  inputImageMask?: {\n    /**\n     * File ID for the mask image.\n     */\n    fileId?: string;\n\n    /**\n     * Base64-encoded mask image.\n     */\n    imageUrl?: string;\n  };\n\n  /**\n   * The image generation model to use. Default: gpt-image-1.\n   */\n  model?: string;\n\n  /**\n   * Moderation level for the generated image. Default: auto.\n   */\n  moderation?: 'auto';\n\n  /**\n   * Compression level for the output image. Default: 100.\n   */\n  outputCompression?: number;\n\n  /**\n   * The output format of the generated image. One of png, webp, or jpeg.\n   * Default: png\n   */\n  outputFormat?: 'png' | 'jpeg' | 'webp';\n\n  /**\n   * The quality of the generated image.\n   * One of low, medium, high, or auto. Default: auto.\n   */\n  quality?: 'auto' | 'low' | 'medium' | 'high';\n\n  /**\n   * The size of the generated image.\n   * One of 1024x1024, 1024x1536, 1536x1024, or auto.\n   * Default: auto.\n   */\n  size?: 'auto' | '1024x1024' | '1024x1536' | '1536x1024';\n};\n\nconst imageGenerationToolFactory =\n  createProviderDefinedToolFactoryWithOutputSchema<\n    {},\n    {\n      /**\n       * The generated image encoded in base64.\n       */\n      result: string;\n    },\n    ImageGenerationArgs\n  >({\n    id: 'openai.image_generation',\n    name: 'image_generation',\n    inputSchema: imageGenerationInputSchema,\n    outputSchema: imageGenerationOutputSchema,\n  });\n\nexport const imageGeneration = (\n  args: ImageGenerationArgs = {}, // default\n) => {\n  return imageGenerationToolFactory(args);\n};\n","import {\n  createProviderDefinedToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const localShellInputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.object({\n        type: z.literal('exec'),\n        command: z.array(z.string()),\n        timeoutMs: z.number().optional(),\n        user: z.string().optional(),\n        workingDirectory: z.string().optional(),\n        env: z.record(z.string(), z.string()).optional(),\n      }),\n    }),\n  ),\n);\n\nexport const localShellOutputSchema = lazySchema(() =>\n  zodSchema(z.object({ output: z.string() })),\n);\n\nexport const localShell = createProviderDefinedToolFactoryWithOutputSchema<\n  {\n    /**\n     * Execute a shell command on the server.\n     */\n    action: {\n      type: 'exec';\n\n      /**\n       * The command to run.\n       */\n      command: string[];\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeoutMs?: number;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      workingDirectory?: string;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env?: Record<string, string>;\n    };\n  },\n  {\n    /**\n     * The output of local shell tool call.\n     */\n    output: string;\n  },\n  {}\n>({\n  id: 'openai.local_shell',\n  name: 'local_shell',\n  inputSchema: localShellInputSchema,\n  outputSchema: localShellOutputSchema,\n});\n","import {\n  createProviderDefinedToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const webSearchArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      filters: z\n        .object({ allowedDomains: z.array(z.string()).optional() })\n        .optional(),\n      searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n      userLocation: z\n        .object({\n          type: z.literal('approximate'),\n          country: z.string().optional(),\n          city: z.string().optional(),\n          region: z.string().optional(),\n          timezone: z.string().optional(),\n        })\n        .optional(),\n    }),\n  ),\n);\n\nconst webSearchInputSchema = lazySchema(() => zodSchema(z.object({})));\n\nexport const webSearchOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().optional(),\n        }),\n        z.object({\n          type: z.literal('openPage'),\n          url: z.string(),\n        }),\n        z.object({\n          type: z.literal('find'),\n          url: z.string(),\n          pattern: z.string(),\n        }),\n      ]),\n    }),\n  ),\n);\n\nexport const webSearchToolFactory =\n  createProviderDefinedToolFactoryWithOutputSchema<\n    {\n      // Web search doesn't take input parameters - it's controlled by the prompt\n    },\n    {\n      /**\n       * An object describing the specific action taken in this web search call.\n       * Includes details on how the model used the web (search, open_page, find).\n       */\n      action:\n        | {\n            /**\n             * Action type \"search\" - Performs a web search query.\n             */\n            type: 'search';\n\n            /**\n             * The search query.\n             */\n            query?: string;\n          }\n        | {\n            /**\n             * Action type \"openPage\" - Opens a specific URL from search results.\n             */\n            type: 'openPage';\n\n            /**\n             * The URL opened by the model.\n             */\n            url: string;\n          }\n        | {\n            /**\n             * Action type \"find\": Searches for a pattern within a loaded page.\n             */\n            type: 'find';\n\n            /**\n             * The URL of the page searched for the pattern.\n             */\n            url: string;\n\n            /**\n             * The pattern or text to search for within the page.\n             */\n            pattern: string;\n          };\n    },\n    {\n      /**\n       * Filters for the search.\n       */\n      filters?: {\n        /**\n         * Allowed domains for the search.\n         * If not provided, all domains are allowed.\n         * Subdomains of the provided domains are allowed as well.\n         */\n        allowedDomains?: string[];\n      };\n\n      /**\n       * Search context size to use for the web search.\n       * - high: Most comprehensive context, highest cost, slower response\n       * - medium: Balanced context, cost, and latency (default)\n       * - low: Least context, lowest cost, fastest response\n       */\n      searchContextSize?: 'low' | 'medium' | 'high';\n\n      /**\n       * User location information to provide geographically relevant search results.\n       */\n      userLocation?: {\n        /**\n         * Type of location (always 'approximate')\n         */\n        type: 'approximate';\n        /**\n         * Two-letter ISO country code (e.g., 'US', 'GB')\n         */\n        country?: string;\n        /**\n         * City name (free text, e.g., 'Minneapolis')\n         */\n        city?: string;\n        /**\n         * Region name (free text, e.g., 'Minnesota')\n         */\n        region?: string;\n        /**\n         * IANA timezone (e.g., 'America/Chicago')\n         */\n        timezone?: string;\n      };\n    }\n  >({\n    id: 'openai.web_search',\n    name: 'web_search',\n    inputSchema: webSearchInputSchema,\n    outputSchema: webSearchOutputSchema,\n  });\n\nexport const webSearch = (\n  args: Parameters<typeof webSearchToolFactory>[0] = {}, // default\n) => webSearchToolFactory(args);\n","import {\n  createProviderDefinedToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const webSearchPreviewArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n      userLocation: z\n        .object({\n          type: z.literal('approximate'),\n          country: z.string().optional(),\n          city: z.string().optional(),\n          region: z.string().optional(),\n          timezone: z.string().optional(),\n        })\n        .optional(),\n    }),\n  ),\n);\n\nexport const webSearchPreviewInputSchema = lazySchema(() =>\n  zodSchema(z.object({})),\n);\n\nconst webSearchPreviewOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().optional(),\n        }),\n        z.object({\n          type: z.literal('openPage'),\n          url: z.string(),\n        }),\n        z.object({\n          type: z.literal('find'),\n          url: z.string(),\n          pattern: z.string(),\n        }),\n      ]),\n    }),\n  ),\n);\n\nexport const webSearchPreview =\n  createProviderDefinedToolFactoryWithOutputSchema<\n    {\n      // Web search preview doesn't take input parameters - it's controlled by the prompt\n    },\n    {\n      /**\n       * An object describing the specific action taken in this web search call.\n       * Includes details on how the model used the web (search, open_page, find).\n       */\n      action:\n        | {\n            /**\n             * Action type \"search\" - Performs a web search query.\n             */\n            type: 'search';\n\n            /**\n             * The search query.\n             */\n            query?: string;\n          }\n        | {\n            /**\n             * Action type \"openPage\" - Opens a specific URL from search results.\n             */\n            type: 'openPage';\n\n            /**\n             * The URL opened by the model.\n             */\n            url: string;\n          }\n        | {\n            /**\n             * Action type \"find\": Searches for a pattern within a loaded page.\n             */\n            type: 'find';\n\n            /**\n             * The URL of the page searched for the pattern.\n             */\n            url: string;\n\n            /**\n             * The pattern or text to search for within the page.\n             */\n            pattern: string;\n          };\n    },\n    {\n      /**\n       * Search context size to use for the web search.\n       * - high: Most comprehensive context, highest cost, slower response\n       * - medium: Balanced context, cost, and latency (default)\n       * - low: Least context, lowest cost, fastest response\n       */\n      searchContextSize?: 'low' | 'medium' | 'high';\n\n      /**\n       * User location information to provide geographically relevant search results.\n       */\n      userLocation?: {\n        /**\n         * Type of location (always 'approximate')\n         */\n        type: 'approximate';\n        /**\n         * Two-letter ISO country code (e.g., 'US', 'GB')\n         */\n        country?: string;\n        /**\n         * City name (free text, e.g., 'Minneapolis')\n         */\n        city?: string;\n        /**\n         * Region name (free text, e.g., 'Minnesota')\n         */\n        region?: string;\n        /**\n         * IANA timezone (e.g., 'America/Chicago')\n         */\n        timezone?: string;\n      };\n    }\n  >({\n    id: 'openai.web_search_preview',\n    name: 'web_search_preview',\n    inputSchema: webSearchPreviewInputSchema,\n    outputSchema: webSearchPreviewOutputSchema,\n  });\n","import { codeInterpreter } from './tool/code-interpreter';\nimport { fileSearch } from './tool/file-search';\nimport { imageGeneration } from './tool/image-generation';\nimport { localShell } from './tool/local-shell';\nimport { webSearch } from './tool/web-search';\nimport { webSearchPreview } from './tool/web-search-preview';\n\nexport const openaiTools = {\n  /**\n   * The Code Interpreter tool allows models to write and run Python code in a\n   * sandboxed environment to solve complex problems in domains like data analysis,\n   * coding, and math.\n   *\n   * @param container - The container to use for the code interpreter.\n   *\n   * Must have name `code_interpreter`.\n   */\n  codeInterpreter,\n\n  /**\n   * File search is a tool available in the Responses API. It enables models to\n   * retrieve information in a knowledge base of previously uploaded files through\n   * semantic and keyword search.\n   *\n   * Must have name `file_search`.\n   *\n   * @param vectorStoreIds - The vector store IDs to use for the file search.\n   * @param maxNumResults - The maximum number of results to return.\n   * @param ranking - The ranking options to use for the file search.\n   * @param filters - The filters to use for the file search.\n   */\n  fileSearch,\n\n  /**\n   * The image generation tool allows you to generate images using a text prompt,\n   * and optionally image inputs. It leverages the GPT Image model,\n   * and automatically optimizes text inputs for improved performance.\n   *\n   * Must have name `image_generation`.\n   *\n   * @param size - Image dimensions (e.g., 1024x1024, 1024x1536)\n   * @param quality - Rendering quality (e.g. low, medium, high)\n   * @param format - File output format\n   * @param compression - Compression level (0-100%) for JPEG and WebP formats\n   * @param background - Transparent or opaque\n   */\n  imageGeneration,\n\n  /**\n   * Local shell is a tool that allows agents to run shell commands locally\n   * on a machine you or the user provides.\n   *\n   * Supported models: `gpt-5-codex` and `codex-mini-latest`\n   *\n   * Must have name `local_shell`.\n   */\n  localShell,\n\n  /**\n   * Web search allows models to access up-to-date information from the internet\n   * and provide answers with sourced citations.\n   *\n   * Must have name `web_search_preview`.\n   *\n   * @param searchContextSize - The search context size to use for the web search.\n   * @param userLocation - The user location to use for the web search.\n   *\n   * @deprecated Use `webSearch` instead.\n   */\n  webSearchPreview,\n\n  /**\n   * Web search allows models to access up-to-date information from the internet\n   * and provide answers with sourced citations.\n   *\n   * Must have name `web_search`.\n   *\n   * @param filters - The filters to use for the web search.\n   * @param searchContextSize - The search context size to use for the web search.\n   * @param userLocation - The user location to use for the web search.\n   */\n  webSearch,\n};\n","import {\n  APICallError,\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2ProviderDefinedTool,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  InferValidator,\n  parseProviderOptions,\n  ParseResult,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  codeInterpreterInputSchema,\n  codeInterpreterOutputSchema,\n} from '../tool/code-interpreter';\nimport { fileSearchOutputSchema } from '../tool/file-search';\nimport { imageGenerationOutputSchema } from '../tool/image-generation';\nimport { localShellInputSchema } from '../tool/local-shell';\nimport { webSearchOutputSchema } from '../tool/web-search';\nimport { convertToOpenAIResponsesInput } from './convert-to-openai-responses-input';\nimport { mapOpenAIResponseFinishReason } from './map-openai-responses-finish-reason';\nimport {\n  OpenAIResponsesChunk,\n  openaiResponsesChunkSchema,\n  OpenAIResponsesIncludeOptions,\n  OpenAIResponsesIncludeValue,\n  OpenAIResponsesLogprobs,\n  openaiResponsesResponseSchema,\n  OpenAIResponsesWebSearchAction,\n} from './openai-responses-api';\nimport {\n  OpenAIResponsesModelId,\n  openaiResponsesProviderOptionsSchema,\n  TOP_LOGPROBS_MAX,\n} from './openai-responses-options';\nimport { prepareResponsesTools } from './openai-responses-prepare-tools';\n\nexport class OpenAIResponsesLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAIResponsesModelId;\n\n  private readonly config: OpenAIConfig;\n\n  constructor(modelId: OpenAIResponsesModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    'image/*': [/^https?:\\/\\/.*$/],\n    'application/pdf': [/^https?:\\/\\/.*$/],\n  };\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    maxOutputTokens,\n    temperature,\n    stopSequences,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    seed,\n    prompt,\n    providerOptions,\n    tools,\n    toolChoice,\n    responseFormat,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n    const modelConfig = getResponsesModelConfig(this.modelId);\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'topK' });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'seed' });\n    }\n\n    if (presencePenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'presencePenalty',\n      });\n    }\n\n    if (frequencyPenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'frequencyPenalty',\n      });\n    }\n\n    if (stopSequences != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'stopSequences' });\n    }\n\n    const openaiOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openaiResponsesProviderOptionsSchema,\n    });\n\n    const { input, warnings: inputWarnings } =\n      await convertToOpenAIResponsesInput({\n        prompt,\n        systemMessageMode: modelConfig.systemMessageMode,\n        fileIdPrefixes: this.config.fileIdPrefixes,\n        store: openaiOptions?.store ?? true,\n        hasLocalShellTool: hasOpenAITool('openai.local_shell'),\n      });\n\n    warnings.push(...inputWarnings);\n\n    const strictJsonSchema = openaiOptions?.strictJsonSchema ?? false;\n\n    let include: OpenAIResponsesIncludeOptions = openaiOptions?.include;\n\n    function addInclude(key: OpenAIResponsesIncludeValue) {\n      if (include == null) {\n        include = [key];\n      } else if (!include.includes(key)) {\n        include = [...include, key];\n      }\n    }\n\n    function hasOpenAITool(id: string) {\n      return (\n        tools?.find(\n          tool => tool.type === 'provider-defined' && tool.id === id,\n        ) != null\n      );\n    }\n\n    // when logprobs are requested, automatically include them:\n    const topLogprobs =\n      typeof openaiOptions?.logprobs === 'number'\n        ? openaiOptions?.logprobs\n        : openaiOptions?.logprobs === true\n          ? TOP_LOGPROBS_MAX\n          : undefined;\n\n    if (topLogprobs) {\n      addInclude('message.output_text.logprobs');\n    }\n\n    // when a web search tool is present, automatically include the sources:\n    const webSearchToolName = (\n      tools?.find(\n        tool =>\n          tool.type === 'provider-defined' &&\n          (tool.id === 'openai.web_search' ||\n            tool.id === 'openai.web_search_preview'),\n      ) as LanguageModelV2ProviderDefinedTool | undefined\n    )?.name;\n\n    if (webSearchToolName) {\n      addInclude('web_search_call.action.sources');\n    }\n\n    // when a code interpreter tool is present, automatically include the outputs:\n    if (hasOpenAITool('openai.code_interpreter')) {\n      addInclude('code_interpreter_call.outputs');\n    }\n\n    const store = openaiOptions?.store;\n\n    // store defaults to true in the OpenAI responses API, so check for false exactly:\n    if (store === false && modelConfig.isReasoningModel) {\n      addInclude('reasoning.encrypted_content');\n    }\n\n    const baseArgs = {\n      model: this.modelId,\n      input,\n      temperature,\n      top_p: topP,\n      max_output_tokens: maxOutputTokens,\n\n      ...((responseFormat?.type === 'json' || openaiOptions?.textVerbosity) && {\n        text: {\n          ...(responseFormat?.type === 'json' && {\n            format:\n              responseFormat.schema != null\n                ? {\n                    type: 'json_schema',\n                    strict: strictJsonSchema,\n                    name: responseFormat.name ?? 'response',\n                    description: responseFormat.description,\n                    schema: responseFormat.schema,\n                  }\n                : { type: 'json_object' },\n          }),\n          ...(openaiOptions?.textVerbosity && {\n            verbosity: openaiOptions.textVerbosity,\n          }),\n        },\n      }),\n\n      // provider options:\n      max_tool_calls: openaiOptions?.maxToolCalls,\n      metadata: openaiOptions?.metadata,\n      parallel_tool_calls: openaiOptions?.parallelToolCalls,\n      previous_response_id: openaiOptions?.previousResponseId,\n      store,\n      user: openaiOptions?.user,\n      instructions: openaiOptions?.instructions,\n      service_tier: openaiOptions?.serviceTier,\n      include,\n      prompt_cache_key: openaiOptions?.promptCacheKey,\n      safety_identifier: openaiOptions?.safetyIdentifier,\n      top_logprobs: topLogprobs,\n      truncation: openaiOptions?.truncation,\n\n      // model-specific settings:\n      ...(modelConfig.isReasoningModel &&\n        (openaiOptions?.reasoningEffort != null ||\n          openaiOptions?.reasoningSummary != null) && {\n          reasoning: {\n            ...(openaiOptions?.reasoningEffort != null && {\n              effort: openaiOptions.reasoningEffort,\n            }),\n            ...(openaiOptions?.reasoningSummary != null && {\n              summary: openaiOptions.reasoningSummary,\n            }),\n          },\n        }),\n    };\n\n    if (modelConfig.isReasoningModel) {\n      // remove unsupported settings for reasoning models\n      // see https://platform.openai.com/docs/guides/reasoning#limitations\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details: 'temperature is not supported for reasoning models',\n        });\n      }\n\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'topP',\n          details: 'topP is not supported for reasoning models',\n        });\n      }\n    } else {\n      if (openaiOptions?.reasoningEffort != null) {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'reasoningEffort',\n          details: 'reasoningEffort is not supported for non-reasoning models',\n        });\n      }\n\n      if (openaiOptions?.reasoningSummary != null) {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'reasoningSummary',\n          details: 'reasoningSummary is not supported for non-reasoning models',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions?.serviceTier === 'flex' &&\n      !modelConfig.supportsFlexProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions?.serviceTier === 'priority' &&\n      !modelConfig.supportsPriorityProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = await prepareResponsesTools({\n      tools,\n      toolChoice,\n      strictJsonSchema,\n    });\n\n    return {\n      webSearchToolName,\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n      store,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const {\n      args: body,\n      warnings,\n      webSearchToolName,\n    } = await this.getArgs(options);\n    const url = this.config.url({\n      path: '/responses',\n      modelId: this.modelId,\n    });\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiResponsesResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    if (response.error) {\n      throw new APICallError({\n        message: response.error.message,\n        url,\n        requestBodyValues: body,\n        statusCode: 400,\n        responseHeaders,\n        responseBody: rawResponse as string,\n        isRetryable: false,\n      });\n    }\n\n    const content: Array<LanguageModelV2Content> = [];\n    const logprobs: Array<OpenAIResponsesLogprobs> = [];\n\n    // flag that checks if there have been client-side tool calls (not executed by openai)\n    let hasFunctionCall = false;\n\n    // map response content to content array\n    for (const part of response.output) {\n      switch (part.type) {\n        case 'reasoning': {\n          // when there are no summary parts, we need to add an empty reasoning part:\n          if (part.summary.length === 0) {\n            part.summary.push({ type: 'summary_text', text: '' });\n          }\n\n          for (const summary of part.summary) {\n            content.push({\n              type: 'reasoning' as const,\n              text: summary.text,\n              providerMetadata: {\n                openai: {\n                  itemId: part.id,\n                  reasoningEncryptedContent: part.encrypted_content ?? null,\n                },\n              },\n            });\n          }\n          break;\n        }\n\n        case 'image_generation_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'image_generation',\n            input: '{}',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'image_generation',\n            result: {\n              result: part.result,\n            } satisfies InferValidator<typeof imageGenerationOutputSchema>,\n            providerExecuted: true,\n          });\n\n          break;\n        }\n\n        case 'local_shell_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: 'local_shell',\n            input: JSON.stringify({\n              action: part.action,\n            } satisfies InferValidator<typeof localShellInputSchema>),\n            providerMetadata: {\n              openai: {\n                itemId: part.id,\n              },\n            },\n          });\n\n          break;\n        }\n\n        case 'message': {\n          for (const contentPart of part.content) {\n            if (\n              options.providerOptions?.openai?.logprobs &&\n              contentPart.logprobs\n            ) {\n              logprobs.push(contentPart.logprobs);\n            }\n\n            content.push({\n              type: 'text',\n              text: contentPart.text,\n              providerMetadata: {\n                openai: {\n                  itemId: part.id,\n                },\n              },\n            });\n\n            for (const annotation of contentPart.annotations) {\n              if (annotation.type === 'url_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: this.config.generateId?.() ?? generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              } else if (annotation.type === 'file_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: this.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title: annotation.quote ?? annotation.filename ?? 'Document',\n                  filename: annotation.filename ?? annotation.file_id,\n                });\n              }\n            }\n          }\n\n          break;\n        }\n\n        case 'function_call': {\n          hasFunctionCall = true;\n\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: part.name,\n            input: part.arguments,\n            providerMetadata: {\n              openai: {\n                itemId: part.id,\n              },\n            },\n          });\n          break;\n        }\n\n        case 'web_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: webSearchToolName ?? 'web_search',\n            input: JSON.stringify({}),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: webSearchToolName ?? 'web_search',\n            result: mapWebSearchOutput(part.action),\n            providerExecuted: true,\n          });\n\n          break;\n        }\n\n        case 'computer_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'computer_use',\n            input: '',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'computer_use',\n            result: {\n              type: 'computer_use_tool_result',\n              status: part.status || 'completed',\n            },\n            providerExecuted: true,\n          });\n          break;\n        }\n\n        case 'file_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'file_search',\n            input: '{}',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'file_search',\n            result: {\n              queries: part.queries,\n              results:\n                part.results?.map(result => ({\n                  attributes: result.attributes,\n                  fileId: result.file_id,\n                  filename: result.filename,\n                  score: result.score,\n                  text: result.text,\n                })) ?? null,\n            } satisfies InferValidator<typeof fileSearchOutputSchema>,\n            providerExecuted: true,\n          });\n          break;\n        }\n\n        case 'code_interpreter_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'code_interpreter',\n            input: JSON.stringify({\n              code: part.code,\n              containerId: part.container_id,\n            } satisfies InferValidator<typeof codeInterpreterInputSchema>),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'code_interpreter',\n            result: {\n              outputs: part.outputs,\n            } satisfies InferValidator<typeof codeInterpreterOutputSchema>,\n            providerExecuted: true,\n          });\n          break;\n        }\n      }\n    }\n\n    const providerMetadata: SharedV2ProviderMetadata = {\n      openai: { responseId: response.id },\n    };\n\n    if (logprobs.length > 0) {\n      providerMetadata.openai.logprobs = logprobs;\n    }\n\n    if (typeof response.service_tier === 'string') {\n      providerMetadata.openai.serviceTier = response.service_tier;\n    }\n\n    return {\n      content,\n      finishReason: mapOpenAIResponseFinishReason({\n        finishReason: response.incomplete_details?.reason,\n        hasFunctionCall,\n      }),\n      usage: {\n        inputTokens: response.usage.input_tokens,\n        outputTokens: response.usage.output_tokens,\n        totalTokens: response.usage.input_tokens + response.usage.output_tokens,\n        reasoningTokens:\n          response.usage.output_tokens_details?.reasoning_tokens ?? undefined,\n        cachedInputTokens:\n          response.usage.input_tokens_details?.cached_tokens ?? undefined,\n      },\n      request: { body },\n      response: {\n        id: response.id,\n        timestamp: new Date(response.created_at * 1000),\n        modelId: response.model,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const {\n      args: body,\n      warnings,\n      webSearchToolName,\n      store,\n    } = await this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/responses',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: {\n        ...body,\n        stream: true,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiResponsesChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const self = this;\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    const logprobs: Array<OpenAIResponsesLogprobs> = [];\n    let responseId: string | null = null;\n    const ongoingToolCalls: Record<\n      number,\n      | {\n          toolName: string;\n          toolCallId: string;\n          codeInterpreter?: {\n            containerId: string;\n          };\n        }\n      | undefined\n    > = {};\n\n    // flag that checks if there have been client-side tool calls (not executed by openai)\n    let hasFunctionCall = false;\n\n    const activeReasoning: Record<\n      string,\n      {\n        encryptedContent?: string | null;\n        // summary index as string to reasoning part state:\n        summaryParts: Record<string, 'active' | 'can-conclude' | 'concluded'>;\n      }\n    > = {};\n\n    let serviceTier: string | undefined;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<OpenAIResponsesChunk>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            if (isResponseOutputItemAddedChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: value.item.name,\n                  toolCallId: value.item.call_id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.call_id,\n                  toolName: value.item.name,\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: webSearchToolName ?? 'web_search',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: webSearchToolName ?? 'web_search',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'web_search',\n                  input: JSON.stringify({}),\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: 'computer_use',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: 'computer_use',\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'code_interpreter_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: 'code_interpreter',\n                  toolCallId: value.item.id,\n                  codeInterpreter: {\n                    containerId: value.item.container_id,\n                  },\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: 'code_interpreter',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: value.item.id,\n                  delta: `{\"containerId\":\"${value.item.container_id}\",\"code\":\"`,\n                });\n              } else if (value.item.type === 'file_search_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'file_search',\n                  input: '{}',\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'image_generation_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'image_generation',\n                  input: '{}',\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-start',\n                  id: value.item.id,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (\n                isResponseOutputItemAddedChunk(value) &&\n                value.item.type === 'reasoning'\n              ) {\n                activeReasoning[value.item.id] = {\n                  encryptedContent: value.item.encrypted_content,\n                  summaryParts: { 0: 'active' },\n                };\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item.id}:0`,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                      reasoningEncryptedContent:\n                        value.item.encrypted_content ?? null,\n                    },\n                  },\n                });\n              }\n            } else if (isResponseOutputItemDoneChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasFunctionCall = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.call_id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: value.item.name,\n                  input: value.item.arguments,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'web_search',\n                  result: mapWebSearchOutput(value.item.action),\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'computer_use',\n                  input: '',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'computer_use',\n                  result: {\n                    type: 'computer_use_tool_result',\n                    status: value.item.status || 'completed',\n                  },\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'file_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'file_search',\n                  result: {\n                    queries: value.item.queries,\n                    results:\n                      value.item.results?.map(result => ({\n                        attributes: result.attributes,\n                        fileId: result.file_id,\n                        filename: result.filename,\n                        score: result.score,\n                        text: result.text,\n                      })) ?? null,\n                  } satisfies InferValidator<typeof fileSearchOutputSchema>,\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'code_interpreter_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'code_interpreter',\n                  result: {\n                    outputs: value.item.outputs,\n                  } satisfies InferValidator<\n                    typeof codeInterpreterOutputSchema\n                  >,\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'image_generation_call') {\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'image_generation',\n                  result: {\n                    result: value.item.result,\n                  } satisfies InferValidator<\n                    typeof imageGenerationOutputSchema\n                  >,\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'local_shell_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: 'local_shell',\n                  input: JSON.stringify({\n                    action: {\n                      type: 'exec',\n                      command: value.item.action.command,\n                      timeoutMs: value.item.action.timeout_ms,\n                      user: value.item.action.user,\n                      workingDirectory: value.item.action.working_directory,\n                      env: value.item.action.env,\n                    },\n                  } satisfies InferValidator<typeof localShellInputSchema>),\n                  providerMetadata: {\n                    openai: { itemId: value.item.id },\n                  },\n                });\n              } else if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-end',\n                  id: value.item.id,\n                });\n              } else if (value.item.type === 'reasoning') {\n                const activeReasoningPart = activeReasoning[value.item.id];\n\n                // get all active or can-conclude summary parts' ids\n                // to conclude ongoing reasoning parts:\n                const summaryPartIndices = Object.entries(\n                  activeReasoningPart.summaryParts,\n                )\n                  .filter(\n                    ([_, status]) =>\n                      status === 'active' || status === 'can-conclude',\n                  )\n                  .map(([summaryIndex]) => summaryIndex);\n\n                for (const summaryIndex of summaryPartIndices) {\n                  controller.enqueue({\n                    type: 'reasoning-end',\n                    id: `${value.item.id}:${summaryIndex}`,\n                    providerMetadata: {\n                      openai: {\n                        itemId: value.item.id,\n                        reasoningEncryptedContent:\n                          value.item.encrypted_content ?? null,\n                      },\n                    },\n                  });\n                }\n\n                delete activeReasoning[value.item.id];\n              }\n            } else if (isResponseFunctionCallArgumentsDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: value.delta,\n                });\n              }\n            } else if (isResponseCodeInterpreterCallCodeDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  // The delta is code, which is embedding in a JSON string.\n                  // To escape it, we use JSON.stringify and slice to remove the outer quotes.\n                  delta: JSON.stringify(value.delta).slice(1, -1),\n                });\n              }\n            } else if (isResponseCodeInterpreterCallCodeDoneChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: '\"}',\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: toolCall.toolCallId,\n                });\n\n                // immediately send the tool call after the input end:\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: toolCall.toolCallId,\n                  toolName: 'code_interpreter',\n                  input: JSON.stringify({\n                    code: value.code,\n                    containerId: toolCall.codeInterpreter!.containerId,\n                  } satisfies InferValidator<\n                    typeof codeInterpreterInputSchema\n                  >),\n                  providerExecuted: true,\n                });\n              }\n            } else if (isResponseCreatedChunk(value)) {\n              responseId = value.response.id;\n              controller.enqueue({\n                type: 'response-metadata',\n                id: value.response.id,\n                timestamp: new Date(value.response.created_at * 1000),\n                modelId: value.response.model,\n              });\n            } else if (isTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: value.item_id,\n                delta: value.delta,\n              });\n\n              if (options.providerOptions?.openai?.logprobs && value.logprobs) {\n                logprobs.push(value.logprobs);\n              }\n            } else if (value.type === 'response.reasoning_summary_part.added') {\n              // the first reasoning start is pushed in isResponseOutputItemAddedReasoningChunk\n              if (value.summary_index > 0) {\n                const activeReasoningPart = activeReasoning[value.item_id]!;\n\n                activeReasoningPart.summaryParts[value.summary_index] =\n                  'active';\n\n                // since there is a new active summary part, we can conclude all can-conclude summary parts\n                for (const summaryIndex of Object.keys(\n                  activeReasoningPart.summaryParts,\n                )) {\n                  if (\n                    activeReasoningPart.summaryParts[summaryIndex] ===\n                    'can-conclude'\n                  ) {\n                    controller.enqueue({\n                      type: 'reasoning-end',\n                      id: `${value.item_id}:${summaryIndex}`,\n                      providerMetadata: { openai: { itemId: value.item_id } },\n                    });\n                    activeReasoningPart.summaryParts[summaryIndex] =\n                      'concluded';\n                  }\n                }\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item_id}:${value.summary_index}`,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item_id,\n                      reasoningEncryptedContent:\n                        activeReasoning[value.item_id]?.encryptedContent ??\n                        null,\n                    },\n                  },\n                });\n              }\n            } else if (value.type === 'response.reasoning_summary_text.delta') {\n              controller.enqueue({\n                type: 'reasoning-delta',\n                id: `${value.item_id}:${value.summary_index}`,\n                delta: value.delta,\n                providerMetadata: {\n                  openai: {\n                    itemId: value.item_id,\n                  },\n                },\n              });\n            } else if (value.type === 'response.reasoning_summary_part.done') {\n              // when OpenAI stores the message data, we can immediately conclude the reasoning part\n              // since we do not need to send the encrypted content.\n              if (store) {\n                controller.enqueue({\n                  type: 'reasoning-end',\n                  id: `${value.item_id}:${value.summary_index}`,\n                  providerMetadata: {\n                    openai: { itemId: value.item_id },\n                  },\n                });\n\n                // mark the summary part as concluded\n                activeReasoning[value.item_id]!.summaryParts[\n                  value.summary_index\n                ] = 'concluded';\n              } else {\n                // mark the summary part as can-conclude only\n                // because we need to have a final summary part with the encrypted content\n                activeReasoning[value.item_id]!.summaryParts[\n                  value.summary_index\n                ] = 'can-conclude';\n              }\n            } else if (isResponseFinishedChunk(value)) {\n              finishReason = mapOpenAIResponseFinishReason({\n                finishReason: value.response.incomplete_details?.reason,\n                hasFunctionCall,\n              });\n              usage.inputTokens = value.response.usage.input_tokens;\n              usage.outputTokens = value.response.usage.output_tokens;\n              usage.totalTokens =\n                value.response.usage.input_tokens +\n                value.response.usage.output_tokens;\n              usage.reasoningTokens =\n                value.response.usage.output_tokens_details?.reasoning_tokens ??\n                undefined;\n              usage.cachedInputTokens =\n                value.response.usage.input_tokens_details?.cached_tokens ??\n                undefined;\n              if (typeof value.response.service_tier === 'string') {\n                serviceTier = value.response.service_tier;\n              }\n            } else if (isResponseAnnotationAddedChunk(value)) {\n              if (value.annotation.type === 'url_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: self.config.generateId?.() ?? generateId(),\n                  url: value.annotation.url,\n                  title: value.annotation.title,\n                });\n              } else if (value.annotation.type === 'file_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: self.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title:\n                    value.annotation.quote ??\n                    value.annotation.filename ??\n                    'Document',\n                  filename:\n                    value.annotation.filename ?? value.annotation.file_id,\n                });\n              }\n            } else if (isErrorChunk(value)) {\n              controller.enqueue({ type: 'error', error: value });\n            }\n          },\n\n          flush(controller) {\n            const providerMetadata: SharedV2ProviderMetadata = {\n              openai: {\n                responseId,\n              },\n            };\n\n            if (logprobs.length > 0) {\n              providerMetadata.openai.logprobs = logprobs;\n            }\n\n            if (serviceTier !== undefined) {\n              providerMetadata.openai.serviceTier = serviceTier;\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              providerMetadata,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nfunction isTextDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.output_text.delta' } {\n  return chunk.type === 'response.output_text.delta';\n}\n\nfunction isResponseOutputItemDoneChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.output_item.done' } {\n  return chunk.type === 'response.output_item.done';\n}\n\nfunction isResponseFinishedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.completed' | 'response.incomplete';\n} {\n  return (\n    chunk.type === 'response.completed' || chunk.type === 'response.incomplete'\n  );\n}\n\nfunction isResponseCreatedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.created' } {\n  return chunk.type === 'response.created';\n}\n\nfunction isResponseFunctionCallArgumentsDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.function_call_arguments.delta';\n} {\n  return chunk.type === 'response.function_call_arguments.delta';\n}\n\nfunction isResponseCodeInterpreterCallCodeDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.code_interpreter_call_code.delta';\n} {\n  return chunk.type === 'response.code_interpreter_call_code.delta';\n}\n\nfunction isResponseCodeInterpreterCallCodeDoneChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.code_interpreter_call_code.done';\n} {\n  return chunk.type === 'response.code_interpreter_call_code.done';\n}\n\nfunction isResponseOutputItemAddedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.output_item.added' } {\n  return chunk.type === 'response.output_item.added';\n}\n\nfunction isResponseAnnotationAddedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.output_text.annotation.added';\n} {\n  return chunk.type === 'response.output_text.annotation.added';\n}\n\nfunction isErrorChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'error' } {\n  return chunk.type === 'error';\n}\n\ntype ResponsesModelConfig = {\n  isReasoningModel: boolean;\n  systemMessageMode: 'remove' | 'system' | 'developer';\n  supportsFlexProcessing: boolean;\n  supportsPriorityProcessing: boolean;\n};\n\nfunction getResponsesModelConfig(modelId: string): ResponsesModelConfig {\n  const supportsFlexProcessing =\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'));\n  const supportsPriorityProcessing =\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini');\n  const defaults = {\n    systemMessageMode: 'system' as const,\n    supportsFlexProcessing,\n    supportsPriorityProcessing,\n  };\n\n  // gpt-5-chat models are non-reasoning\n  if (modelId.startsWith('gpt-5-chat')) {\n    return {\n      ...defaults,\n      isReasoningModel: false,\n    };\n  }\n\n  // o series reasoning models:\n  if (\n    modelId.startsWith('o') ||\n    modelId.startsWith('gpt-5') ||\n    modelId.startsWith('codex-') ||\n    modelId.startsWith('computer-use')\n  ) {\n    if (modelId.startsWith('o1-mini') || modelId.startsWith('o1-preview')) {\n      return {\n        ...defaults,\n        isReasoningModel: true,\n        systemMessageMode: 'remove',\n      };\n    }\n\n    return {\n      ...defaults,\n      isReasoningModel: true,\n      systemMessageMode: 'developer',\n    };\n  }\n\n  // gpt models:\n  return {\n    ...defaults,\n    isReasoningModel: false,\n  };\n}\n\nfunction mapWebSearchOutput(\n  action: OpenAIResponsesWebSearchAction,\n): InferValidator<typeof webSearchOutputSchema> {\n  switch (action.type) {\n    case 'search':\n      return { action: { type: 'search', query: action.query ?? undefined } };\n    case 'open_page':\n      return { action: { type: 'openPage', url: action.url } };\n    case 'find':\n      return {\n        action: { type: 'find', url: action.url, pattern: action.pattern },\n      };\n  }\n}\n","import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2Prompt,\n  LanguageModelV2ToolCallPart,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  convertToBase64,\n  parseProviderOptions,\n  validateTypes,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  localShellInputSchema,\n  localShellOutputSchema,\n} from '../tool/local-shell';\nimport {\n  OpenAIResponsesFunctionCallOutput,\n  OpenAIResponsesInput,\n  OpenAIResponsesReasoning,\n} from './openai-responses-api';\n\n/**\n * Check if a string is a file ID based on the given prefixes\n * Returns false if prefixes is undefined (disables file ID detection)\n */\nfunction isFileId(data: string, prefixes?: readonly string[]): boolean {\n  if (!prefixes) return false;\n  return prefixes.some(prefix => data.startsWith(prefix));\n}\n\nexport async function convertToOpenAIResponsesInput({\n  prompt,\n  systemMessageMode,\n  fileIdPrefixes,\n  store,\n  hasLocalShellTool = false,\n}: {\n  prompt: LanguageModelV2Prompt;\n  systemMessageMode: 'system' | 'developer' | 'remove';\n  fileIdPrefixes?: readonly string[];\n  store: boolean;\n  hasLocalShellTool?: boolean;\n}): Promise<{\n  input: OpenAIResponsesInput;\n  warnings: Array<LanguageModelV2CallWarning>;\n}> {\n  const input: OpenAIResponsesInput = [];\n  const warnings: Array<LanguageModelV2CallWarning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            input.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            input.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        input.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'input_text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'input_image',\n                    ...(part.data instanceof URL\n                      ? { image_url: part.data.toString() }\n                      : typeof part.data === 'string' &&\n                          isFileId(part.data, fileIdPrefixes)\n                        ? { file_id: part.data }\n                        : {\n                            image_url: `data:${mediaType};base64,${convertToBase64(part.data)}`,\n                          }),\n                    detail: part.providerOptions?.openai?.imageDetail,\n                  };\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    return {\n                      type: 'input_file',\n                      file_url: part.data.toString(),\n                    };\n                  }\n                  return {\n                    type: 'input_file',\n                    ...(typeof part.data === 'string' &&\n                    isFileId(part.data, fileIdPrefixes)\n                      ? { file_id: part.data }\n                      : {\n                          filename: part.filename ?? `part-${index}.pdf`,\n                          file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                        }),\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        const reasoningMessages: Record<string, OpenAIResponsesReasoning> = {};\n        const toolCallParts: Record<string, LanguageModelV2ToolCallPart> = {};\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              const id = part.providerOptions?.openai?.itemId as\n                | string\n                | undefined;\n\n              // item references reduce the payload size\n              if (store && id != null) {\n                input.push({ type: 'item_reference', id });\n                break;\n              }\n\n              input.push({\n                role: 'assistant',\n                content: [{ type: 'output_text', text: part.text }],\n                id,\n              });\n\n              break;\n            }\n            case 'tool-call': {\n              toolCallParts[part.toolCallId] = part;\n\n              if (part.providerExecuted) {\n                break;\n              }\n\n              const id = part.providerOptions?.openai?.itemId as\n                | string\n                | undefined;\n\n              // item references reduce the payload size\n              if (store && id != null) {\n                input.push({ type: 'item_reference', id });\n                break;\n              }\n\n              if (hasLocalShellTool && part.toolName === 'local_shell') {\n                const parsedInput = await validateTypes({\n                  value: part.input,\n                  schema: localShellInputSchema,\n                });\n                input.push({\n                  type: 'local_shell_call',\n                  call_id: part.toolCallId,\n                  id: id!,\n                  action: {\n                    type: 'exec',\n                    command: parsedInput.action.command,\n                    timeout_ms: parsedInput.action.timeoutMs,\n                    user: parsedInput.action.user,\n                    working_directory: parsedInput.action.workingDirectory,\n                    env: parsedInput.action.env,\n                  },\n                });\n\n                break;\n              }\n\n              input.push({\n                type: 'function_call',\n                call_id: part.toolCallId,\n                name: part.toolName,\n                arguments: JSON.stringify(part.input),\n                id,\n              });\n              break;\n            }\n\n            // assistant tool result parts are from provider-executed tools:\n            case 'tool-result': {\n              if (store) {\n                // use item references to refer to tool results from built-in tools\n                input.push({ type: 'item_reference', id: part.toolCallId });\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Results for OpenAI tool ${part.toolName} are not sent to the API when store is false`,\n                });\n              }\n\n              break;\n            }\n\n            case 'reasoning': {\n              const providerOptions = await parseProviderOptions({\n                provider: 'openai',\n                providerOptions: part.providerOptions,\n                schema: openaiResponsesReasoningProviderOptionsSchema,\n              });\n\n              const reasoningId = providerOptions?.itemId;\n\n              if (reasoningId != null) {\n                const reasoningMessage = reasoningMessages[reasoningId];\n\n                if (store) {\n                  // use item references to refer to reasoning (single reference)\n                  // when the first part is encountered\n                  if (reasoningMessage === undefined) {\n                    input.push({ type: 'item_reference', id: reasoningId });\n\n                    // store unused reasoning message to mark id as used\n                    reasoningMessages[reasoningId] = {\n                      type: 'reasoning',\n                      id: reasoningId,\n                      summary: [],\n                    };\n                  }\n                } else {\n                  const summaryParts: Array<{\n                    type: 'summary_text';\n                    text: string;\n                  }> = [];\n\n                  if (part.text.length > 0) {\n                    summaryParts.push({\n                      type: 'summary_text',\n                      text: part.text,\n                    });\n                  } else if (reasoningMessage !== undefined) {\n                    warnings.push({\n                      type: 'other',\n                      message: `Cannot append empty reasoning part to existing reasoning sequence. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                    });\n                  }\n\n                  if (reasoningMessage === undefined) {\n                    reasoningMessages[reasoningId] = {\n                      type: 'reasoning',\n                      id: reasoningId,\n                      encrypted_content:\n                        providerOptions?.reasoningEncryptedContent,\n                      summary: summaryParts,\n                    };\n                    input.push(reasoningMessages[reasoningId]);\n                  } else {\n                    reasoningMessage.summary.push(...summaryParts);\n\n                    // updated encrypted content to enable setting it in the last summary part:\n                    if (providerOptions?.reasoningEncryptedContent != null) {\n                      reasoningMessage.encrypted_content =\n                        providerOptions.reasoningEncryptedContent;\n                    }\n                  }\n                }\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Non-OpenAI reasoning parts are not supported. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                });\n              }\n              break;\n            }\n          }\n        }\n\n        break;\n      }\n\n      case 'tool': {\n        for (const part of content) {\n          const output = part.output;\n\n          if (\n            hasLocalShellTool &&\n            part.toolName === 'local_shell' &&\n            output.type === 'json'\n          ) {\n            const parsedOutput = await validateTypes({\n              value: output.value,\n              schema: localShellOutputSchema,\n            });\n\n            input.push({\n              type: 'local_shell_call_output',\n              call_id: part.toolCallId,\n              output: parsedOutput.output,\n            });\n            break;\n          }\n\n          let contentValue: OpenAIResponsesFunctionCallOutput['output'];\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n            case 'content':\n              contentValue = output.value.map(item => {\n                switch (item.type) {\n                  case 'text': {\n                    return { type: 'input_text' as const, text: item.text };\n                  }\n                  case 'media': {\n                    return item.mediaType.startsWith('image/')\n                      ? {\n                          type: 'input_image' as const,\n                          image_url: `data:${item.mediaType};base64,${item.data}`,\n                        }\n                      : {\n                          type: 'input_file' as const,\n                          filename: 'data',\n                          file_data: `data:${item.mediaType};base64,${item.data}`,\n                        };\n                  }\n                }\n              });\n              break;\n          }\n\n          input.push({\n            type: 'function_call_output',\n            call_id: part.toolCallId,\n            output: contentValue,\n          });\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { input, warnings };\n}\n\nconst openaiResponsesReasoningProviderOptionsSchema = z.object({\n  itemId: z.string().nullish(),\n  reasoningEncryptedContent: z.string().nullish(),\n});\n\nexport type OpenAIResponsesReasoningProviderOptions = z.infer<\n  typeof openaiResponsesReasoningProviderOptionsSchema\n>;\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIResponseFinishReason({\n  finishReason,\n  hasFunctionCall,\n}: {\n  finishReason: string | null | undefined;\n  // flag that checks if there have been client-side tool calls (not executed by openai)\n  hasFunctionCall: boolean;\n}): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case undefined:\n    case null:\n      return hasFunctionCall ? 'tool-calls' : 'stop';\n    case 'max_output_tokens':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    default:\n      return hasFunctionCall ? 'tool-calls' : 'unknown';\n  }\n}\n","import { JSONSchema7 } from '@ai-sdk/provider';\nimport {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAIResponsesInput = Array<OpenAIResponsesInputItem>;\n\nexport type OpenAIResponsesInputItem =\n  | OpenAIResponsesSystemMessage\n  | OpenAIResponsesUserMessage\n  | OpenAIResponsesAssistantMessage\n  | OpenAIResponsesFunctionCall\n  | OpenAIResponsesFunctionCallOutput\n  | OpenAIResponsesComputerCall\n  | OpenAIResponsesLocalShellCall\n  | OpenAIResponsesLocalShellCallOutput\n  | OpenAIResponsesReasoning\n  | OpenAIResponsesItemReference;\n\nexport type OpenAIResponsesIncludeValue =\n  | 'web_search_call.action.sources'\n  | 'code_interpreter_call.outputs'\n  | 'computer_call_output.output.image_url'\n  | 'file_search_call.results'\n  | 'message.input_image.image_url'\n  | 'message.output_text.logprobs'\n  | 'reasoning.encrypted_content';\n\nexport type OpenAIResponsesIncludeOptions =\n  | Array<OpenAIResponsesIncludeValue>\n  | undefined\n  | null;\n\nexport type OpenAIResponsesSystemMessage = {\n  role: 'system' | 'developer';\n  content: string;\n};\n\nexport type OpenAIResponsesUserMessage = {\n  role: 'user';\n  content: Array<\n    | { type: 'input_text'; text: string }\n    | { type: 'input_image'; image_url: string }\n    | { type: 'input_image'; file_id: string }\n    | { type: 'input_file'; file_url: string }\n    | { type: 'input_file'; filename: string; file_data: string }\n    | { type: 'input_file'; file_id: string }\n  >;\n};\n\nexport type OpenAIResponsesAssistantMessage = {\n  role: 'assistant';\n  content: Array<{ type: 'output_text'; text: string }>;\n  id?: string;\n};\n\nexport type OpenAIResponsesFunctionCall = {\n  type: 'function_call';\n  call_id: string;\n  name: string;\n  arguments: string;\n  id?: string;\n};\n\nexport type OpenAIResponsesFunctionCallOutput = {\n  type: 'function_call_output';\n  call_id: string;\n  output:\n    | string\n    | Array<\n        | { type: 'input_text'; text: string }\n        | { type: 'input_image'; image_url: string }\n        | { type: 'input_file'; filename: string; file_data: string }\n      >;\n};\n\nexport type OpenAIResponsesComputerCall = {\n  type: 'computer_call';\n  id: string;\n  status?: string;\n};\n\nexport type OpenAIResponsesLocalShellCall = {\n  type: 'local_shell_call';\n  id: string;\n  call_id: string;\n  action: {\n    type: 'exec';\n    command: string[];\n    timeout_ms?: number;\n    user?: string;\n    working_directory?: string;\n    env?: Record<string, string>;\n  };\n};\n\nexport type OpenAIResponsesLocalShellCallOutput = {\n  type: 'local_shell_call_output';\n  call_id: string;\n  output: string;\n};\n\nexport type OpenAIResponsesItemReference = {\n  type: 'item_reference';\n  id: string;\n};\n\n/**\n * A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n */\nexport type OpenAIResponsesFileSearchToolComparisonFilter = {\n  /**\n   * The key to compare against the value.\n   */\n  key: string;\n\n  /**\n   * Specifies the comparison operator: eq, ne, gt, gte, lt, lte.\n   */\n  type: 'eq' | 'ne' | 'gt' | 'gte' | 'lt' | 'lte';\n\n  /**\n   * The value to compare against the attribute key; supports string, number, or boolean types.\n   */\n  value: string | number | boolean;\n};\n\n/**\n * Combine multiple filters using and or or.\n */\nexport type OpenAIResponsesFileSearchToolCompoundFilter = {\n  /**\n   * Type of operation: and or or.\n   */\n  type: 'and' | 'or';\n\n  /**\n   * Array of filters to combine. Items can be ComparisonFilter or CompoundFilter.\n   */\n  filters: Array<\n    | OpenAIResponsesFileSearchToolComparisonFilter\n    | OpenAIResponsesFileSearchToolCompoundFilter\n  >;\n};\n\nexport type OpenAIResponsesTool =\n  | {\n      type: 'function';\n      name: string;\n      description: string | undefined;\n      parameters: JSONSchema7;\n      strict: boolean | undefined;\n    }\n  | {\n      type: 'web_search';\n      filters: { allowed_domains: string[] | undefined } | undefined;\n      search_context_size: 'low' | 'medium' | 'high' | undefined;\n      user_location:\n        | {\n            type: 'approximate';\n            city?: string;\n            country?: string;\n            region?: string;\n            timezone?: string;\n          }\n        | undefined;\n    }\n  | {\n      type: 'web_search_preview';\n      search_context_size: 'low' | 'medium' | 'high' | undefined;\n      user_location:\n        | {\n            type: 'approximate';\n            city?: string;\n            country?: string;\n            region?: string;\n            timezone?: string;\n          }\n        | undefined;\n    }\n  | {\n      type: 'code_interpreter';\n      container: string | { type: 'auto'; file_ids: string[] | undefined };\n    }\n  | {\n      type: 'file_search';\n      vector_store_ids: string[];\n      max_num_results: number | undefined;\n      ranking_options:\n        | { ranker?: string; score_threshold?: number }\n        | undefined;\n      filters:\n        | OpenAIResponsesFileSearchToolComparisonFilter\n        | OpenAIResponsesFileSearchToolCompoundFilter\n        | undefined;\n    }\n  | {\n      type: 'image_generation';\n      background: 'auto' | 'opaque' | 'transparent' | undefined;\n      input_fidelity: 'low' | 'high' | undefined;\n      input_image_mask:\n        | {\n            file_id: string | undefined;\n            image_url: string | undefined;\n          }\n        | undefined;\n      model: string | undefined;\n      moderation: 'auto' | undefined;\n      output_compression: number | undefined;\n      output_format: 'png' | 'jpeg' | 'webp' | undefined;\n      quality: 'auto' | 'low' | 'medium' | 'high' | undefined;\n      size: 'auto' | '1024x1024' | '1024x1536' | '1536x1024' | undefined;\n    }\n  | {\n      type: 'local_shell';\n    };\n\nexport type OpenAIResponsesReasoning = {\n  type: 'reasoning';\n  id: string;\n  encrypted_content?: string | null;\n  summary: Array<{\n    type: 'summary_text';\n    text: string;\n  }>;\n};\n\nexport const openaiResponsesChunkSchema = lazyValidator(() =>\n  zodSchema(\n    z.union([\n      z.object({\n        type: z.literal('response.output_text.delta'),\n        item_id: z.string(),\n        delta: z.string(),\n        logprobs: z\n          .array(\n            z.object({\n              token: z.string(),\n              logprob: z.number(),\n              top_logprobs: z.array(\n                z.object({\n                  token: z.string(),\n                  logprob: z.number(),\n                }),\n              ),\n            }),\n          )\n          .nullish(),\n      }),\n      z.object({\n        type: z.enum(['response.completed', 'response.incomplete']),\n        response: z.object({\n          incomplete_details: z.object({ reason: z.string() }).nullish(),\n          usage: z.object({\n            input_tokens: z.number(),\n            input_tokens_details: z\n              .object({ cached_tokens: z.number().nullish() })\n              .nullish(),\n            output_tokens: z.number(),\n            output_tokens_details: z\n              .object({ reasoning_tokens: z.number().nullish() })\n              .nullish(),\n          }),\n          service_tier: z.string().nullish(),\n        }),\n      }),\n      z.object({\n        type: z.literal('response.created'),\n        response: z.object({\n          id: z.string(),\n          created_at: z.number(),\n          model: z.string(),\n          service_tier: z.string().nullish(),\n        }),\n      }),\n      z.object({\n        type: z.literal('response.output_item.added'),\n        output_index: z.number(),\n        item: z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('message'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('reasoning'),\n            id: z.string(),\n            encrypted_content: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('function_call'),\n            id: z.string(),\n            call_id: z.string(),\n            name: z.string(),\n            arguments: z.string(),\n          }),\n          z.object({\n            type: z.literal('web_search_call'),\n            id: z.string(),\n            status: z.string(),\n          }),\n          z.object({\n            type: z.literal('computer_call'),\n            id: z.string(),\n            status: z.string(),\n          }),\n          z.object({\n            type: z.literal('file_search_call'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('image_generation_call'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('code_interpreter_call'),\n            id: z.string(),\n            container_id: z.string(),\n            code: z.string().nullable(),\n            outputs: z\n              .array(\n                z.discriminatedUnion('type', [\n                  z.object({ type: z.literal('logs'), logs: z.string() }),\n                  z.object({ type: z.literal('image'), url: z.string() }),\n                ]),\n              )\n              .nullable(),\n            status: z.string(),\n          }),\n        ]),\n      }),\n      z.object({\n        type: z.literal('response.output_item.done'),\n        output_index: z.number(),\n        item: z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('message'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('reasoning'),\n            id: z.string(),\n            encrypted_content: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('function_call'),\n            id: z.string(),\n            call_id: z.string(),\n            name: z.string(),\n            arguments: z.string(),\n            status: z.literal('completed'),\n          }),\n          z.object({\n            type: z.literal('code_interpreter_call'),\n            id: z.string(),\n            code: z.string().nullable(),\n            container_id: z.string(),\n            outputs: z\n              .array(\n                z.discriminatedUnion('type', [\n                  z.object({ type: z.literal('logs'), logs: z.string() }),\n                  z.object({ type: z.literal('image'), url: z.string() }),\n                ]),\n              )\n              .nullable(),\n          }),\n          z.object({\n            type: z.literal('image_generation_call'),\n            id: z.string(),\n            result: z.string(),\n          }),\n          z.object({\n            type: z.literal('web_search_call'),\n            id: z.string(),\n            status: z.string(),\n            action: z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('search'),\n                query: z.string().nullish(),\n              }),\n              z.object({\n                type: z.literal('open_page'),\n                url: z.string(),\n              }),\n              z.object({\n                type: z.literal('find'),\n                url: z.string(),\n                pattern: z.string(),\n              }),\n            ]),\n          }),\n          z.object({\n            type: z.literal('file_search_call'),\n            id: z.string(),\n            queries: z.array(z.string()),\n            results: z\n              .array(\n                z.object({\n                  attributes: z.record(z.string(), z.unknown()),\n                  file_id: z.string(),\n                  filename: z.string(),\n                  score: z.number(),\n                  text: z.string(),\n                }),\n              )\n              .nullish(),\n          }),\n          z.object({\n            type: z.literal('local_shell_call'),\n            id: z.string(),\n            call_id: z.string(),\n            action: z.object({\n              type: z.literal('exec'),\n              command: z.array(z.string()),\n              timeout_ms: z.number().optional(),\n              user: z.string().optional(),\n              working_directory: z.string().optional(),\n              env: z.record(z.string(), z.string()).optional(),\n            }),\n          }),\n          z.object({\n            type: z.literal('computer_call'),\n            id: z.string(),\n            status: z.literal('completed'),\n          }),\n        ]),\n      }),\n      z.object({\n        type: z.literal('response.function_call_arguments.delta'),\n        item_id: z.string(),\n        output_index: z.number(),\n        delta: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.image_generation_call.partial_image'),\n        item_id: z.string(),\n        output_index: z.number(),\n        partial_image_b64: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.code_interpreter_call_code.delta'),\n        item_id: z.string(),\n        output_index: z.number(),\n        delta: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.code_interpreter_call_code.done'),\n        item_id: z.string(),\n        output_index: z.number(),\n        code: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.output_text.annotation.added'),\n        annotation: z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('url_citation'),\n            url: z.string(),\n            title: z.string(),\n          }),\n          z.object({\n            type: z.literal('file_citation'),\n            file_id: z.string(),\n            filename: z.string().nullish(),\n            index: z.number().nullish(),\n            start_index: z.number().nullish(),\n            end_index: z.number().nullish(),\n            quote: z.string().nullish(),\n          }),\n        ]),\n      }),\n      z.object({\n        type: z.literal('response.reasoning_summary_part.added'),\n        item_id: z.string(),\n        summary_index: z.number(),\n      }),\n      z.object({\n        type: z.literal('response.reasoning_summary_text.delta'),\n        item_id: z.string(),\n        summary_index: z.number(),\n        delta: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.reasoning_summary_part.done'),\n        item_id: z.string(),\n        summary_index: z.number(),\n      }),\n      z.object({\n        type: z.literal('error'),\n        code: z.string(),\n        message: z.string(),\n        param: z.string().nullish(),\n        sequence_number: z.number(),\n      }),\n      z\n        .object({ type: z.string() })\n        .loose()\n        .transform(value => ({\n          type: 'unknown_chunk' as const,\n          message: value.type,\n        })), // fallback for unknown chunks\n    ]),\n  ),\n);\n\nexport type OpenAIResponsesChunk = InferValidator<\n  typeof openaiResponsesChunkSchema\n>;\n\nexport type OpenAIResponsesLogprobs = NonNullable<\n  (OpenAIResponsesChunk & {\n    type: 'response.output_text.delta';\n  })['logprobs']\n> | null;\n\nexport type OpenAIResponsesWebSearchAction = NonNullable<\n  ((OpenAIResponsesChunk & {\n    type: 'response.output_item.done';\n  })['item'] & {\n    type: 'web_search_call';\n  })['action']\n>;\n\nexport const openaiResponsesResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      id: z.string(),\n      created_at: z.number(),\n      error: z\n        .object({\n          code: z.string(),\n          message: z.string(),\n        })\n        .nullish(),\n      model: z.string(),\n      output: z.array(\n        z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('message'),\n            role: z.literal('assistant'),\n            id: z.string(),\n            content: z.array(\n              z.object({\n                type: z.literal('output_text'),\n                text: z.string(),\n                logprobs: z\n                  .array(\n                    z.object({\n                      token: z.string(),\n                      logprob: z.number(),\n                      top_logprobs: z.array(\n                        z.object({\n                          token: z.string(),\n                          logprob: z.number(),\n                        }),\n                      ),\n                    }),\n                  )\n                  .nullish(),\n                annotations: z.array(\n                  z.discriminatedUnion('type', [\n                    z.object({\n                      type: z.literal('url_citation'),\n                      start_index: z.number(),\n                      end_index: z.number(),\n                      url: z.string(),\n                      title: z.string(),\n                    }),\n                    z.object({\n                      type: z.literal('file_citation'),\n                      file_id: z.string(),\n                      filename: z.string().nullish(),\n                      index: z.number().nullish(),\n                      start_index: z.number().nullish(),\n                      end_index: z.number().nullish(),\n                      quote: z.string().nullish(),\n                    }),\n                    z.object({\n                      type: z.literal('container_file_citation'),\n                    }),\n                  ]),\n                ),\n              }),\n            ),\n          }),\n          z.object({\n            type: z.literal('web_search_call'),\n            id: z.string(),\n            status: z.string(),\n            action: z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('search'),\n                query: z.string().nullish(),\n              }),\n              z.object({\n                type: z.literal('open_page'),\n                url: z.string(),\n              }),\n              z.object({\n                type: z.literal('find'),\n                url: z.string(),\n                pattern: z.string(),\n              }),\n            ]),\n          }),\n          z.object({\n            type: z.literal('file_search_call'),\n            id: z.string(),\n            queries: z.array(z.string()),\n            results: z\n              .array(\n                z.object({\n                  attributes: z.record(z.string(), z.unknown()),\n                  file_id: z.string(),\n                  filename: z.string(),\n                  score: z.number(),\n                  text: z.string(),\n                }),\n              )\n              .nullish(),\n          }),\n          z.object({\n            type: z.literal('code_interpreter_call'),\n            id: z.string(),\n            code: z.string().nullable(),\n            container_id: z.string(),\n            outputs: z\n              .array(\n                z.discriminatedUnion('type', [\n                  z.object({ type: z.literal('logs'), logs: z.string() }),\n                  z.object({ type: z.literal('image'), url: z.string() }),\n                ]),\n              )\n              .nullable(),\n          }),\n          z.object({\n            type: z.literal('image_generation_call'),\n            id: z.string(),\n            result: z.string(),\n          }),\n          z.object({\n            type: z.literal('local_shell_call'),\n            id: z.string(),\n            call_id: z.string(),\n            action: z.object({\n              type: z.literal('exec'),\n              command: z.array(z.string()),\n              timeout_ms: z.number().optional(),\n              user: z.string().optional(),\n              working_directory: z.string().optional(),\n              env: z.record(z.string(), z.string()).optional(),\n            }),\n          }),\n          z.object({\n            type: z.literal('function_call'),\n            call_id: z.string(),\n            name: z.string(),\n            arguments: z.string(),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('computer_call'),\n            id: z.string(),\n            status: z.string().optional(),\n          }),\n          z.object({\n            type: z.literal('reasoning'),\n            id: z.string(),\n            encrypted_content: z.string().nullish(),\n            summary: z.array(\n              z.object({\n                type: z.literal('summary_text'),\n                text: z.string(),\n              }),\n            ),\n          }),\n        ]),\n      ),\n      service_tier: z.string().nullish(),\n      incomplete_details: z.object({ reason: z.string() }).nullish(),\n      usage: z.object({\n        input_tokens: z.number(),\n        input_tokens_details: z\n          .object({ cached_tokens: z.number().nullish() })\n          .nullish(),\n        output_tokens: z.number(),\n        output_tokens_details: z\n          .object({ reasoning_tokens: z.number().nullish() })\n          .nullish(),\n      }),\n    }),\n  ),\n);\n","import {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/**\n * `top_logprobs` request body argument can be set to an integer between\n * 0 and 20 specifying the number of most likely tokens to return at each\n * token position, each with an associated log probability.\n *\n * @see https://platform.openai.com/docs/api-reference/responses/create#responses_create-top_logprobs\n */\nexport const TOP_LOGPROBS_MAX = 20;\n\nexport const openaiResponsesReasoningModelIds = [\n  'o1',\n  'o1-2024-12-17',\n  'o3-mini',\n  'o3-mini-2025-01-31',\n  'o3',\n  'o3-2025-04-16',\n  'o4-mini',\n  'o4-mini-2025-04-16',\n  'codex-mini-latest',\n  'computer-use-preview',\n  'gpt-5',\n  'gpt-5-2025-08-07',\n  'gpt-5-codex',\n  'gpt-5-mini',\n  'gpt-5-mini-2025-08-07',\n  'gpt-5-nano',\n  'gpt-5-nano-2025-08-07',\n  'gpt-5-pro',\n  'gpt-5-pro-2025-10-06',\n] as const;\n\nexport const openaiResponsesModelIds = [\n  'gpt-4.1',\n  'gpt-4.1-2025-04-14',\n  'gpt-4.1-mini',\n  'gpt-4.1-mini-2025-04-14',\n  'gpt-4.1-nano',\n  'gpt-4.1-nano-2025-04-14',\n  'gpt-4o',\n  'gpt-4o-2024-05-13',\n  'gpt-4o-2024-08-06',\n  'gpt-4o-2024-11-20',\n  'gpt-4o-audio-preview',\n  'gpt-4o-audio-preview-2024-10-01',\n  'gpt-4o-audio-preview-2024-12-17',\n  'gpt-4o-search-preview',\n  'gpt-4o-search-preview-2025-03-11',\n  'gpt-4o-mini-search-preview',\n  'gpt-4o-mini-search-preview-2025-03-11',\n  'gpt-4o-mini',\n  'gpt-4o-mini-2024-07-18',\n  'gpt-4-turbo',\n  'gpt-4-turbo-2024-04-09',\n  'gpt-4-turbo-preview',\n  'gpt-4-0125-preview',\n  'gpt-4-1106-preview',\n  'gpt-4',\n  'gpt-4-0613',\n  'gpt-4.5-preview',\n  'gpt-4.5-preview-2025-02-27',\n  'gpt-3.5-turbo-0125',\n  'gpt-3.5-turbo',\n  'gpt-3.5-turbo-1106',\n  'chatgpt-4o-latest',\n  'gpt-5-chat-latest',\n  ...openaiResponsesReasoningModelIds,\n] as const;\n\nexport type OpenAIResponsesModelId =\n  | 'chatgpt-4o-latest'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo-1106'\n  | 'gpt-3.5-turbo'\n  | 'gpt-4-0613'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4-turbo'\n  | 'gpt-4.1-2025-04-14'\n  | 'gpt-4.1-mini-2025-04-14'\n  | 'gpt-4.1-mini'\n  | 'gpt-4.1-nano-2025-04-14'\n  | 'gpt-4.1-nano'\n  | 'gpt-4.1'\n  | 'gpt-4'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4o-mini'\n  | 'gpt-4o'\n  | 'gpt-5-2025-08-07'\n  | 'gpt-5-chat-latest'\n  | 'gpt-5-codex'\n  | 'gpt-5-mini-2025-08-07'\n  | 'gpt-5-mini'\n  | 'gpt-5-nano-2025-08-07'\n  | 'gpt-5-nano'\n  | 'gpt-5-pro-2025-10-06'\n  | 'gpt-5-pro'\n  | 'gpt-5'\n  | 'o1-2024-12-17'\n  | 'o1'\n  | 'o3-2025-04-16'\n  | 'o3-mini-2025-01-31'\n  | 'o3-mini'\n  | 'o3'\n  | (string & {});\n\n// TODO AI SDK 6: use optional here instead of nullish\nexport const openaiResponsesProviderOptionsSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      include: z\n        .array(\n          z.enum([\n            'reasoning.encrypted_content', // handled internally by default, only needed for unknown reasoning models\n            'file_search_call.results',\n            'message.output_text.logprobs',\n          ]),\n        )\n        .nullish(),\n      instructions: z.string().nullish(),\n\n      /**\n       * Return the log probabilities of the tokens.\n       *\n       * Setting to true will return the log probabilities of the tokens that\n       * were generated.\n       *\n       * Setting to a number will return the log probabilities of the top n\n       * tokens that were generated.\n       *\n       * @see https://platform.openai.com/docs/api-reference/responses/create\n       * @see https://cookbook.openai.com/examples/using_logprobs\n       */\n      logprobs: z\n        .union([z.boolean(), z.number().min(1).max(TOP_LOGPROBS_MAX)])\n        .optional(),\n\n      /**\n       * The maximum number of total calls to built-in tools that can be processed in a response.\n       * This maximum number applies across all built-in tool calls, not per individual tool.\n       * Any further attempts to call a tool by the model will be ignored.\n       */\n      maxToolCalls: z.number().nullish(),\n\n      metadata: z.any().nullish(),\n      parallelToolCalls: z.boolean().nullish(),\n      previousResponseId: z.string().nullish(),\n      promptCacheKey: z.string().nullish(),\n      reasoningEffort: z.string().nullish(),\n      reasoningSummary: z.string().nullish(),\n      safetyIdentifier: z.string().nullish(),\n      serviceTier: z.enum(['auto', 'flex', 'priority', 'default']).nullish(),\n      store: z.boolean().nullish(),\n      strictJsonSchema: z.boolean().nullish(),\n      textVerbosity: z.enum(['low', 'medium', 'high']).nullish(),\n      truncation: z.enum(['auto', 'disabled']).nullish(),\n      user: z.string().nullish(),\n    }),\n  ),\n);\n\nexport type OpenAIResponsesProviderOptions = InferValidator<\n  typeof openaiResponsesProviderOptionsSchema\n>;\n","import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { codeInterpreterArgsSchema } from '../tool/code-interpreter';\nimport { fileSearchArgsSchema } from '../tool/file-search';\nimport { webSearchArgsSchema } from '../tool/web-search';\nimport { webSearchPreviewArgsSchema } from '../tool/web-search-preview';\nimport { imageGenerationArgsSchema } from '../tool/image-generation';\nimport { OpenAIResponsesTool } from './openai-responses-api';\nimport { validateTypes } from '@ai-sdk/provider-utils';\n\nexport async function prepareResponsesTools({\n  tools,\n  toolChoice,\n  strictJsonSchema,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  strictJsonSchema: boolean;\n}): Promise<{\n  tools?: Array<OpenAIResponsesTool>;\n  toolChoice?:\n    | 'auto'\n    | 'none'\n    | 'required'\n    | { type: 'file_search' }\n    | { type: 'web_search_preview' }\n    | { type: 'web_search' }\n    | { type: 'function'; name: string }\n    | { type: 'code_interpreter' }\n    | { type: 'image_generation' };\n  toolWarnings: LanguageModelV2CallWarning[];\n}> {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: Array<OpenAIResponsesTool> = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.inputSchema,\n          strict: strictJsonSchema,\n        });\n        break;\n      case 'provider-defined': {\n        switch (tool.id) {\n          case 'openai.file_search': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: fileSearchArgsSchema,\n            });\n\n            openaiTools.push({\n              type: 'file_search',\n              vector_store_ids: args.vectorStoreIds,\n              max_num_results: args.maxNumResults,\n              ranking_options: args.ranking\n                ? {\n                    ranker: args.ranking.ranker,\n                    score_threshold: args.ranking.scoreThreshold,\n                  }\n                : undefined,\n              filters: args.filters,\n            });\n\n            break;\n          }\n          case 'openai.local_shell': {\n            openaiTools.push({\n              type: 'local_shell',\n            });\n            break;\n          }\n          case 'openai.web_search_preview': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: webSearchPreviewArgsSchema,\n            });\n            openaiTools.push({\n              type: 'web_search_preview',\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.web_search': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: webSearchArgsSchema,\n            });\n            openaiTools.push({\n              type: 'web_search',\n              filters:\n                args.filters != null\n                  ? { allowed_domains: args.filters.allowedDomains }\n                  : undefined,\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.code_interpreter': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: codeInterpreterArgsSchema,\n            });\n\n            openaiTools.push({\n              type: 'code_interpreter',\n              container:\n                args.container == null\n                  ? { type: 'auto', file_ids: undefined }\n                  : typeof args.container === 'string'\n                    ? args.container\n                    : { type: 'auto', file_ids: args.container.fileIds },\n            });\n            break;\n          }\n          case 'openai.image_generation': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: imageGenerationArgsSchema,\n            });\n\n            openaiTools.push({\n              type: 'image_generation',\n              background: args.background,\n              input_fidelity: args.inputFidelity,\n              input_image_mask: args.inputImageMask\n                ? {\n                    file_id: args.inputImageMask.fileId,\n                    image_url: args.inputImageMask.imageUrl,\n                  }\n                : undefined,\n              model: args.model,\n              size: args.size,\n              quality: args.quality,\n              moderation: args.moderation,\n              output_format: args.outputFormat,\n              output_compression: args.outputCompression,\n            });\n            break;\n          }\n        }\n        break;\n      }\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice:\n          toolChoice.toolName === 'code_interpreter' ||\n          toolChoice.toolName === 'file_search' ||\n          toolChoice.toolName === 'image_generation' ||\n          toolChoice.toolName === 'web_search_preview' ||\n          toolChoice.toolName === 'web_search'\n            ? { type: toolChoice.toolName }\n            : { type: 'function', name: toolChoice.toolName },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import { SpeechModelV2, SpeechModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createBinaryResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { OpenAISpeechAPITypes } from './openai-speech-api';\nimport {\n  openaiSpeechProviderOptionsSchema,\n  OpenAISpeechModelId,\n} from './openai-speech-options';\n\ninterface OpenAISpeechModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAISpeechModel implements SpeechModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAISpeechModelId,\n    private readonly config: OpenAISpeechModelConfig,\n  ) {}\n\n  private async getArgs({\n    text,\n    voice = 'alloy',\n    outputFormat = 'mp3',\n    speed,\n    instructions,\n    language,\n    providerOptions,\n  }: Parameters<SpeechModelV2['doGenerate']>[0]) {\n    const warnings: SpeechModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openaiSpeechProviderOptionsSchema,\n    });\n\n    // Create request body\n    const requestBody: Record<string, unknown> = {\n      model: this.modelId,\n      input: text,\n      voice,\n      response_format: 'mp3',\n      speed,\n      instructions,\n    };\n\n    if (outputFormat) {\n      if (['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'].includes(outputFormat)) {\n        requestBody.response_format = outputFormat;\n      } else {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'outputFormat',\n          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`,\n        });\n      }\n    }\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const speechModelOptions: OpenAISpeechAPITypes = {};\n\n      for (const key in speechModelOptions) {\n        const value = speechModelOptions[key as keyof OpenAISpeechAPITypes];\n        if (value !== undefined) {\n          requestBody[key] = value;\n        }\n      }\n    }\n\n    if (language) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'language',\n        details: `OpenAI speech models do not support language selection. Language parameter \"${language}\" was ignored.`,\n      });\n    }\n\n    return {\n      requestBody,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<SpeechModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<SpeechModelV2['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { requestBody, warnings } = await this.getArgs(options);\n\n    const {\n      value: audio,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/audio/speech',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: requestBody,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createBinaryResponseHandler(),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      audio,\n      warnings,\n      request: {\n        body: JSON.stringify(requestBody),\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n","import {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAISpeechModelId =\n  | 'tts-1'\n  | 'tts-1-hd'\n  | 'gpt-4o-mini-tts'\n  | (string & {});\n\n// https://platform.openai.com/docs/api-reference/audio/createSpeech\nexport const openaiSpeechProviderOptionsSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      instructions: z.string().nullish(),\n      speed: z.number().min(0.25).max(4.0).default(1.0).nullish(),\n    }),\n  ),\n);\n\nexport type OpenAISpeechCallOptions = InferValidator<\n  typeof openaiSpeechProviderOptionsSchema\n>;\n","import {\n  TranscriptionModelV2,\n  TranscriptionModelV2CallOptions,\n  TranscriptionModelV2CallWarning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  convertBase64ToUint8Array,\n  createJsonResponseHandler,\n  mediaTypeToExtension,\n  parseProviderOptions,\n  postFormDataToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { openaiTranscriptionResponseSchema } from './openai-transcription-api';\nimport {\n  OpenAITranscriptionModelId,\n  openAITranscriptionProviderOptions,\n  OpenAITranscriptionProviderOptions,\n} from './openai-transcription-options';\n\nexport type OpenAITranscriptionCallOptions = Omit<\n  TranscriptionModelV2CallOptions,\n  'providerOptions'\n> & {\n  providerOptions?: {\n    openai?: OpenAITranscriptionProviderOptions;\n  };\n};\n\ninterface OpenAITranscriptionModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\n// https://platform.openai.com/docs/guides/speech-to-text#supported-languages\nconst languageMap = {\n  afrikaans: 'af',\n  arabic: 'ar',\n  armenian: 'hy',\n  azerbaijani: 'az',\n  belarusian: 'be',\n  bosnian: 'bs',\n  bulgarian: 'bg',\n  catalan: 'ca',\n  chinese: 'zh',\n  croatian: 'hr',\n  czech: 'cs',\n  danish: 'da',\n  dutch: 'nl',\n  english: 'en',\n  estonian: 'et',\n  finnish: 'fi',\n  french: 'fr',\n  galician: 'gl',\n  german: 'de',\n  greek: 'el',\n  hebrew: 'he',\n  hindi: 'hi',\n  hungarian: 'hu',\n  icelandic: 'is',\n  indonesian: 'id',\n  italian: 'it',\n  japanese: 'ja',\n  kannada: 'kn',\n  kazakh: 'kk',\n  korean: 'ko',\n  latvian: 'lv',\n  lithuanian: 'lt',\n  macedonian: 'mk',\n  malay: 'ms',\n  marathi: 'mr',\n  maori: 'mi',\n  nepali: 'ne',\n  norwegian: 'no',\n  persian: 'fa',\n  polish: 'pl',\n  portuguese: 'pt',\n  romanian: 'ro',\n  russian: 'ru',\n  serbian: 'sr',\n  slovak: 'sk',\n  slovenian: 'sl',\n  spanish: 'es',\n  swahili: 'sw',\n  swedish: 'sv',\n  tagalog: 'tl',\n  tamil: 'ta',\n  thai: 'th',\n  turkish: 'tr',\n  ukrainian: 'uk',\n  urdu: 'ur',\n  vietnamese: 'vi',\n  welsh: 'cy',\n};\n\nexport class OpenAITranscriptionModel implements TranscriptionModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAITranscriptionModelId,\n    private readonly config: OpenAITranscriptionModelConfig,\n  ) {}\n\n  private async getArgs({\n    audio,\n    mediaType,\n    providerOptions,\n  }: OpenAITranscriptionCallOptions) {\n    const warnings: TranscriptionModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openAITranscriptionProviderOptions,\n    });\n\n    // Create form data with base fields\n    const formData = new FormData();\n    const blob =\n      audio instanceof Uint8Array\n        ? new Blob([audio])\n        : new Blob([convertBase64ToUint8Array(audio)]);\n\n    formData.append('model', this.modelId);\n    const fileExtension = mediaTypeToExtension(mediaType);\n    formData.append(\n      'file',\n      new File([blob], 'audio', { type: mediaType }),\n      `audio.${fileExtension}`,\n    );\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const transcriptionModelOptions = {\n        include: openAIOptions.include,\n        language: openAIOptions.language,\n        prompt: openAIOptions.prompt,\n        // https://platform.openai.com/docs/api-reference/audio/createTranscription#audio_createtranscription-response_format\n        // prefer verbose_json to get segments for models that support it\n        response_format: [\n          'gpt-4o-transcribe',\n          'gpt-4o-mini-transcribe',\n        ].includes(this.modelId)\n          ? 'json'\n          : 'verbose_json',\n        temperature: openAIOptions.temperature,\n        timestamp_granularities: openAIOptions.timestampGranularities,\n      };\n\n      for (const [key, value] of Object.entries(transcriptionModelOptions)) {\n        if (value != null) {\n          if (Array.isArray(value)) {\n            for (const item of value) {\n              formData.append(`${key}[]`, String(item));\n            }\n          } else {\n            formData.append(key, String(value));\n          }\n        }\n      }\n    }\n\n    return {\n      formData,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: OpenAITranscriptionCallOptions,\n  ): Promise<Awaited<ReturnType<TranscriptionModelV2['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { formData, warnings } = await this.getArgs(options);\n\n    const {\n      value: response,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postFormDataToApi({\n      url: this.config.url({\n        path: '/audio/transcriptions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      formData,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTranscriptionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const language =\n      response.language != null && response.language in languageMap\n        ? languageMap[response.language as keyof typeof languageMap]\n        : undefined;\n\n    return {\n      text: response.text,\n      segments:\n        response.segments?.map(segment => ({\n          text: segment.text,\n          startSecond: segment.start,\n          endSecond: segment.end,\n        })) ??\n        response.words?.map(word => ({\n          text: word.word,\n          startSecond: word.start,\n          endSecond: word.end,\n        })) ??\n        [],\n      language,\n      durationInSeconds: response.duration ?? undefined,\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n","import { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const openaiTranscriptionResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      text: z.string(),\n      language: z.string().nullish(),\n      duration: z.number().nullish(),\n      words: z\n        .array(\n          z.object({\n            word: z.string(),\n            start: z.number(),\n            end: z.number(),\n          }),\n        )\n        .nullish(),\n      segments: z\n        .array(\n          z.object({\n            id: z.number(),\n            seek: z.number(),\n            start: z.number(),\n            end: z.number(),\n            text: z.string(),\n            tokens: z.array(z.number()),\n            temperature: z.number(),\n            avg_logprob: z.number(),\n            compression_ratio: z.number(),\n            no_speech_prob: z.number(),\n          }),\n        )\n        .nullish(),\n    }),\n  ),\n);\n","import {\n  InferValidator,\n  lazyValidator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAITranscriptionModelId =\n  | 'whisper-1'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-transcribe'\n  | (string & {});\n\n// https://platform.openai.com/docs/api-reference/audio/createTranscription\nexport const openAITranscriptionProviderOptions = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      /**\n       * Additional information to include in the transcription response.\n       */\n\n      include: z.array(z.string()).optional(),\n\n      /**\n       * The language of the input audio in ISO-639-1 format.\n       */\n      language: z.string().optional(),\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio segment.\n       */\n      prompt: z.string().optional(),\n\n      /**\n       * The sampling temperature, between 0 and 1.\n       * @default 0\n       */\n      temperature: z.number().min(0).max(1).default(0).optional(),\n\n      /**\n       * The timestamp granularities to populate for this transcription.\n       * @default ['segment']\n       */\n      timestampGranularities: z\n        .array(z.enum(['word', 'segment']))\n        .default(['segment'])\n        .optional(),\n    }),\n  ),\n);\n\nexport type OpenAITranscriptionProviderOptions = InferValidator<\n  typeof openAITranscriptionProviderOptions\n>;\n","// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACQA,IAAAA,0BAMO;;;ACdP,IAAAC,mBAUO;AACP,IAAAC,yBAUO;;;ACrBP,gBAAkB;AAClB,4BAA+C;AAExC,IAAM,wBAAwB,YAAE,OAAO;AAAA,EAC5C,OAAO,YAAE,OAAO;AAAA,IACd,SAAS,YAAE,OAAO;AAAA;AAAA;AAAA;AAAA,IAKlB,MAAM,YAAE,OAAO,EAAE,QAAQ;AAAA,IACzB,OAAO,YAAE,IAAI,EAAE,QAAQ;AAAA,IACvB,MAAM,YAAE,MAAM,CAAC,YAAE,OAAO,GAAG,YAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;AAAA,EAClD,CAAC;AACH,CAAC;AAIM,IAAM,kCAA8B,sDAA+B;AAAA,EACxE,aAAa;AAAA,EACb,gBAAgB,UAAQ,KAAK,MAAM;AACrC,CAAC;;;ACrBD,sBAIO;AAEP,IAAAC,yBAAgC;AAEzB,SAAS,4BAA4B;AAAA,EAC1C;AAAA,EACA,oBAAoB;AACtB,GAME;AACA,QAAM,WAA6B,CAAC;AACpC,QAAM,WAA8C,CAAC;AAErD,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;AAAA,MACZ,KAAK,UAAU;AACb,gBAAQ,mBAAmB;AAAA,UACzB,KAAK,UAAU;AACb,qBAAS,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACzC;AAAA,UACF;AAAA,UACA,KAAK,aAAa;AAChB,qBAAS,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AAC5C;AAAA,UACF;AAAA,UACA,KAAK,UAAU;AACb,qBAAS,KAAK;AAAA,cACZ,MAAM;AAAA,cACN,SAAS;AAAA,YACX,CAAC;AACD;AAAA,UACF;AAAA,UACA,SAAS;AACP,kBAAM,mBAA0B;AAChC,kBAAM,IAAI;AAAA,cACR,oCAAoC,gBAAgB;AAAA,YACtD;AAAA,UACF;AAAA,QACF;AACA;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,YAAI,QAAQ,WAAW,KAAK,QAAQ,CAAC,EAAE,SAAS,QAAQ;AACtD,mBAAS,KAAK,EAAE,MAAM,QAAQ,SAAS,QAAQ,CAAC,EAAE,KAAK,CAAC;AACxD;AAAA,QACF;AAEA,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS,QAAQ,IAAI,CAAC,MAAM,UAAU;AA1DhD;AA2DY,oBAAQ,KAAK,MAAM;AAAA,cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,QAAQ,MAAM,KAAK,KAAK;AAAA,cACzC;AAAA,cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,UAAU,WAAW,QAAQ,GAAG;AACvC,wBAAM,YACJ,KAAK,cAAc,YACf,eACA,KAAK;AAEX,yBAAO;AAAA,oBACL,MAAM;AAAA,oBACN,WAAW;AAAA,sBACT,KACE,KAAK,gBAAgB,MACjB,KAAK,KAAK,SAAS,IACnB,QAAQ,SAAS,eAAW,wCAAgB,KAAK,IAAI,CAAC;AAAA;AAAA,sBAG5D,SAAQ,gBAAK,oBAAL,mBAAsB,WAAtB,mBAA8B;AAAA,oBACxC;AAAA,kBACF;AAAA,gBACF,WAAW,KAAK,UAAU,WAAW,QAAQ,GAAG;AAC9C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,0BAAM,IAAI,8CAA8B;AAAA,sBACtC,eAAe;AAAA,oBACjB,CAAC;AAAA,kBACH;AAEA,0BAAQ,KAAK,WAAW;AAAA,oBACtB,KAAK,aAAa;AAChB,6BAAO;AAAA,wBACL,MAAM;AAAA,wBACN,aAAa;AAAA,0BACX,UAAM,wCAAgB,KAAK,IAAI;AAAA,0BAC/B,QAAQ;AAAA,wBACV;AAAA,sBACF;AAAA,oBACF;AAAA,oBACA,KAAK;AAAA,oBACL,KAAK,cAAc;AACjB,6BAAO;AAAA,wBACL,MAAM;AAAA,wBACN,aAAa;AAAA,0BACX,UAAM,wCAAgB,KAAK,IAAI;AAAA,0BAC/B,QAAQ;AAAA,wBACV;AAAA,sBACF;AAAA,oBACF;AAAA,oBAEA,SAAS;AACP,4BAAM,IAAI,8CAA8B;AAAA,wBACtC,eAAe,uCAAuC,KAAK,SAAS;AAAA,sBACtE,CAAC;AAAA,oBACH;AAAA,kBACF;AAAA,gBACF,WAAW,KAAK,cAAc,mBAAmB;AAC/C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,0BAAM,IAAI,8CAA8B;AAAA,sBACtC,eAAe;AAAA,oBACjB,CAAC;AAAA,kBACH;AAEA,yBAAO;AAAA,oBACL,MAAM;AAAA,oBACN,MACE,OAAO,KAAK,SAAS,YACrB,KAAK,KAAK,WAAW,OAAO,IACxB,EAAE,SAAS,KAAK,KAAK,IACrB;AAAA,sBACE,WAAU,UAAK,aAAL,YAAiB,QAAQ,KAAK;AAAA,sBACxC,WAAW,mCAA+B,wCAAgB,KAAK,IAAI,CAAC;AAAA,oBACtE;AAAA,kBACR;AAAA,gBACF,OAAO;AACL,wBAAM,IAAI,8CAA8B;AAAA,oBACtC,eAAe,wBAAwB,KAAK,SAAS;AAAA,kBACvD,CAAC;AAAA,gBACH;AAAA,cACF;AAAA,YACF;AAAA,UACF,CAAC;AAAA,QACH,CAAC;AAED;AAAA,MACF;AAAA,MAEA,KAAK,aAAa;AAChB,YAAI,OAAO;AACX,cAAM,YAID,CAAC;AAEN,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,sBAAQ,KAAK;AACb;AAAA,YACF;AAAA,YACA,KAAK,aAAa;AAChB,wBAAU,KAAK;AAAA,gBACb,IAAI,KAAK;AAAA,gBACT,MAAM;AAAA,gBACN,UAAU;AAAA,kBACR,MAAM,KAAK;AAAA,kBACX,WAAW,KAAK,UAAU,KAAK,KAAK;AAAA,gBACtC;AAAA,cACF,CAAC;AACD;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAEA,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,YAAY,UAAU,SAAS,IAAI,YAAY;AAAA,QACjD,CAAC;AAED;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,mBAAW,gBAAgB,SAAS;AAClC,gBAAM,SAAS,aAAa;AAE5B,cAAI;AACJ,kBAAQ,OAAO,MAAM;AAAA,YACnB,KAAK;AAAA,YACL,KAAK;AACH,6BAAe,OAAO;AACtB;AAAA,YACF,KAAK;AAAA,YACL,KAAK;AAAA,YACL,KAAK;AACH,6BAAe,KAAK,UAAU,OAAO,KAAK;AAC1C;AAAA,UACJ;AAEA,mBAAS,KAAK;AAAA,YACZ,MAAM;AAAA,YACN,cAAc,aAAa;AAAA,YAC3B,SAAS;AAAA,UACX,CAAC;AAAA,QACH;AACA;AAAA,MACF;AAAA,MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAEA,SAAO,EAAE,UAAU,SAAS;AAC9B;;;AC1NO,SAAS,oBAAoB;AAAA,EAClC;AAAA,EACA;AAAA,EACA;AACF,GAIG;AACD,SAAO;AAAA,IACL,IAAI,kBAAM;AAAA,IACV,SAAS,wBAAS;AAAA,IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;AAAA,EAC1D;AACF;;;ACZO,SAAS,sBACd,cAC6B;AAC7B,UAAQ,cAAc;AAAA,IACpB,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AAAA,IACL,KAAK;AACH,aAAO;AAAA,IACT;AACE,aAAO;AAAA,EACX;AACF;;;ACjBA,IAAAC,yBAIO;AACP,IAAAC,aAAkB;AAqBX,IAAM,+BAA2B;AAAA,EAAc,UACpD;AAAA,IACE,aAAE,OAAO;AAAA,MACP,IAAI,aAAE,OAAO,EAAE,QAAQ;AAAA,MACvB,SAAS,aAAE,OAAO,EAAE,QAAQ;AAAA,MAC5B,OAAO,aAAE,OAAO,EAAE,QAAQ;AAAA,MAC1B,SAAS,aAAE;AAAA,QACT,aAAE,OAAO;AAAA,UACP,SAAS,aAAE,OAAO;AAAA,YAChB,MAAM,aAAE,QAAQ,WAAW,EAAE,QAAQ;AAAA,YACrC,SAAS,aAAE,OAAO,EAAE,QAAQ;AAAA,YAC5B,YAAY,aACT;AAAA,cACC,aAAE,OAAO;AAAA,gBACP,IAAI,aAAE,OAAO,EAAE,QAAQ;AAAA,gBACvB,MAAM,aAAE,QAAQ,UAAU;AAAA,gBAC1B,UAAU,aAAE,OAAO;AAAA,kBACjB,MAAM,aAAE,OAAO;AAAA,kBACf,WAAW,aAAE,OAAO;AAAA,gBACtB,CAAC;AAAA,cACH,CAAC;AAAA,YACH,EACC,QAAQ;AAAA,YACX,aAAa,aACV;AAAA,cACC,aAAE,OAAO;AAAA,gBACP,MAAM,aAAE,QAAQ,cAAc;AAAA,gBAC9B,aAAa,aAAE,OAAO;AAAA,gBACtB,WAAW,aAAE,OAAO;AAAA,gBACpB,KAAK,aAAE,OAAO;AAAA,gBACd,OAAO,aAAE,OAAO;AAAA,cAClB,CAAC;AAAA,YACH,EACC,QAAQ;AAAA,UACb,CAAC;AAAA,UACD,OAAO,aAAE,OAAO;AAAA,UAChB,UAAU,aACP,OAAO;AAAA,YACN,SAAS,aACN;AAAA,cACC,aAAE,OAAO;AAAA,gBACP,OAAO,aAAE,OAAO;AAAA,gBAChB,SAAS,aAAE,OAAO;AAAA,gBAClB,cAAc,aAAE;AAAA,kBACd,aAAE,OAAO;AAAA,oBACP,OAAO,aAAE,OAAO;AAAA,oBAChB,SAAS,aAAE,OAAO;AAAA,kBACpB,CAAC;AAAA,gBACH;AAAA,cACF,CAAC;AAAA,YACH,EACC,QAAQ;AAAA,UACb,CAAC,EACA,QAAQ;AAAA,UACX,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,QACpC,CAAC;AAAA,MACH;AAAA,MACA,OAAO,aACJ,OAAO;AAAA,QACN,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,QAClC,mBAAmB,aAAE,OAAO,EAAE,QAAQ;AAAA,QACtC,cAAc,aAAE,OAAO,EAAE,QAAQ;AAAA,QACjC,uBAAuB,aACpB,OAAO;AAAA,UACN,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,QACpC,CAAC,EACA,QAAQ;AAAA,QACX,2BAA2B,aACxB,OAAO;AAAA,UACN,kBAAkB,aAAE,OAAO,EAAE,QAAQ;AAAA,UACrC,4BAA4B,aAAE,OAAO,EAAE,QAAQ;AAAA,UAC/C,4BAA4B,aAAE,OAAO,EAAE,QAAQ;AAAA,QACjD,CAAC,EACA,QAAQ;AAAA,MACb,CAAC,EACA,QAAQ;AAAA,IACb,CAAC;AAAA,EACH;AACF;AAIO,IAAM,4BAAwB;AAAA,EAAc,UACjD;AAAA,IACE,aAAE,MAAM;AAAA,MACN,aAAE,OAAO;AAAA,QACP,IAAI,aAAE,OAAO,EAAE,QAAQ;AAAA,QACvB,SAAS,aAAE,OAAO,EAAE,QAAQ;AAAA,QAC5B,OAAO,aAAE,OAAO,EAAE,QAAQ;AAAA,QAC1B,SAAS,aAAE;AAAA,UACT,aAAE,OAAO;AAAA,YACP,OAAO,aACJ,OAAO;AAAA,cACN,MAAM,aAAE,KAAK,CAAC,WAAW,CAAC,EAAE,QAAQ;AAAA,cACpC,SAAS,aAAE,OAAO,EAAE,QAAQ;AAAA,cAC5B,YAAY,aACT;AAAA,gBACC,aAAE,OAAO;AAAA,kBACP,OAAO,aAAE,OAAO;AAAA,kBAChB,IAAI,aAAE,OAAO,EAAE,QAAQ;AAAA,kBACvB,MAAM,aAAE,QAAQ,UAAU,EAAE,QAAQ;AAAA,kBACpC,UAAU,aAAE,OAAO;AAAA,oBACjB,MAAM,aAAE,OAAO,EAAE,QAAQ;AAAA,oBACzB,WAAW,aAAE,OAAO,EAAE,QAAQ;AAAA,kBAChC,CAAC;AAAA,gBACH,CAAC;AAAA,cACH,EACC,QAAQ;AAAA,cACX,aAAa,aACV;AAAA,gBACC,aAAE,OAAO;AAAA,kBACP,MAAM,aAAE,QAAQ,cAAc;AAAA,kBAC9B,aAAa,aAAE,OAAO;AAAA,kBACtB,WAAW,aAAE,OAAO;AAAA,kBACpB,KAAK,aAAE,OAAO;AAAA,kBACd,OAAO,aAAE,OAAO;AAAA,gBAClB,CAAC;AAAA,cACH,EACC,QAAQ;AAAA,YACb,CAAC,EACA,QAAQ;AAAA,YACX,UAAU,aACP,OAAO;AAAA,cACN,SAAS,aACN;AAAA,gBACC,aAAE,OAAO;AAAA,kBACP,OAAO,aAAE,OAAO;AAAA,kBAChB,SAAS,aAAE,OAAO;AAAA,kBAClB,cAAc,aAAE;AAAA,oBACd,aAAE,OAAO;AAAA,sBACP,OAAO,aAAE,OAAO;AAAA,sBAChB,SAAS,aAAE,OAAO;AAAA,oBACpB,CAAC;AAAA,kBACH;AAAA,gBACF,CAAC;AAAA,cACH,EACC,QAAQ;AAAA,YACb,CAAC,EACA,QAAQ;AAAA,YACX,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,YAClC,OAAO,aAAE,OAAO;AAAA,UAClB,CAAC;AAAA,QACH;AAAA,QACA,OAAO,aACJ,OAAO;AAAA,UACN,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,UAClC,mBAAmB,aAAE,OAAO,EAAE,QAAQ;AAAA,UACtC,cAAc,aAAE,OAAO,EAAE,QAAQ;AAAA,UACjC,uBAAuB,aACpB,OAAO;AAAA,YACN,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,UACpC,CAAC,EACA,QAAQ;AAAA,UACX,2BAA2B,aACxB,OAAO;AAAA,YACN,kBAAkB,aAAE,OAAO,EAAE,QAAQ;AAAA,YACrC,4BAA4B,aAAE,OAAO,EAAE,QAAQ;AAAA,YAC/C,4BAA4B,aAAE,OAAO,EAAE,QAAQ;AAAA,UACjD,CAAC,EACA,QAAQ;AAAA,QACb,CAAC,EACA,QAAQ;AAAA,MACb,CAAC;AAAA,MACD;AAAA,IACF,CAAC;AAAA,EACH;AACF;;;ACjMA,IAAAC,yBAIO;AACP,IAAAC,aAAkB;AAyCX,IAAM,qCAAiC;AAAA,EAAc,UAC1D;AAAA,IACE,aAAE,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOP,WAAW,aAAE,OAAO,aAAE,OAAO,OAAe,GAAG,aAAE,OAAO,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWpE,UAAU,aAAE,MAAM,CAAC,aAAE,QAAQ,GAAG,aAAE,OAAO,CAAC,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAKtD,mBAAmB,aAAE,QAAQ,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAMxC,MAAM,aAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAK1B,iBAAiB,aAAE,KAAK,CAAC,WAAW,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAKvE,qBAAqB,aAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAKzC,OAAO,aAAE,QAAQ,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAK5B,UAAU,aAAE,OAAO,aAAE,OAAO,EAAE,IAAI,EAAE,GAAG,aAAE,OAAO,EAAE,IAAI,GAAG,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAKrE,YAAY,aAAE,OAAO,aAAE,OAAO,GAAG,aAAE,IAAI,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOnD,mBAAmB,aAAE,QAAQ,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAYxC,aAAa,aAAE,KAAK,CAAC,QAAQ,QAAQ,YAAY,SAAS,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOtE,kBAAkB,aAAE,QAAQ,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAMvC,eAAe,aAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAM1D,gBAAgB,aAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASpC,kBAAkB,aAAE,OAAO,EAAE,SAAS;AAAA,IACxC,CAAC;AAAA,EACH;AACF;;;ACxJA,IAAAC,mBAIO;AAMA,SAAS,iBAAiB;AAAA,EAC/B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,GASE;AAEA,WAAQ,+BAAO,UAAS,QAAQ;AAEhC,QAAM,eAA6C,CAAC;AAEpD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;AAAA,EACjE;AAEA,QAAMC,eAAwC,CAAC;AAE/C,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;AAAA,MACjB,KAAK;AACH,QAAAA,aAAY,KAAK;AAAA,UACf,MAAM;AAAA,UACN,UAAU;AAAA,YACR,MAAM,KAAK;AAAA,YACX,aAAa,KAAK;AAAA,YAClB,YAAY,KAAK;AAAA,YACjB,QAAQ,oBAAoB,mBAAmB;AAAA,UACjD;AAAA,QACF,CAAC;AACD;AAAA,MACF;AACE,qBAAa,KAAK,EAAE,MAAM,oBAAoB,KAAK,CAAC;AACpD;AAAA,IACJ;AAAA,EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAOA,cAAa,YAAY,QAAW,aAAa;AAAA,EACnE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;AAAA,IACZ,KAAK;AAAA,IACL,KAAK;AAAA,IACL,KAAK;AACH,aAAO,EAAE,OAAOA,cAAa,YAAY,MAAM,aAAa;AAAA,IAC9D,KAAK;AACH,aAAO;AAAA,QACL,OAAOA;AAAA,QACP,YAAY;AAAA,UACV,MAAM;AAAA,UACN,UAAU;AAAA,YACR,MAAM,WAAW;AAAA,UACnB;AAAA,QACF;AAAA,QACA;AAAA,MACF;AAAA,IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAI,+CAA8B;AAAA,QACtC,eAAe,qBAAqB,gBAAgB;AAAA,MACtD,CAAC;AAAA,IACH;AAAA,EACF;AACF;;;APxCO,IAAM,0BAAN,MAAyD;AAAA,EAW9D,YAAY,SAA4B,QAA0B;AAVlE,SAAS,uBAAuB;AAIhC,SAAS,gBAAgB;AAAA,MACvB,WAAW,CAAC,iBAAiB;AAAA,IAC/B;AAKE,SAAK,UAAU;AACf,SAAK,SAAS;AAAA,EAChB;AAAA,EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,MAAc,QAAQ;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAA+B;AA9EjC;AA+EI,UAAM,WAAyC,CAAC;AAGhD,UAAM,iBACH,eAAM,6CAAqB;AAAA,MAC1B,UAAU;AAAA,MACV;AAAA,MACA,QAAQ;AAAA,IACV,CAAC,MAJA,YAIM,CAAC;AAEV,UAAM,qBAAoB,mBAAc,sBAAd,YAAmC;AAE7D,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAEA,SACE,iDAAgB,UAAS,UACzB,eAAe,UAAU,QACzB,CAAC,mBACD;AACA,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACE;AAAA,MACJ,CAAC;AAAA,IACH;AAEA,UAAM,EAAE,UAAU,UAAU,gBAAgB,IAAI;AAAA,MAC9C;AAAA,QACE;AAAA,QACA,mBAAmB,qBAAqB,KAAK,OAAO;AAAA,MACtD;AAAA,IACF;AAEA,aAAS,KAAK,GAAG,eAAe;AAEhC,UAAM,oBAAmB,mBAAc,qBAAd,YAAkC;AAE3D,UAAM,WAAW;AAAA;AAAA,MAEf,OAAO,KAAK;AAAA;AAAA,MAGZ,YAAY,cAAc;AAAA,MAC1B,UACE,cAAc,aAAa,QAC3B,OAAO,cAAc,aAAa,WAC9B,OACA;AAAA,MACN,cACE,OAAO,cAAc,aAAa,WAC9B,cAAc,WACd,OAAO,cAAc,aAAa,YAChC,cAAc,WACZ,IACA,SACF;AAAA,MACR,MAAM,cAAc;AAAA,MACpB,qBAAqB,cAAc;AAAA;AAAA,MAGnC,YAAY;AAAA,MACZ;AAAA,MACA,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB,kBACE,iDAAgB,UAAS,SACrB,qBAAqB,eAAe,UAAU,OAC5C;AAAA,QACE,MAAM;AAAA,QACN,aAAa;AAAA,UACX,QAAQ,eAAe;AAAA,UACvB,QAAQ;AAAA,UACR,OAAM,oBAAe,SAAf,YAAuB;AAAA,UAC7B,aAAa,eAAe;AAAA,QAC9B;AAAA,MACF,IACA,EAAE,MAAM,cAAc,IACxB;AAAA,MACN,MAAM;AAAA,MACN;AAAA,MACA,WAAW,cAAc;AAAA;AAAA;AAAA,MAIzB,uBAAuB,cAAc;AAAA,MACrC,OAAO,cAAc;AAAA,MACrB,UAAU,cAAc;AAAA,MACxB,YAAY,cAAc;AAAA,MAC1B,kBAAkB,cAAc;AAAA,MAChC,cAAc,cAAc;AAAA,MAC5B,kBAAkB,cAAc;AAAA,MAChC,mBAAmB,cAAc;AAAA;AAAA,MAGjC;AAAA,IACF;AAEA,QAAI,iBAAiB,KAAK,OAAO,GAAG;AAGlC,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AACA,UAAI,SAAS,SAAS,MAAM;AAC1B,iBAAS,QAAQ;AACjB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AACA,UAAI,SAAS,qBAAqB,MAAM;AACtC,iBAAS,oBAAoB;AAC7B,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AACA,UAAI,SAAS,oBAAoB,MAAM;AACrC,iBAAS,mBAAmB;AAC5B,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AACA,UAAI,SAAS,cAAc,MAAM;AAC/B,iBAAS,aAAa;AACtB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AACA,UAAI,SAAS,YAAY,MAAM;AAC7B,iBAAS,WAAW;AACpB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AACA,UAAI,SAAS,gBAAgB,MAAM;AACjC,iBAAS,eAAe;AACxB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAGA,UAAI,SAAS,cAAc,MAAM;AAC/B,YAAI,SAAS,yBAAyB,MAAM;AAC1C,mBAAS,wBAAwB,SAAS;AAAA,QAC5C;AACA,iBAAS,aAAa;AAAA,MACxB;AAAA,IACF,WACE,KAAK,QAAQ,WAAW,uBAAuB,KAC/C,KAAK,QAAQ,WAAW,4BAA4B,GACpD;AACA,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SACE;AAAA,QACJ,CAAC;AAAA,MACH;AAAA,IACF;AAGA,QACE,cAAc,gBAAgB,UAC9B,CAAC,uBAAuB,KAAK,OAAO,GACpC;AACA,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACE;AAAA,MACJ,CAAC;AACD,eAAS,eAAe;AAAA,IAC1B;AAGA,QACE,cAAc,gBAAgB,cAC9B,CAAC,2BAA2B,KAAK,OAAO,GACxC;AACA,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACE;AAAA,MACJ,CAAC;AACD,eAAS,eAAe;AAAA,IAC1B;AAEA,UAAM;AAAA,MACJ,OAAOC;AAAA,MACP,YAAY;AAAA,MACZ;AAAA,IACF,IAAI,iBAAiB;AAAA,MACnB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAED,WAAO;AAAA,MACL,MAAM;AAAA,QACJ,GAAG;AAAA,QACH,OAAOA;AAAA,QACP,aAAa;AAAA,MACf;AAAA,MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;AAAA,IACzC;AAAA,EACF;AAAA,EAEA,MAAM,WACJ,SAC6D;AAzTjE;AA0TI,UAAM,EAAE,MAAM,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE3D,UAAM;AAAA,MACJ;AAAA,MACA,OAAO;AAAA,MACP,UAAU;AAAA,IACZ,IAAI,UAAM,sCAAc;AAAA,MACtB,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,uCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,SAAS,SAAS,QAAQ,CAAC;AACjC,UAAM,UAAyC,CAAC;AAGhD,UAAM,OAAO,OAAO,QAAQ;AAC5B,QAAI,QAAQ,QAAQ,KAAK,SAAS,GAAG;AACnC,cAAQ,KAAK,EAAE,MAAM,QAAQ,KAAK,CAAC;AAAA,IACrC;AAGA,eAAW,aAAY,YAAO,QAAQ,eAAf,YAA6B,CAAC,GAAG;AACtD,cAAQ,KAAK;AAAA,QACX,MAAM;AAAA,QACN,aAAY,cAAS,OAAT,gBAAe,mCAAW;AAAA,QACtC,UAAU,SAAS,SAAS;AAAA,QAC5B,OAAO,SAAS,SAAS;AAAA,MAC3B,CAAC;AAAA,IACH;AAGA,eAAW,eAAc,YAAO,QAAQ,gBAAf,YAA8B,CAAC,GAAG;AACzD,cAAQ,KAAK;AAAA,QACX,MAAM;AAAA,QACN,YAAY;AAAA,QACZ,QAAI,mCAAW;AAAA,QACf,KAAK,WAAW;AAAA,QAChB,OAAO,WAAW;AAAA,MACpB,CAAC;AAAA,IACH;AAGA,UAAM,0BAAyB,cAAS,UAAT,mBAAgB;AAC/C,UAAM,sBAAqB,cAAS,UAAT,mBAAgB;AAC3C,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAChE,SAAI,iEAAwB,+BAA8B,MAAM;AAC9D,uBAAiB,OAAO,2BACtB,iEAAwB;AAAA,IAC5B;AACA,SAAI,iEAAwB,+BAA8B,MAAM;AAC9D,uBAAiB,OAAO,2BACtB,iEAAwB;AAAA,IAC5B;AACA,UAAI,YAAO,aAAP,mBAAiB,YAAW,MAAM;AACpC,uBAAiB,OAAO,WAAW,OAAO,SAAS;AAAA,IACrD;AAEA,WAAO;AAAA,MACL;AAAA,MACA,cAAc,sBAAsB,OAAO,aAAa;AAAA,MACxD,OAAO;AAAA,QACL,cAAa,oBAAS,UAAT,mBAAgB,kBAAhB,YAAiC;AAAA,QAC9C,eAAc,oBAAS,UAAT,mBAAgB,sBAAhB,YAAqC;AAAA,QACnD,cAAa,oBAAS,UAAT,mBAAgB,iBAAhB,YAAgC;AAAA,QAC7C,kBAAiB,sEAAwB,qBAAxB,YAA4C;AAAA,QAC7D,oBAAmB,8DAAoB,kBAApB,YAAqC;AAAA,MAC1D;AAAA,MACA,SAAS,EAAE,KAAK;AAAA,MAChB,UAAU;AAAA,QACR,GAAG,oBAAoB,QAAQ;AAAA,QAC/B,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM,OAAO;AAAA,MACX,GAAG;AAAA,MACH,QAAQ;AAAA,MACR,gBAAgB;AAAA,QACd,eAAe;AAAA,MACjB;AAAA,IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,UAAM,sCAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,uCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,YAQD,CAAC;AAEN,QAAI,eAA4C;AAChD,UAAM,QAA8B;AAAA,MAClC,aAAa;AAAA,MACb,cAAc;AAAA,MACd,aAAa;AAAA,IACf;AACA,QAAI,eAAe;AACnB,QAAI,eAAe;AAEnB,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAEhE,WAAO;AAAA,MACL,QAAQ,SAAS;AAAA,QACf,IAAI,gBAGF;AAAA,UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;AAAA,UACvD;AAAA,UAEA,UAAU,OAAO,YAAY;AA7cvC;AA8cY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;AAAA,YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,gBAAI,cAAc;AAChB,6BAAe;AAEf,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,GAAG,oBAAoB,KAAK;AAAA,cAC9B,CAAC;AAAA,YACH;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,oBAAM,eAAc,WAAM,MAAM,kBAAZ,YAA6B;AACjD,oBAAM,gBAAe,WAAM,MAAM,sBAAZ,YAAiC;AACtD,oBAAM,eAAc,WAAM,MAAM,iBAAZ,YAA4B;AAChD,oBAAM,mBACJ,iBAAM,MAAM,8BAAZ,mBAAuC,qBAAvC,YACA;AACF,oBAAM,qBACJ,iBAAM,MAAM,0BAAZ,mBAAmC,kBAAnC,YAAoD;AAEtD,oBACE,WAAM,MAAM,8BAAZ,mBACI,+BAA8B,MAClC;AACA,iCAAiB,OAAO,4BACtB,WAAM,MAAM,8BAAZ,mBAAuC;AAAA,cAC3C;AACA,oBACE,WAAM,MAAM,8BAAZ,mBACI,+BAA8B,MAClC;AACA,iCAAiB,OAAO,4BACtB,WAAM,MAAM,8BAAZ,mBAAuC;AAAA,cAC3C;AAAA,YACF;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,iCAAQ,kBAAiB,MAAM;AACjC,6BAAe,sBAAsB,OAAO,aAAa;AAAA,YAC3D;AAEA,kBAAI,sCAAQ,aAAR,mBAAkB,YAAW,MAAM;AACrC,+BAAiB,OAAO,WAAW,OAAO,SAAS;AAAA,YACrD;AAEA,iBAAI,iCAAQ,UAAS,MAAM;AACzB;AAAA,YACF;AAEA,kBAAM,QAAQ,OAAO;AAErB,gBAAI,MAAM,WAAW,MAAM;AACzB,kBAAI,CAAC,cAAc;AACjB,2BAAW,QAAQ,EAAE,MAAM,cAAc,IAAI,IAAI,CAAC;AAClD,+BAAe;AAAA,cACjB;AAEA,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,IAAI;AAAA,gBACJ,OAAO,MAAM;AAAA,cACf,CAAC;AAAA,YACH;AAEA,gBAAI,MAAM,cAAc,MAAM;AAC5B,yBAAW,iBAAiB,MAAM,YAAY;AAC5C,sBAAM,QAAQ,cAAc;AAG5B,oBAAI,UAAU,KAAK,KAAK,MAAM;AAC5B,sBAAI,cAAc,SAAS,YAAY;AACrC,0BAAM,IAAI,0CAAyB;AAAA,sBACjC,MAAM;AAAA,sBACN,SAAS;AAAA,oBACX,CAAC;AAAA,kBACH;AAEA,sBAAI,cAAc,MAAM,MAAM;AAC5B,0BAAM,IAAI,0CAAyB;AAAA,sBACjC,MAAM;AAAA,sBACN,SAAS;AAAA,oBACX,CAAC;AAAA,kBACH;AAEA,wBAAI,mBAAc,aAAd,mBAAwB,SAAQ,MAAM;AACxC,0BAAM,IAAI,0CAAyB;AAAA,sBACjC,MAAM;AAAA,sBACN,SAAS;AAAA,oBACX,CAAC;AAAA,kBACH;AAEA,6BAAW,QAAQ;AAAA,oBACjB,MAAM;AAAA,oBACN,IAAI,cAAc;AAAA,oBAClB,UAAU,cAAc,SAAS;AAAA,kBACnC,CAAC;AAED,4BAAU,KAAK,IAAI;AAAA,oBACjB,IAAI,cAAc;AAAA,oBAClB,MAAM;AAAA,oBACN,UAAU;AAAA,sBACR,MAAM,cAAc,SAAS;AAAA,sBAC7B,YAAW,mBAAc,SAAS,cAAvB,YAAoC;AAAA,oBACjD;AAAA,oBACA,aAAa;AAAA,kBACf;AAEA,wBAAMC,YAAW,UAAU,KAAK;AAEhC,wBACE,KAAAA,UAAS,aAAT,mBAAmB,SAAQ,UAC3B,KAAAA,UAAS,aAAT,mBAAmB,cAAa,MAChC;AAEA,wBAAIA,UAAS,SAAS,UAAU,SAAS,GAAG;AAC1C,iCAAW,QAAQ;AAAA,wBACjB,MAAM;AAAA,wBACN,IAAIA,UAAS;AAAA,wBACb,OAAOA,UAAS,SAAS;AAAA,sBAC3B,CAAC;AAAA,oBACH;AAIA,4BAAI,uCAAeA,UAAS,SAAS,SAAS,GAAG;AAC/C,iCAAW,QAAQ;AAAA,wBACjB,MAAM;AAAA,wBACN,IAAIA,UAAS;AAAA,sBACf,CAAC;AAED,iCAAW,QAAQ;AAAA,wBACjB,MAAM;AAAA,wBACN,aAAY,KAAAA,UAAS,OAAT,gBAAe,mCAAW;AAAA,wBACtC,UAAUA,UAAS,SAAS;AAAA,wBAC5B,OAAOA,UAAS,SAAS;AAAA,sBAC3B,CAAC;AACD,sBAAAA,UAAS,cAAc;AAAA,oBACzB;AAAA,kBACF;AAEA;AAAA,gBACF;AAGA,sBAAM,WAAW,UAAU,KAAK;AAEhC,oBAAI,SAAS,aAAa;AACxB;AAAA,gBACF;AAEA,sBAAI,mBAAc,aAAd,mBAAwB,cAAa,MAAM;AAC7C,2BAAS,SAAU,cACjB,yBAAc,aAAd,mBAAwB,cAAxB,YAAqC;AAAA,gBACzC;AAGA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,SAAS;AAAA,kBACb,QAAO,mBAAc,SAAS,cAAvB,YAAoC;AAAA,gBAC7C,CAAC;AAGD,sBACE,cAAS,aAAT,mBAAmB,SAAQ,UAC3B,cAAS,aAAT,mBAAmB,cAAa,YAChC,uCAAe,SAAS,SAAS,SAAS,GAC1C;AACA,6BAAW,QAAQ;AAAA,oBACjB,MAAM;AAAA,oBACN,IAAI,SAAS;AAAA,kBACf,CAAC;AAED,6BAAW,QAAQ;AAAA,oBACjB,MAAM;AAAA,oBACN,aAAY,cAAS,OAAT,gBAAe,mCAAW;AAAA,oBACtC,UAAU,SAAS,SAAS;AAAA,oBAC5B,OAAO,SAAS,SAAS;AAAA,kBAC3B,CAAC;AACD,2BAAS,cAAc;AAAA,gBACzB;AAAA,cACF;AAAA,YACF;AAGA,gBAAI,MAAM,eAAe,MAAM;AAC7B,yBAAW,cAAc,MAAM,aAAa;AAC1C,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY;AAAA,kBACZ,QAAI,mCAAW;AAAA,kBACf,KAAK,WAAW;AAAA,kBAChB,OAAO,WAAW;AAAA,gBACpB,CAAC;AAAA,cACH;AAAA,YACF;AAAA,UACF;AAAA,UAEA,MAAM,YAAY;AAChB,gBAAI,cAAc;AAChB,yBAAW,QAAQ,EAAE,MAAM,YAAY,IAAI,IAAI,CAAC;AAAA,YAClD;AAEA,uBAAW,QAAQ;AAAA,cACjB,MAAM;AAAA,cACN;AAAA,cACA;AAAA,cACA,GAAI,oBAAoB,OAAO,EAAE,iBAAiB,IAAI,CAAC;AAAA,YACzD,CAAC;AAAA,UACH;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MACA,SAAS,EAAE,KAAK;AAAA,MAChB,UAAU,EAAE,SAAS,gBAAgB;AAAA,IACvC;AAAA,EACF;AACF;AAEA,SAAS,iBAAiB,SAAiB;AACzC,UACG,QAAQ,WAAW,GAAG,KAAK,QAAQ,WAAW,OAAO,MACtD,CAAC,QAAQ,WAAW,YAAY;AAEpC;AAEA,SAAS,uBAAuB,SAAiB;AAC/C,SACE,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS,KAC3B,QAAQ,WAAW,OAAO,KAAK,CAAC,QAAQ,WAAW,YAAY;AAEpE;AAEA,SAAS,2BAA2B,SAAiB;AACnD,SACE,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,YAAY,KAC9B,QAAQ,WAAW,OAAO,KACzB,CAAC,QAAQ,WAAW,YAAY,KAChC,CAAC,QAAQ,WAAW,YAAY,KAClC,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS;AAEhC;AAEA,SAAS,qBAAqB,SAAiB;AAvtB/C;AAwtBE,MAAI,CAAC,iBAAiB,OAAO,GAAG;AAC9B,WAAO;AAAA,EACT;AAEA,UACE,2BAAgB,OAAuC,MAAvD,mBACI,sBADJ,YACyB;AAE7B;AAEA,IAAM,kBAAkB;AAAA,EACtB,WAAW;AAAA,IACT,mBAAmB;AAAA,EACrB;AAAA,EACA,sBAAsB;AAAA,IACpB,mBAAmB;AAAA,EACrB;AAAA,EACA,cAAc;AAAA,IACZ,mBAAmB;AAAA,EACrB;AAAA,EACA,yBAAyB;AAAA,IACvB,mBAAmB;AAAA,EACrB;AAAA,EACA,IAAI;AAAA,IACF,mBAAmB;AAAA,EACrB;AAAA,EACA,iBAAiB;AAAA,IACf,mBAAmB;AAAA,EACrB;AAAA,EACA,WAAW;AAAA,IACT,mBAAmB;AAAA,EACrB;AAAA,EACA,sBAAsB;AAAA,IACpB,mBAAmB;AAAA,EACrB;AAAA,EACA,WAAW;AAAA,IACT,mBAAmB;AAAA,EACrB;AAAA,EACA,sBAAsB;AAAA,IACpB,mBAAmB;AAAA,EACrB;AACF;;;AQzvBA,IAAAC,yBAQO;;;AChBP,IAAAC,mBAIO;AAEA,SAAS,gCAAgC;AAAA,EAC9C;AAAA,EACA,OAAO;AAAA,EACP,YAAY;AACd,GAOE;AAEA,MAAI,OAAO;AAGX,MAAI,OAAO,CAAC,EAAE,SAAS,UAAU;AAC/B,YAAQ,GAAG,OAAO,CAAC,EAAE,OAAO;AAAA;AAAA;AAC5B,aAAS,OAAO,MAAM,CAAC;AAAA,EACzB;AAEA,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;AAAA,MACZ,KAAK,UAAU;AACb,cAAM,IAAI,oCAAmB;AAAA,UAC3B,SAAS;AAAA,UACT;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,KAAK,QAAQ;AACX,cAAM,cAAc,QACjB,IAAI,UAAQ;AACX,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;AAAA,YACd;AAAA,UACF;AAAA,QACF,CAAC,EACA,OAAO,OAAO,EACd,KAAK,EAAE;AAEV,gBAAQ,GAAG,IAAI;AAAA,EAAM,WAAW;AAAA;AAAA;AAChC;AAAA,MACF;AAAA,MAEA,KAAK,aAAa;AAChB,cAAM,mBAAmB,QACtB,IAAI,UAAQ;AACX,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;AAAA,YACd;AAAA,YACA,KAAK,aAAa;AAChB,oBAAM,IAAI,+CAA8B;AAAA,gBACtC,eAAe;AAAA,cACjB,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF,CAAC,EACA,KAAK,EAAE;AAEV,gBAAQ,GAAG,SAAS;AAAA,EAAM,gBAAgB;AAAA;AAAA;AAC1C;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,cAAM,IAAI,+CAA8B;AAAA,UACtC,eAAe;AAAA,QACjB,CAAC;AAAA,MACH;AAAA,MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAGA,UAAQ,GAAG,SAAS;AAAA;AAEpB,SAAO;AAAA,IACL,QAAQ;AAAA,IACR,eAAe,CAAC;AAAA,EAAK,IAAI,GAAG;AAAA,EAC9B;AACF;;;AC5FO,SAASC,qBAAoB;AAAA,EAClC;AAAA,EACA;AAAA,EACA;AACF,GAIG;AACD,SAAO;AAAA,IACL,IAAI,kBAAM;AAAA,IACV,SAAS,wBAAS;AAAA,IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;AAAA,EAC1D;AACF;;;ACZO,SAASC,uBACd,cAC6B;AAC7B,UAAQ,cAAc;AAAA,IACpB,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AAAA,IACL,KAAK;AACH,aAAO;AAAA,IACT;AACE,aAAO;AAAA,EACX;AACF;;;AClBA,IAAAC,aAAkB;AAElB,IAAAC,yBAIO;AAIA,IAAM,qCAAiC;AAAA,EAAc,UAC1D;AAAA,IACE,aAAE,OAAO;AAAA,MACP,IAAI,aAAE,OAAO,EAAE,QAAQ;AAAA,MACvB,SAAS,aAAE,OAAO,EAAE,QAAQ;AAAA,MAC5B,OAAO,aAAE,OAAO,EAAE,QAAQ;AAAA,MAC1B,SAAS,aAAE;AAAA,QACT,aAAE,OAAO;AAAA,UACP,MAAM,aAAE,OAAO;AAAA,UACf,eAAe,aAAE,OAAO;AAAA,UACxB,UAAU,aACP,OAAO;AAAA,YACN,QAAQ,aAAE,MAAM,aAAE,OAAO,CAAC;AAAA,YAC1B,gBAAgB,aAAE,MAAM,aAAE,OAAO,CAAC;AAAA,YAClC,cAAc,aAAE,MAAM,aAAE,OAAO,aAAE,OAAO,GAAG,aAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;AAAA,UAClE,CAAC,EACA,QAAQ;AAAA,QACb,CAAC;AAAA,MACH;AAAA,MACA,OAAO,aACJ,OAAO;AAAA,QACN,eAAe,aAAE,OAAO;AAAA,QACxB,mBAAmB,aAAE,OAAO;AAAA,QAC5B,cAAc,aAAE,OAAO;AAAA,MACzB,CAAC,EACA,QAAQ;AAAA,IACb,CAAC;AAAA,EACH;AACF;AAIO,IAAM,kCAA8B;AAAA,EAAc,UACvD;AAAA,IACE,aAAE,MAAM;AAAA,MACN,aAAE,OAAO;AAAA,QACP,IAAI,aAAE,OAAO,EAAE,QAAQ;AAAA,QACvB,SAAS,aAAE,OAAO,EAAE,QAAQ;AAAA,QAC5B,OAAO,aAAE,OAAO,EAAE,QAAQ;AAAA,QAC1B,SAAS,aAAE;AAAA,UACT,aAAE,OAAO;AAAA,YACP,MAAM,aAAE,OAAO;AAAA,YACf,eAAe,aAAE,OAAO,EAAE,QAAQ;AAAA,YAClC,OAAO,aAAE,OAAO;AAAA,YAChB,UAAU,aACP,OAAO;AAAA,cACN,QAAQ,aAAE,MAAM,aAAE,OAAO,CAAC;AAAA,cAC1B,gBAAgB,aAAE,MAAM,aAAE,OAAO,CAAC;AAAA,cAClC,cAAc,aACX,MAAM,aAAE,OAAO,aAAE,OAAO,GAAG,aAAE,OAAO,CAAC,CAAC,EACtC,QAAQ;AAAA,YACb,CAAC,EACA,QAAQ;AAAA,UACb,CAAC;AAAA,QACH;AAAA,QACA,OAAO,aACJ,OAAO;AAAA,UACN,eAAe,aAAE,OAAO;AAAA,UACxB,mBAAmB,aAAE,OAAO;AAAA,UAC5B,cAAc,aAAE,OAAO;AAAA,QACzB,CAAC,EACA,QAAQ;AAAA,MACb,CAAC;AAAA,MACD;AAAA,IACF,CAAC;AAAA,EACH;AACF;;;AC5EA,IAAAC,yBAIO;AACP,IAAAC,aAAkB;AAKX,IAAM,sCAAkC;AAAA,EAAc,UAC3D;AAAA,IACE,aAAE,OAAO;AAAA;AAAA;AAAA;AAAA,MAIP,MAAM,aAAE,QAAQ,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAgB3B,WAAW,aAAE,OAAO,aAAE,OAAO,GAAG,aAAE,OAAO,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAKrD,QAAQ,aAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAM5B,MAAM,aAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAW1B,UAAU,aAAE,MAAM,CAAC,aAAE,QAAQ,GAAG,aAAE,OAAO,CAAC,CAAC,EAAE,SAAS;AAAA,IACxD,CAAC;AAAA,EACH;AACF;;;ALnBO,IAAM,gCAAN,MAA+D;AAAA,EAWpE,YACE,SACA,QACA;AAbF,SAAS,uBAAuB;AAsBhC,SAAS,gBAA0C;AAAA;AAAA,IAEnD;AAVE,SAAK,UAAU;AACf,SAAK,SAAS;AAAA,EAChB;AAAA,EAVA,IAAY,sBAA8B;AACxC,WAAO,KAAK,OAAO,SAAS,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK;AAAA,EACjD;AAAA,EAUA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAMA,MAAc,QAAQ;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,eAAe;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAAiD;AAC/C,UAAM,WAAyC,CAAC;AAGhD,UAAM,gBAAgB;AAAA,MACpB,GAAI,UAAM,6CAAqB;AAAA,QAC7B,UAAU;AAAA,QACV;AAAA,QACA,QAAQ;AAAA,MACV,CAAC;AAAA,MACD,GAAI,UAAM,6CAAqB;AAAA,QAC7B,UAAU,KAAK;AAAA,QACf;AAAA,QACA,QAAQ;AAAA,MACV,CAAC;AAAA,IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;AAAA,IAChE;AAEA,QAAI,+BAAO,QAAQ;AACjB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,QAAQ,CAAC;AAAA,IACjE;AAEA,QAAI,cAAc,MAAM;AACtB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,aAAa,CAAC;AAAA,IACtE;AAEA,QAAI,kBAAkB,QAAQ,eAAe,SAAS,QAAQ;AAC5D,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAEA,UAAM,EAAE,QAAQ,kBAAkB,cAAc,IAC9C,gCAAgC,EAAE,OAAO,CAAC;AAE5C,UAAM,OAAO,CAAC,GAAI,wCAAiB,CAAC,GAAI,GAAI,gDAAqB,CAAC,CAAE;AAEpE,WAAO;AAAA,MACL,MAAM;AAAA;AAAA,QAEJ,OAAO,KAAK;AAAA;AAAA,QAGZ,MAAM,cAAc;AAAA,QACpB,YAAY,cAAc;AAAA,QAC1B,WACE,+CAAe,cAAa,OACxB,KACA,+CAAe,cAAa,QAC1B,SACA,+CAAe;AAAA,QACvB,QAAQ,cAAc;AAAA,QACtB,MAAM,cAAc;AAAA;AAAA,QAGpB,YAAY;AAAA,QACZ;AAAA,QACA,OAAO;AAAA,QACP,mBAAmB;AAAA,QACnB,kBAAkB;AAAA,QAClB;AAAA;AAAA,QAGA,QAAQ;AAAA;AAAA,QAGR,MAAM,KAAK,SAAS,IAAI,OAAO;AAAA,MACjC;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,WACJ,SAC6D;AA9JjE;AA+JI,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM;AAAA,MACJ;AAAA,MACA,OAAO;AAAA,MACP,UAAU;AAAA,IACZ,IAAI,UAAM,sCAAc;AAAA,MACtB,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,uCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D,MAAM;AAAA,MACN,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,SAAS,SAAS,QAAQ,CAAC;AAEjC,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAEhE,QAAI,OAAO,YAAY,MAAM;AAC3B,uBAAiB,OAAO,WAAW,OAAO;AAAA,IAC5C;AAEA,WAAO;AAAA,MACL,SAAS,CAAC,EAAE,MAAM,QAAQ,MAAM,OAAO,KAAK,CAAC;AAAA,MAC7C,OAAO;AAAA,QACL,cAAa,cAAS,UAAT,mBAAgB;AAAA,QAC7B,eAAc,cAAS,UAAT,mBAAgB;AAAA,QAC9B,cAAa,cAAS,UAAT,mBAAgB;AAAA,MAC/B;AAAA,MACA,cAAcC,uBAAsB,OAAO,aAAa;AAAA,MACxD,SAAS,EAAE,MAAM,KAAK;AAAA,MACtB,UAAU;AAAA,QACR,GAAGC,qBAAoB,QAAQ;AAAA,QAC/B,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM,OAAO;AAAA,MACX,GAAG;AAAA,MACH,QAAQ;AAAA,MAER,gBAAgB;AAAA,QACd,eAAe;AAAA,MACjB;AAAA,IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,UAAM,sCAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,uCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,QAAI,eAA4C;AAChD,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAChE,UAAM,QAA8B;AAAA,MAClC,aAAa;AAAA,MACb,cAAc;AAAA,MACd,aAAa;AAAA,IACf;AACA,QAAI,eAAe;AAEnB,WAAO;AAAA,MACL,QAAQ,SAAS;AAAA,QACf,IAAI,gBAGF;AAAA,UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;AAAA,UACvD;AAAA,UAEA,UAAU,OAAO,YAAY;AAC3B,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;AAAA,YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,gBAAI,cAAc;AAChB,6BAAe;AAEf,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,GAAGA,qBAAoB,KAAK;AAAA,cAC9B,CAAC;AAED,yBAAW,QAAQ,EAAE,MAAM,cAAc,IAAI,IAAI,CAAC;AAAA,YACpD;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,oBAAM,cAAc,MAAM,MAAM;AAChC,oBAAM,eAAe,MAAM,MAAM;AACjC,oBAAM,cAAc,MAAM,MAAM;AAAA,YAClC;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,iCAAQ,kBAAiB,MAAM;AACjC,6BAAeD,uBAAsB,OAAO,aAAa;AAAA,YAC3D;AAEA,iBAAI,iCAAQ,aAAY,MAAM;AAC5B,+BAAiB,OAAO,WAAW,OAAO;AAAA,YAC5C;AAEA,iBAAI,iCAAQ,SAAQ,QAAQ,OAAO,KAAK,SAAS,GAAG;AAClD,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,IAAI;AAAA,gBACJ,OAAO,OAAO;AAAA,cAChB,CAAC;AAAA,YACH;AAAA,UACF;AAAA,UAEA,MAAM,YAAY;AAChB,gBAAI,CAAC,cAAc;AACjB,yBAAW,QAAQ,EAAE,MAAM,YAAY,IAAI,IAAI,CAAC;AAAA,YAClD;AAEA,uBAAW,QAAQ;AAAA,cACjB,MAAM;AAAA,cACN;AAAA,cACA;AAAA,cACA;AAAA,YACF,CAAC;AAAA,UACH;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MACA,SAAS,EAAE,KAAK;AAAA,MAChB,UAAU,EAAE,SAAS,gBAAgB;AAAA,IACvC;AAAA,EACF;AACF;;;AM1UA,IAAAE,mBAGO;AACP,IAAAC,0BAKO;;;ACTP,IAAAC,yBAIO;AACP,IAAAC,aAAkB;AAQX,IAAM,qCAAiC;AAAA,EAAc,UAC1D;AAAA,IACE,aAAE,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA,MAKP,YAAY,aAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAMhC,MAAM,aAAE,OAAO,EAAE,SAAS;AAAA,IAC5B,CAAC;AAAA,EACH;AACF;;;AC7BA,IAAAC,0BAAyC;AACzC,IAAAC,aAAkB;AAIX,IAAM,wCAAoC;AAAA,EAAc,UAC7D;AAAA,IACE,aAAE,OAAO;AAAA,MACP,MAAM,aAAE,MAAM,aAAE,OAAO,EAAE,WAAW,aAAE,MAAM,aAAE,OAAO,CAAC,EAAE,CAAC,CAAC;AAAA,MAC1D,OAAO,aAAE,OAAO,EAAE,eAAe,aAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;AAAA,IACzD,CAAC;AAAA,EACH;AACF;;;AFMO,IAAM,uBAAN,MAA+D;AAAA,EAYpE,YAAY,SAAiC,QAAsB;AAXnE,SAAS,uBAAuB;AAEhC,SAAS,uBAAuB;AAChC,SAAS,wBAAwB;AAS/B,SAAK,UAAU;AACf,SAAK,SAAS;AAAA,EAChB;AAAA,EAPA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAOA,MAAM,QAAQ;AAAA,IACZ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAEE;AA1CJ;AA2CI,QAAI,OAAO,SAAS,KAAK,sBAAsB;AAC7C,YAAM,IAAI,oDAAmC;AAAA,QAC3C,UAAU,KAAK;AAAA,QACf,SAAS,KAAK;AAAA,QACd,sBAAsB,KAAK;AAAA,QAC3B;AAAA,MACF,CAAC;AAAA,IACH;AAGA,UAAM,iBACH,eAAM,8CAAqB;AAAA,MAC1B,UAAU;AAAA,MACV;AAAA,MACA,QAAQ;AAAA,IACV,CAAC,MAJA,YAIM,CAAC;AAEV,UAAM;AAAA,MACJ;AAAA,MACA,OAAO;AAAA,MACP;AAAA,IACF,IAAI,UAAM,uCAAc;AAAA,MACtB,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,wCAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;AAAA,MACtD,MAAM;AAAA,QACJ,OAAO,KAAK;AAAA,QACZ,OAAO;AAAA,QACP,iBAAiB;AAAA,QACjB,YAAY,cAAc;AAAA,QAC1B,MAAM,cAAc;AAAA,MACtB;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA;AAAA,MACA,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,WAAO;AAAA,MACL,YAAY,SAAS,KAAK,IAAI,UAAQ,KAAK,SAAS;AAAA,MACpD,OAAO,SAAS,QACZ,EAAE,QAAQ,SAAS,MAAM,cAAc,IACvC;AAAA,MACJ,UAAU,EAAE,SAAS,iBAAiB,MAAM,SAAS;AAAA,IACvD;AAAA,EACF;AACF;;;AG5FA,IAAAC,0BAIO;;;ACLP,IAAAC,0BAAyC;AACzC,IAAAC,aAAkB;AAIX,IAAM,gCAA4B;AAAA,EAAc,UACrD;AAAA,IACE,aAAE,OAAO;AAAA,MACP,MAAM,aAAE;AAAA,QACN,aAAE,OAAO;AAAA,UACP,UAAU,aAAE,OAAO;AAAA,UACnB,gBAAgB,aAAE,OAAO,EAAE,SAAS;AAAA,QACtC,CAAC;AAAA,MACH;AAAA,IACF,CAAC;AAAA,EACH;AACF;;;ACRO,IAAM,wBAA4D;AAAA,EACvE,YAAY;AAAA,EACZ,YAAY;AAAA,EACZ,eAAe;AAAA,EACf,oBAAoB;AACtB;AAEO,IAAM,2BAA2B,oBAAI,IAAI;AAAA,EAC9C;AAAA,EACA;AACF,CAAC;;;AFGM,IAAM,mBAAN,MAA+C;AAAA,EAWpD,YACW,SACQ,QACjB;AAFS;AACQ;AAZnB,SAAS,uBAAuB;AAAA,EAa7B;AAAA,EAXH,IAAI,mBAA2B;AAxBjC;AAyBI,YAAO,2BAAsB,KAAK,OAAO,MAAlC,YAAuC;AAAA,EAChD;AAAA,EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAOA,MAAM,WAAW;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAEE;AAhDJ;AAiDI,UAAM,WAA2C,CAAC;AAElD,QAAI,eAAe,MAAM;AACvB,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACE;AAAA,MACJ,CAAC;AAAA,IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;AAAA,IAChE;AAEA,UAAM,eAAc,sBAAK,OAAO,cAAZ,mBAAuB,gBAAvB,4CAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,OAAO,UAAU,gBAAgB,IAAI,UAAM,uCAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,wCAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;AAAA,MACtD,MAAM;AAAA,QACJ,OAAO,KAAK;AAAA,QACZ;AAAA,QACA;AAAA,QACA;AAAA,QACA,IAAI,qBAAgB,WAAhB,YAA0B,CAAC;AAAA,QAC/B,GAAI,CAAC,yBAAyB,IAAI,KAAK,OAAO,IAC1C,EAAE,iBAAiB,WAAW,IAC9B,CAAC;AAAA,MACP;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA;AAAA,MACA,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,WAAO;AAAA,MACL,QAAQ,SAAS,KAAK,IAAI,UAAQ,KAAK,QAAQ;AAAA,MAC/C;AAAA,MACA,UAAU;AAAA,QACR,WAAW;AAAA,QACX,SAAS,KAAK;AAAA,QACd,SAAS;AAAA,MACX;AAAA,MACA,kBAAkB;AAAA,QAChB,QAAQ;AAAA,UACN,QAAQ,SAAS,KAAK;AAAA,YAAI,UACxB,KAAK,iBACD;AAAA,cACE,eAAe,KAAK;AAAA,YACtB,IACA;AAAA,UACN;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;;;AG9GA,IAAAC,0BAIO;AACP,IAAAC,aAAkB;AAEX,IAAM,iCAA6B;AAAA,EAAW,UACnD;AAAA,IACE,aAAE,OAAO;AAAA,MACP,MAAM,aAAE,OAAO,EAAE,QAAQ;AAAA,MACzB,aAAa,aAAE,OAAO;AAAA,IACxB,CAAC;AAAA,EACH;AACF;AAEO,IAAM,kCAA8B;AAAA,EAAW,UACpD;AAAA,IACE,aAAE,OAAO;AAAA,MACP,SAAS,aACN;AAAA,QACC,aAAE,mBAAmB,QAAQ;AAAA,UAC3B,aAAE,OAAO,EAAE,MAAM,aAAE,QAAQ,MAAM,GAAG,MAAM,aAAE,OAAO,EAAE,CAAC;AAAA,UACtD,aAAE,OAAO,EAAE,MAAM,aAAE,QAAQ,OAAO,GAAG,KAAK,aAAE,OAAO,EAAE,CAAC;AAAA,QACxD,CAAC;AAAA,MACH,EACC,QAAQ;AAAA,IACb,CAAC;AAAA,EACH;AACF;AAEO,IAAM,gCAA4B;AAAA,EAAW,UAClD;AAAA,IACE,aAAE,OAAO;AAAA,MACP,WAAW,aACR,MAAM;AAAA,QACL,aAAE,OAAO;AAAA,QACT,aAAE,OAAO;AAAA,UACP,SAAS,aAAE,MAAM,aAAE,OAAO,CAAC,EAAE,SAAS;AAAA,QACxC,CAAC;AAAA,MACH,CAAC,EACA,SAAS;AAAA,IACd,CAAC;AAAA,EACH;AACF;AAWO,IAAM,iCACX,0EAqCE;AAAA,EACA,IAAI;AAAA,EACJ,MAAM;AAAA,EACN,aAAa;AAAA,EACb,cAAc;AAChB,CAAC;AAEI,IAAM,kBAAkB,CAC7B,OAA4B,CAAC,MAC1B;AACH,SAAO,2BAA2B,IAAI;AACxC;;;ACxGA,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAMlB,IAAM,yBAAyB,cAAE,OAAO;AAAA,EACtC,KAAK,cAAE,OAAO;AAAA,EACd,MAAM,cAAE,KAAK,CAAC,MAAM,MAAM,MAAM,OAAO,MAAM,KAAK,CAAC;AAAA,EACnD,OAAO,cAAE,MAAM,CAAC,cAAE,OAAO,GAAG,cAAE,OAAO,GAAG,cAAE,QAAQ,CAAC,CAAC;AACtD,CAAC;AAED,IAAM,uBAAuC,cAAE,OAAO;AAAA,EACpD,MAAM,cAAE,KAAK,CAAC,OAAO,IAAI,CAAC;AAAA,EAC1B,SAAS,cAAE;AAAA,IACT,cAAE,MAAM,CAAC,wBAAwB,cAAE,KAAK,MAAM,oBAAoB,CAAC,CAAC;AAAA,EACtE;AACF,CAAC;AAEM,IAAM,2BAAuB;AAAA,EAAW,UAC7C;AAAA,IACE,cAAE,OAAO;AAAA,MACP,gBAAgB,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,MAClC,eAAe,cAAE,OAAO,EAAE,SAAS;AAAA,MACnC,SAAS,cACN,OAAO;AAAA,QACN,QAAQ,cAAE,OAAO,EAAE,SAAS;AAAA,QAC5B,gBAAgB,cAAE,OAAO,EAAE,SAAS;AAAA,MACtC,CAAC,EACA,SAAS;AAAA,MACZ,SAAS,cACN,MAAM,CAAC,wBAAwB,oBAAoB,CAAC,EACpD,SAAS;AAAA,IACd,CAAC;AAAA,EACH;AACF;AAEO,IAAM,6BAAyB;AAAA,EAAW,UAC/C;AAAA,IACE,cAAE,OAAO;AAAA,MACP,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,MAC3B,SAAS,cACN;AAAA,QACC,cAAE,OAAO;AAAA,UACP,YAAY,cAAE,OAAO,cAAE,OAAO,GAAG,cAAE,QAAQ,CAAC;AAAA,UAC5C,QAAQ,cAAE,OAAO;AAAA,UACjB,UAAU,cAAE,OAAO;AAAA,UACnB,OAAO,cAAE,OAAO;AAAA,UAChB,MAAM,cAAE,OAAO;AAAA,QACjB,CAAC;AAAA,MACH,EACC,SAAS;AAAA,IACd,CAAC;AAAA,EACH;AACF;AAEO,IAAM,iBAAa,0EA+ExB;AAAA,EACA,IAAI;AAAA,EACJ,MAAM;AAAA,EACN,aAAa,cAAE,OAAO,CAAC,CAAC;AAAA,EACxB,cAAc;AAChB,CAAC;;;ACjJD,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAEX,IAAM,gCAA4B;AAAA,EAAW,UAClD;AAAA,IACE,cACG,OAAO;AAAA,MACN,YAAY,cAAE,KAAK,CAAC,QAAQ,UAAU,aAAa,CAAC,EAAE,SAAS;AAAA,MAC/D,eAAe,cAAE,KAAK,CAAC,OAAO,MAAM,CAAC,EAAE,SAAS;AAAA,MAChD,gBAAgB,cACb,OAAO;AAAA,QACN,QAAQ,cAAE,OAAO,EAAE,SAAS;AAAA,QAC5B,UAAU,cAAE,OAAO,EAAE,SAAS;AAAA,MAChC,CAAC,EACA,SAAS;AAAA,MACZ,OAAO,cAAE,OAAO,EAAE,SAAS;AAAA,MAC3B,YAAY,cAAE,KAAK,CAAC,MAAM,CAAC,EAAE,SAAS;AAAA,MACtC,mBAAmB,cAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG,EAAE,SAAS;AAAA,MAC7D,cAAc,cAAE,KAAK,CAAC,OAAO,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,MACvD,eAAe,cAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,MACvD,SAAS,cAAE,KAAK,CAAC,QAAQ,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;AAAA,MAC5D,MAAM,cACH,KAAK,CAAC,aAAa,aAAa,aAAa,MAAM,CAAC,EACpD,SAAS;AAAA,IACd,CAAC,EACA,OAAO;AAAA,EACZ;AACF;AAEA,IAAM,iCAA6B,oCAAW,UAAM,mCAAU,cAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AAEpE,IAAM,kCAA8B;AAAA,EAAW,UACpD,mCAAU,cAAE,OAAO,EAAE,QAAQ,cAAE,OAAO,EAAE,CAAC,CAAC;AAC5C;AAgEA,IAAM,iCACJ,0EASE;AAAA,EACA,IAAI;AAAA,EACJ,MAAM;AAAA,EACN,aAAa;AAAA,EACb,cAAc;AAChB,CAAC;AAEI,IAAM,kBAAkB,CAC7B,OAA4B,CAAC,MAC1B;AACH,SAAO,2BAA2B,IAAI;AACxC;;;AC1HA,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAEX,IAAM,4BAAwB;AAAA,EAAW,UAC9C;AAAA,IACE,cAAE,OAAO;AAAA,MACP,QAAQ,cAAE,OAAO;AAAA,QACf,MAAM,cAAE,QAAQ,MAAM;AAAA,QACtB,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,QAC3B,WAAW,cAAE,OAAO,EAAE,SAAS;AAAA,QAC/B,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,QAC1B,kBAAkB,cAAE,OAAO,EAAE,SAAS;AAAA,QACtC,KAAK,cAAE,OAAO,cAAE,OAAO,GAAG,cAAE,OAAO,CAAC,EAAE,SAAS;AAAA,MACjD,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AACF;AAEO,IAAM,6BAAyB;AAAA,EAAW,UAC/C,mCAAU,cAAE,OAAO,EAAE,QAAQ,cAAE,OAAO,EAAE,CAAC,CAAC;AAC5C;AAEO,IAAM,iBAAa,0EAyCxB;AAAA,EACA,IAAI;AAAA,EACJ,MAAM;AAAA,EACN,aAAa;AAAA,EACb,cAAc;AAChB,CAAC;;;ACxED,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAEX,IAAM,0BAAsB;AAAA,EAAW,UAC5C;AAAA,IACE,cAAE,OAAO;AAAA,MACP,SAAS,cACN,OAAO,EAAE,gBAAgB,cAAE,MAAM,cAAE,OAAO,CAAC,EAAE,SAAS,EAAE,CAAC,EACzD,SAAS;AAAA,MACZ,mBAAmB,cAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;AAAA,MAC9D,cAAc,cACX,OAAO;AAAA,QACN,MAAM,cAAE,QAAQ,aAAa;AAAA,QAC7B,SAAS,cAAE,OAAO,EAAE,SAAS;AAAA,QAC7B,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,QAC1B,QAAQ,cAAE,OAAO,EAAE,SAAS;AAAA,QAC5B,UAAU,cAAE,OAAO,EAAE,SAAS;AAAA,MAChC,CAAC,EACA,SAAS;AAAA,IACd,CAAC;AAAA,EACH;AACF;AAEA,IAAM,2BAAuB,oCAAW,UAAM,mCAAU,cAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AAE9D,IAAM,4BAAwB;AAAA,EAAW,UAC9C;AAAA,IACE,cAAE,OAAO;AAAA,MACP,QAAQ,cAAE,mBAAmB,QAAQ;AAAA,QACnC,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,QAAQ,QAAQ;AAAA,UACxB,OAAO,cAAE,OAAO,EAAE,SAAS;AAAA,QAC7B,CAAC;AAAA,QACD,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,QAAQ,UAAU;AAAA,UAC1B,KAAK,cAAE,OAAO;AAAA,QAChB,CAAC;AAAA,QACD,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,QAAQ,MAAM;AAAA,UACtB,KAAK,cAAE,OAAO;AAAA,UACd,SAAS,cAAE,OAAO;AAAA,QACpB,CAAC;AAAA,MACH,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AACF;AAEO,IAAM,2BACX,0EAgGE;AAAA,EACA,IAAI;AAAA,EACJ,MAAM;AAAA,EACN,aAAa;AAAA,EACb,cAAc;AAChB,CAAC;AAEI,IAAM,YAAY,CACvB,OAAmD,CAAC,MACjD,qBAAqB,IAAI;;;AC7J9B,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAEX,IAAM,iCAA6B;AAAA,EAAW,UACnD;AAAA,IACE,cAAE,OAAO;AAAA,MACP,mBAAmB,cAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;AAAA,MAC9D,cAAc,cACX,OAAO;AAAA,QACN,MAAM,cAAE,QAAQ,aAAa;AAAA,QAC7B,SAAS,cAAE,OAAO,EAAE,SAAS;AAAA,QAC7B,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,QAC1B,QAAQ,cAAE,OAAO,EAAE,SAAS;AAAA,QAC5B,UAAU,cAAE,OAAO,EAAE,SAAS;AAAA,MAChC,CAAC,EACA,SAAS;AAAA,IACd,CAAC;AAAA,EACH;AACF;AAEO,IAAM,kCAA8B;AAAA,EAAW,UACpD,mCAAU,cAAE,OAAO,CAAC,CAAC,CAAC;AACxB;AAEA,IAAM,mCAA+B;AAAA,EAAW,UAC9C;AAAA,IACE,cAAE,OAAO;AAAA,MACP,QAAQ,cAAE,mBAAmB,QAAQ;AAAA,QACnC,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,QAAQ,QAAQ;AAAA,UACxB,OAAO,cAAE,OAAO,EAAE,SAAS;AAAA,QAC7B,CAAC;AAAA,QACD,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,QAAQ,UAAU;AAAA,UAC1B,KAAK,cAAE,OAAO;AAAA,QAChB,CAAC;AAAA,QACD,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,QAAQ,MAAM;AAAA,UACtB,KAAK,cAAE,OAAO;AAAA,UACd,SAAS,cAAE,OAAO;AAAA,QACpB,CAAC;AAAA,MACH,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AACF;AAEO,IAAM,uBACX,0EAoFE;AAAA,EACA,IAAI;AAAA,EACJ,MAAM;AAAA,EACN,aAAa;AAAA,EACb,cAAc;AAChB,CAAC;;;ACrII,IAAM,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAcA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAeA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAYA;AACF;;;AClFA,IAAAC,mBAUO;AACP,IAAAC,0BASO;;;ACpBP,IAAAC,mBAKO;AACP,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAelB,SAAS,SAAS,MAAc,UAAuC;AACrE,MAAI,CAAC,SAAU,QAAO;AACtB,SAAO,SAAS,KAAK,YAAU,KAAK,WAAW,MAAM,CAAC;AACxD;AAEA,eAAsB,8BAA8B;AAAA,EAClD;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,oBAAoB;AACtB,GASG;AA9CH;AA+CE,QAAM,QAA8B,CAAC;AACrC,QAAM,WAA8C,CAAC;AAErD,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;AAAA,MACZ,KAAK,UAAU;AACb,gBAAQ,mBAAmB;AAAA,UACzB,KAAK,UAAU;AACb,kBAAM,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACtC;AAAA,UACF;AAAA,UACA,KAAK,aAAa;AAChB,kBAAM,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AACzC;AAAA,UACF;AAAA,UACA,KAAK,UAAU;AACb,qBAAS,KAAK;AAAA,cACZ,MAAM;AAAA,cACN,SAAS;AAAA,YACX,CAAC;AACD;AAAA,UACF;AAAA,UACA,SAAS;AACP,kBAAM,mBAA0B;AAChC,kBAAM,IAAI;AAAA,cACR,oCAAoC,gBAAgB;AAAA,YACtD;AAAA,UACF;AAAA,QACF;AACA;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,cAAM,KAAK;AAAA,UACT,MAAM;AAAA,UACN,SAAS,QAAQ,IAAI,CAAC,MAAM,UAAU;AAlFhD,gBAAAC,KAAAC,KAAAC;AAmFY,oBAAQ,KAAK,MAAM;AAAA,cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,cAAc,MAAM,KAAK,KAAK;AAAA,cAC/C;AAAA,cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,UAAU,WAAW,QAAQ,GAAG;AACvC,wBAAM,YACJ,KAAK,cAAc,YACf,eACA,KAAK;AAEX,yBAAO;AAAA,oBACL,MAAM;AAAA,oBACN,GAAI,KAAK,gBAAgB,MACrB,EAAE,WAAW,KAAK,KAAK,SAAS,EAAE,IAClC,OAAO,KAAK,SAAS,YACnB,SAAS,KAAK,MAAM,cAAc,IAClC,EAAE,SAAS,KAAK,KAAK,IACrB;AAAA,sBACE,WAAW,QAAQ,SAAS,eAAW,yCAAgB,KAAK,IAAI,CAAC;AAAA,oBACnE;AAAA,oBACN,SAAQD,OAAAD,MAAA,KAAK,oBAAL,gBAAAA,IAAsB,WAAtB,gBAAAC,IAA8B;AAAA,kBACxC;AAAA,gBACF,WAAW,KAAK,cAAc,mBAAmB;AAC/C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,2BAAO;AAAA,sBACL,MAAM;AAAA,sBACN,UAAU,KAAK,KAAK,SAAS;AAAA,oBAC/B;AAAA,kBACF;AACA,yBAAO;AAAA,oBACL,MAAM;AAAA,oBACN,GAAI,OAAO,KAAK,SAAS,YACzB,SAAS,KAAK,MAAM,cAAc,IAC9B,EAAE,SAAS,KAAK,KAAK,IACrB;AAAA,sBACE,WAAUC,MAAA,KAAK,aAAL,OAAAA,MAAiB,QAAQ,KAAK;AAAA,sBACxC,WAAW,mCAA+B,yCAAgB,KAAK,IAAI,CAAC;AAAA,oBACtE;AAAA,kBACN;AAAA,gBACF,OAAO;AACL,wBAAM,IAAI,+CAA8B;AAAA,oBACtC,eAAe,wBAAwB,KAAK,SAAS;AAAA,kBACvD,CAAC;AAAA,gBACH;AAAA,cACF;AAAA,YACF;AAAA,UACF,CAAC;AAAA,QACH,CAAC;AAED;AAAA,MACF;AAAA,MAEA,KAAK,aAAa;AAChB,cAAM,oBAA8D,CAAC;AACrE,cAAM,gBAA6D,CAAC;AAEpE,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,oBAAM,MAAK,gBAAK,oBAAL,mBAAsB,WAAtB,mBAA8B;AAKzC,kBAAI,SAAS,MAAM,MAAM;AACvB,sBAAM,KAAK,EAAE,MAAM,kBAAkB,GAAG,CAAC;AACzC;AAAA,cACF;AAEA,oBAAM,KAAK;AAAA,gBACT,MAAM;AAAA,gBACN,SAAS,CAAC,EAAE,MAAM,eAAe,MAAM,KAAK,KAAK,CAAC;AAAA,gBAClD;AAAA,cACF,CAAC;AAED;AAAA,YACF;AAAA,YACA,KAAK,aAAa;AAChB,4BAAc,KAAK,UAAU,IAAI;AAEjC,kBAAI,KAAK,kBAAkB;AACzB;AAAA,cACF;AAEA,oBAAM,MAAK,gBAAK,oBAAL,mBAAsB,WAAtB,mBAA8B;AAKzC,kBAAI,SAAS,MAAM,MAAM;AACvB,sBAAM,KAAK,EAAE,MAAM,kBAAkB,GAAG,CAAC;AACzC;AAAA,cACF;AAEA,kBAAI,qBAAqB,KAAK,aAAa,eAAe;AACxD,sBAAM,cAAc,UAAM,uCAAc;AAAA,kBACtC,OAAO,KAAK;AAAA,kBACZ,QAAQ;AAAA,gBACV,CAAC;AACD,sBAAM,KAAK;AAAA,kBACT,MAAM;AAAA,kBACN,SAAS,KAAK;AAAA,kBACd;AAAA,kBACA,QAAQ;AAAA,oBACN,MAAM;AAAA,oBACN,SAAS,YAAY,OAAO;AAAA,oBAC5B,YAAY,YAAY,OAAO;AAAA,oBAC/B,MAAM,YAAY,OAAO;AAAA,oBACzB,mBAAmB,YAAY,OAAO;AAAA,oBACtC,KAAK,YAAY,OAAO;AAAA,kBAC1B;AAAA,gBACF,CAAC;AAED;AAAA,cACF;AAEA,oBAAM,KAAK;AAAA,gBACT,MAAM;AAAA,gBACN,SAAS,KAAK;AAAA,gBACd,MAAM,KAAK;AAAA,gBACX,WAAW,KAAK,UAAU,KAAK,KAAK;AAAA,gBACpC;AAAA,cACF,CAAC;AACD;AAAA,YACF;AAAA;AAAA,YAGA,KAAK,eAAe;AAClB,kBAAI,OAAO;AAET,sBAAM,KAAK,EAAE,MAAM,kBAAkB,IAAI,KAAK,WAAW,CAAC;AAAA,cAC5D,OAAO;AACL,yBAAS,KAAK;AAAA,kBACZ,MAAM;AAAA,kBACN,SAAS,2BAA2B,KAAK,QAAQ;AAAA,gBACnD,CAAC;AAAA,cACH;AAEA;AAAA,YACF;AAAA,YAEA,KAAK,aAAa;AAChB,oBAAM,kBAAkB,UAAM,8CAAqB;AAAA,gBACjD,UAAU;AAAA,gBACV,iBAAiB,KAAK;AAAA,gBACtB,QAAQ;AAAA,cACV,CAAC;AAED,oBAAM,cAAc,mDAAiB;AAErC,kBAAI,eAAe,MAAM;AACvB,sBAAM,mBAAmB,kBAAkB,WAAW;AAEtD,oBAAI,OAAO;AAGT,sBAAI,qBAAqB,QAAW;AAClC,0BAAM,KAAK,EAAE,MAAM,kBAAkB,IAAI,YAAY,CAAC;AAGtD,sCAAkB,WAAW,IAAI;AAAA,sBAC/B,MAAM;AAAA,sBACN,IAAI;AAAA,sBACJ,SAAS,CAAC;AAAA,oBACZ;AAAA,kBACF;AAAA,gBACF,OAAO;AACL,wBAAM,eAGD,CAAC;AAEN,sBAAI,KAAK,KAAK,SAAS,GAAG;AACxB,iCAAa,KAAK;AAAA,sBAChB,MAAM;AAAA,sBACN,MAAM,KAAK;AAAA,oBACb,CAAC;AAAA,kBACH,WAAW,qBAAqB,QAAW;AACzC,6BAAS,KAAK;AAAA,sBACZ,MAAM;AAAA,sBACN,SAAS,+FAA+F,KAAK,UAAU,IAAI,CAAC;AAAA,oBAC9H,CAAC;AAAA,kBACH;AAEA,sBAAI,qBAAqB,QAAW;AAClC,sCAAkB,WAAW,IAAI;AAAA,sBAC/B,MAAM;AAAA,sBACN,IAAI;AAAA,sBACJ,mBACE,mDAAiB;AAAA,sBACnB,SAAS;AAAA,oBACX;AACA,0BAAM,KAAK,kBAAkB,WAAW,CAAC;AAAA,kBAC3C,OAAO;AACL,qCAAiB,QAAQ,KAAK,GAAG,YAAY;AAG7C,yBAAI,mDAAiB,8BAA6B,MAAM;AACtD,uCAAiB,oBACf,gBAAgB;AAAA,oBACpB;AAAA,kBACF;AAAA,gBACF;AAAA,cACF,OAAO;AACL,yBAAS,KAAK;AAAA,kBACZ,MAAM;AAAA,kBACN,SAAS,0EAA0E,KAAK,UAAU,IAAI,CAAC;AAAA,gBACzG,CAAC;AAAA,cACH;AACA;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAEA;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,mBAAW,QAAQ,SAAS;AAC1B,gBAAM,SAAS,KAAK;AAEpB,cACE,qBACA,KAAK,aAAa,iBAClB,OAAO,SAAS,QAChB;AACA,kBAAM,eAAe,UAAM,uCAAc;AAAA,cACvC,OAAO,OAAO;AAAA,cACd,QAAQ;AAAA,YACV,CAAC;AAED,kBAAM,KAAK;AAAA,cACT,MAAM;AAAA,cACN,SAAS,KAAK;AAAA,cACd,QAAQ,aAAa;AAAA,YACvB,CAAC;AACD;AAAA,UACF;AAEA,cAAI;AACJ,kBAAQ,OAAO,MAAM;AAAA,YACnB,KAAK;AAAA,YACL,KAAK;AACH,6BAAe,OAAO;AACtB;AAAA,YACF,KAAK;AAAA,YACL,KAAK;AACH,6BAAe,KAAK,UAAU,OAAO,KAAK;AAC1C;AAAA,YACF,KAAK;AACH,6BAAe,OAAO,MAAM,IAAI,UAAQ;AACtC,wBAAQ,KAAK,MAAM;AAAA,kBACjB,KAAK,QAAQ;AACX,2BAAO,EAAE,MAAM,cAAuB,MAAM,KAAK,KAAK;AAAA,kBACxD;AAAA,kBACA,KAAK,SAAS;AACZ,2BAAO,KAAK,UAAU,WAAW,QAAQ,IACrC;AAAA,sBACE,MAAM;AAAA,sBACN,WAAW,QAAQ,KAAK,SAAS,WAAW,KAAK,IAAI;AAAA,oBACvD,IACA;AAAA,sBACE,MAAM;AAAA,sBACN,UAAU;AAAA,sBACV,WAAW,QAAQ,KAAK,SAAS,WAAW,KAAK,IAAI;AAAA,oBACvD;AAAA,kBACN;AAAA,gBACF;AAAA,cACF,CAAC;AACD;AAAA,UACJ;AAEA,gBAAM,KAAK;AAAA,YACT,MAAM;AAAA,YACN,SAAS,KAAK;AAAA,YACd,QAAQ;AAAA,UACV,CAAC;AAAA,QACH;AAEA;AAAA,MACF;AAAA,MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAEA,SAAO,EAAE,OAAO,SAAS;AAC3B;AAEA,IAAM,gDAAgD,cAAE,OAAO;AAAA,EAC7D,QAAQ,cAAE,OAAO,EAAE,QAAQ;AAAA,EAC3B,2BAA2B,cAAE,OAAO,EAAE,QAAQ;AAChD,CAAC;;;ACzXM,SAAS,8BAA8B;AAAA,EAC5C;AAAA,EACA;AACF,GAIgC;AAC9B,UAAQ,cAAc;AAAA,IACpB,KAAK;AAAA,IACL,KAAK;AACH,aAAO,kBAAkB,eAAe;AAAA,IAC1C,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT;AACE,aAAO,kBAAkB,eAAe;AAAA,EAC5C;AACF;;;ACpBA,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AAgOX,IAAM,iCAA6B;AAAA,EAAc,UACtD;AAAA,IACE,cAAE,MAAM;AAAA,MACN,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,4BAA4B;AAAA,QAC5C,SAAS,cAAE,OAAO;AAAA,QAClB,OAAO,cAAE,OAAO;AAAA,QAChB,UAAU,cACP;AAAA,UACC,cAAE,OAAO;AAAA,YACP,OAAO,cAAE,OAAO;AAAA,YAChB,SAAS,cAAE,OAAO;AAAA,YAClB,cAAc,cAAE;AAAA,cACd,cAAE,OAAO;AAAA,gBACP,OAAO,cAAE,OAAO;AAAA,gBAChB,SAAS,cAAE,OAAO;AAAA,cACpB,CAAC;AAAA,YACH;AAAA,UACF,CAAC;AAAA,QACH,EACC,QAAQ;AAAA,MACb,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,KAAK,CAAC,sBAAsB,qBAAqB,CAAC;AAAA,QAC1D,UAAU,cAAE,OAAO;AAAA,UACjB,oBAAoB,cAAE,OAAO,EAAE,QAAQ,cAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;AAAA,UAC7D,OAAO,cAAE,OAAO;AAAA,YACd,cAAc,cAAE,OAAO;AAAA,YACvB,sBAAsB,cACnB,OAAO,EAAE,eAAe,cAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EAC9C,QAAQ;AAAA,YACX,eAAe,cAAE,OAAO;AAAA,YACxB,uBAAuB,cACpB,OAAO,EAAE,kBAAkB,cAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EACjD,QAAQ;AAAA,UACb,CAAC;AAAA,UACD,cAAc,cAAE,OAAO,EAAE,QAAQ;AAAA,QACnC,CAAC;AAAA,MACH,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,kBAAkB;AAAA,QAClC,UAAU,cAAE,OAAO;AAAA,UACjB,IAAI,cAAE,OAAO;AAAA,UACb,YAAY,cAAE,OAAO;AAAA,UACrB,OAAO,cAAE,OAAO;AAAA,UAChB,cAAc,cAAE,OAAO,EAAE,QAAQ;AAAA,QACnC,CAAC;AAAA,MACH,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,4BAA4B;AAAA,QAC5C,cAAc,cAAE,OAAO;AAAA,QACvB,MAAM,cAAE,mBAAmB,QAAQ;AAAA,UACjC,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,SAAS;AAAA,YACzB,IAAI,cAAE,OAAO;AAAA,UACf,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,WAAW;AAAA,YAC3B,IAAI,cAAE,OAAO;AAAA,YACb,mBAAmB,cAAE,OAAO,EAAE,QAAQ;AAAA,UACxC,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE,OAAO;AAAA,YAClB,MAAM,cAAE,OAAO;AAAA,YACf,WAAW,cAAE,OAAO;AAAA,UACtB,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,iBAAiB;AAAA,YACjC,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO;AAAA,UACnB,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO;AAAA,UACnB,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,kBAAkB;AAAA,YAClC,IAAI,cAAE,OAAO;AAAA,UACf,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,uBAAuB;AAAA,YACvC,IAAI,cAAE,OAAO;AAAA,UACf,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,uBAAuB;AAAA,YACvC,IAAI,cAAE,OAAO;AAAA,YACb,cAAc,cAAE,OAAO;AAAA,YACvB,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,YAC1B,SAAS,cACN;AAAA,cACC,cAAE,mBAAmB,QAAQ;AAAA,gBAC3B,cAAE,OAAO,EAAE,MAAM,cAAE,QAAQ,MAAM,GAAG,MAAM,cAAE,OAAO,EAAE,CAAC;AAAA,gBACtD,cAAE,OAAO,EAAE,MAAM,cAAE,QAAQ,OAAO,GAAG,KAAK,cAAE,OAAO,EAAE,CAAC;AAAA,cACxD,CAAC;AAAA,YACH,EACC,SAAS;AAAA,YACZ,QAAQ,cAAE,OAAO;AAAA,UACnB,CAAC;AAAA,QACH,CAAC;AAAA,MACH,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,2BAA2B;AAAA,QAC3C,cAAc,cAAE,OAAO;AAAA,QACvB,MAAM,cAAE,mBAAmB,QAAQ;AAAA,UACjC,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,SAAS;AAAA,YACzB,IAAI,cAAE,OAAO;AAAA,UACf,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,WAAW;AAAA,YAC3B,IAAI,cAAE,OAAO;AAAA,YACb,mBAAmB,cAAE,OAAO,EAAE,QAAQ;AAAA,UACxC,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE,OAAO;AAAA,YAClB,MAAM,cAAE,OAAO;AAAA,YACf,WAAW,cAAE,OAAO;AAAA,YACpB,QAAQ,cAAE,QAAQ,WAAW;AAAA,UAC/B,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,uBAAuB;AAAA,YACvC,IAAI,cAAE,OAAO;AAAA,YACb,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,YAC1B,cAAc,cAAE,OAAO;AAAA,YACvB,SAAS,cACN;AAAA,cACC,cAAE,mBAAmB,QAAQ;AAAA,gBAC3B,cAAE,OAAO,EAAE,MAAM,cAAE,QAAQ,MAAM,GAAG,MAAM,cAAE,OAAO,EAAE,CAAC;AAAA,gBACtD,cAAE,OAAO,EAAE,MAAM,cAAE,QAAQ,OAAO,GAAG,KAAK,cAAE,OAAO,EAAE,CAAC;AAAA,cACxD,CAAC;AAAA,YACH,EACC,SAAS;AAAA,UACd,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,uBAAuB;AAAA,YACvC,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO;AAAA,UACnB,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,iBAAiB;AAAA,YACjC,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO;AAAA,YACjB,QAAQ,cAAE,mBAAmB,QAAQ;AAAA,cACnC,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,QAAQ;AAAA,gBACxB,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,cAC5B,CAAC;AAAA,cACD,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,WAAW;AAAA,gBAC3B,KAAK,cAAE,OAAO;AAAA,cAChB,CAAC;AAAA,cACD,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,MAAM;AAAA,gBACtB,KAAK,cAAE,OAAO;AAAA,gBACd,SAAS,cAAE,OAAO;AAAA,cACpB,CAAC;AAAA,YACH,CAAC;AAAA,UACH,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,kBAAkB;AAAA,YAClC,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,YAC3B,SAAS,cACN;AAAA,cACC,cAAE,OAAO;AAAA,gBACP,YAAY,cAAE,OAAO,cAAE,OAAO,GAAG,cAAE,QAAQ,CAAC;AAAA,gBAC5C,SAAS,cAAE,OAAO;AAAA,gBAClB,UAAU,cAAE,OAAO;AAAA,gBACnB,OAAO,cAAE,OAAO;AAAA,gBAChB,MAAM,cAAE,OAAO;AAAA,cACjB,CAAC;AAAA,YACH,EACC,QAAQ;AAAA,UACb,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,kBAAkB;AAAA,YAClC,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE,OAAO;AAAA,YAClB,QAAQ,cAAE,OAAO;AAAA,cACf,MAAM,cAAE,QAAQ,MAAM;AAAA,cACtB,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,cAC3B,YAAY,cAAE,OAAO,EAAE,SAAS;AAAA,cAChC,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,cAC1B,mBAAmB,cAAE,OAAO,EAAE,SAAS;AAAA,cACvC,KAAK,cAAE,OAAO,cAAE,OAAO,GAAG,cAAE,OAAO,CAAC,EAAE,SAAS;AAAA,YACjD,CAAC;AAAA,UACH,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,QAAQ,WAAW;AAAA,UAC/B,CAAC;AAAA,QACH,CAAC;AAAA,MACH,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,wCAAwC;AAAA,QACxD,SAAS,cAAE,OAAO;AAAA,QAClB,cAAc,cAAE,OAAO;AAAA,QACvB,OAAO,cAAE,OAAO;AAAA,MAClB,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,8CAA8C;AAAA,QAC9D,SAAS,cAAE,OAAO;AAAA,QAClB,cAAc,cAAE,OAAO;AAAA,QACvB,mBAAmB,cAAE,OAAO;AAAA,MAC9B,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,2CAA2C;AAAA,QAC3D,SAAS,cAAE,OAAO;AAAA,QAClB,cAAc,cAAE,OAAO;AAAA,QACvB,OAAO,cAAE,OAAO;AAAA,MAClB,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,0CAA0C;AAAA,QAC1D,SAAS,cAAE,OAAO;AAAA,QAClB,cAAc,cAAE,OAAO;AAAA,QACvB,MAAM,cAAE,OAAO;AAAA,MACjB,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,uCAAuC;AAAA,QACvD,YAAY,cAAE,mBAAmB,QAAQ;AAAA,UACvC,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,cAAc;AAAA,YAC9B,KAAK,cAAE,OAAO;AAAA,YACd,OAAO,cAAE,OAAO;AAAA,UAClB,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,SAAS,cAAE,OAAO;AAAA,YAClB,UAAU,cAAE,OAAO,EAAE,QAAQ;AAAA,YAC7B,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,YAC1B,aAAa,cAAE,OAAO,EAAE,QAAQ;AAAA,YAChC,WAAW,cAAE,OAAO,EAAE,QAAQ;AAAA,YAC9B,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,UAC5B,CAAC;AAAA,QACH,CAAC;AAAA,MACH,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,uCAAuC;AAAA,QACvD,SAAS,cAAE,OAAO;AAAA,QAClB,eAAe,cAAE,OAAO;AAAA,MAC1B,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,uCAAuC;AAAA,QACvD,SAAS,cAAE,OAAO;AAAA,QAClB,eAAe,cAAE,OAAO;AAAA,QACxB,OAAO,cAAE,OAAO;AAAA,MAClB,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,sCAAsC;AAAA,QACtD,SAAS,cAAE,OAAO;AAAA,QAClB,eAAe,cAAE,OAAO;AAAA,MAC1B,CAAC;AAAA,MACD,cAAE,OAAO;AAAA,QACP,MAAM,cAAE,QAAQ,OAAO;AAAA,QACvB,MAAM,cAAE,OAAO;AAAA,QACf,SAAS,cAAE,OAAO;AAAA,QAClB,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,QAC1B,iBAAiB,cAAE,OAAO;AAAA,MAC5B,CAAC;AAAA,MACD,cACG,OAAO,EAAE,MAAM,cAAE,OAAO,EAAE,CAAC,EAC3B,MAAM,EACN,UAAU,YAAU;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,MAAM;AAAA,MACjB,EAAE;AAAA;AAAA,IACN,CAAC;AAAA,EACH;AACF;AAoBO,IAAM,oCAAgC;AAAA,EAAc,UACzD;AAAA,IACE,cAAE,OAAO;AAAA,MACP,IAAI,cAAE,OAAO;AAAA,MACb,YAAY,cAAE,OAAO;AAAA,MACrB,OAAO,cACJ,OAAO;AAAA,QACN,MAAM,cAAE,OAAO;AAAA,QACf,SAAS,cAAE,OAAO;AAAA,MACpB,CAAC,EACA,QAAQ;AAAA,MACX,OAAO,cAAE,OAAO;AAAA,MAChB,QAAQ,cAAE;AAAA,QACR,cAAE,mBAAmB,QAAQ;AAAA,UAC3B,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,SAAS;AAAA,YACzB,MAAM,cAAE,QAAQ,WAAW;AAAA,YAC3B,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE;AAAA,cACT,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,aAAa;AAAA,gBAC7B,MAAM,cAAE,OAAO;AAAA,gBACf,UAAU,cACP;AAAA,kBACC,cAAE,OAAO;AAAA,oBACP,OAAO,cAAE,OAAO;AAAA,oBAChB,SAAS,cAAE,OAAO;AAAA,oBAClB,cAAc,cAAE;AAAA,sBACd,cAAE,OAAO;AAAA,wBACP,OAAO,cAAE,OAAO;AAAA,wBAChB,SAAS,cAAE,OAAO;AAAA,sBACpB,CAAC;AAAA,oBACH;AAAA,kBACF,CAAC;AAAA,gBACH,EACC,QAAQ;AAAA,gBACX,aAAa,cAAE;AAAA,kBACb,cAAE,mBAAmB,QAAQ;AAAA,oBAC3B,cAAE,OAAO;AAAA,sBACP,MAAM,cAAE,QAAQ,cAAc;AAAA,sBAC9B,aAAa,cAAE,OAAO;AAAA,sBACtB,WAAW,cAAE,OAAO;AAAA,sBACpB,KAAK,cAAE,OAAO;AAAA,sBACd,OAAO,cAAE,OAAO;AAAA,oBAClB,CAAC;AAAA,oBACD,cAAE,OAAO;AAAA,sBACP,MAAM,cAAE,QAAQ,eAAe;AAAA,sBAC/B,SAAS,cAAE,OAAO;AAAA,sBAClB,UAAU,cAAE,OAAO,EAAE,QAAQ;AAAA,sBAC7B,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,sBAC1B,aAAa,cAAE,OAAO,EAAE,QAAQ;AAAA,sBAChC,WAAW,cAAE,OAAO,EAAE,QAAQ;AAAA,sBAC9B,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,oBAC5B,CAAC;AAAA,oBACD,cAAE,OAAO;AAAA,sBACP,MAAM,cAAE,QAAQ,yBAAyB;AAAA,oBAC3C,CAAC;AAAA,kBACH,CAAC;AAAA,gBACH;AAAA,cACF,CAAC;AAAA,YACH;AAAA,UACF,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,iBAAiB;AAAA,YACjC,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO;AAAA,YACjB,QAAQ,cAAE,mBAAmB,QAAQ;AAAA,cACnC,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,QAAQ;AAAA,gBACxB,OAAO,cAAE,OAAO,EAAE,QAAQ;AAAA,cAC5B,CAAC;AAAA,cACD,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,WAAW;AAAA,gBAC3B,KAAK,cAAE,OAAO;AAAA,cAChB,CAAC;AAAA,cACD,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,MAAM;AAAA,gBACtB,KAAK,cAAE,OAAO;AAAA,gBACd,SAAS,cAAE,OAAO;AAAA,cACpB,CAAC;AAAA,YACH,CAAC;AAAA,UACH,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,kBAAkB;AAAA,YAClC,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,YAC3B,SAAS,cACN;AAAA,cACC,cAAE,OAAO;AAAA,gBACP,YAAY,cAAE,OAAO,cAAE,OAAO,GAAG,cAAE,QAAQ,CAAC;AAAA,gBAC5C,SAAS,cAAE,OAAO;AAAA,gBAClB,UAAU,cAAE,OAAO;AAAA,gBACnB,OAAO,cAAE,OAAO;AAAA,gBAChB,MAAM,cAAE,OAAO;AAAA,cACjB,CAAC;AAAA,YACH,EACC,QAAQ;AAAA,UACb,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,uBAAuB;AAAA,YACvC,IAAI,cAAE,OAAO;AAAA,YACb,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,YAC1B,cAAc,cAAE,OAAO;AAAA,YACvB,SAAS,cACN;AAAA,cACC,cAAE,mBAAmB,QAAQ;AAAA,gBAC3B,cAAE,OAAO,EAAE,MAAM,cAAE,QAAQ,MAAM,GAAG,MAAM,cAAE,OAAO,EAAE,CAAC;AAAA,gBACtD,cAAE,OAAO,EAAE,MAAM,cAAE,QAAQ,OAAO,GAAG,KAAK,cAAE,OAAO,EAAE,CAAC;AAAA,cACxD,CAAC;AAAA,YACH,EACC,SAAS;AAAA,UACd,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,uBAAuB;AAAA,YACvC,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO;AAAA,UACnB,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,kBAAkB;AAAA,YAClC,IAAI,cAAE,OAAO;AAAA,YACb,SAAS,cAAE,OAAO;AAAA,YAClB,QAAQ,cAAE,OAAO;AAAA,cACf,MAAM,cAAE,QAAQ,MAAM;AAAA,cACtB,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,cAC3B,YAAY,cAAE,OAAO,EAAE,SAAS;AAAA,cAChC,MAAM,cAAE,OAAO,EAAE,SAAS;AAAA,cAC1B,mBAAmB,cAAE,OAAO,EAAE,SAAS;AAAA,cACvC,KAAK,cAAE,OAAO,cAAE,OAAO,GAAG,cAAE,OAAO,CAAC,EAAE,SAAS;AAAA,YACjD,CAAC;AAAA,UACH,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,SAAS,cAAE,OAAO;AAAA,YAClB,MAAM,cAAE,OAAO;AAAA,YACf,WAAW,cAAE,OAAO;AAAA,YACpB,IAAI,cAAE,OAAO;AAAA,UACf,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,eAAe;AAAA,YAC/B,IAAI,cAAE,OAAO;AAAA,YACb,QAAQ,cAAE,OAAO,EAAE,SAAS;AAAA,UAC9B,CAAC;AAAA,UACD,cAAE,OAAO;AAAA,YACP,MAAM,cAAE,QAAQ,WAAW;AAAA,YAC3B,IAAI,cAAE,OAAO;AAAA,YACb,mBAAmB,cAAE,OAAO,EAAE,QAAQ;AAAA,YACtC,SAAS,cAAE;AAAA,cACT,cAAE,OAAO;AAAA,gBACP,MAAM,cAAE,QAAQ,cAAc;AAAA,gBAC9B,MAAM,cAAE,OAAO;AAAA,cACjB,CAAC;AAAA,YACH;AAAA,UACF,CAAC;AAAA,QACH,CAAC;AAAA,MACH;AAAA,MACA,cAAc,cAAE,OAAO,EAAE,QAAQ;AAAA,MACjC,oBAAoB,cAAE,OAAO,EAAE,QAAQ,cAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;AAAA,MAC7D,OAAO,cAAE,OAAO;AAAA,QACd,cAAc,cAAE,OAAO;AAAA,QACvB,sBAAsB,cACnB,OAAO,EAAE,eAAe,cAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EAC9C,QAAQ;AAAA,QACX,eAAe,cAAE,OAAO;AAAA,QACxB,uBAAuB,cACpB,OAAO,EAAE,kBAAkB,cAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EACjD,QAAQ;AAAA,MACb,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AACF;;;ACrrBA,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AASX,IAAM,mBAAmB;AAEzB,IAAM,mCAAmC;AAAA,EAC9C;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAEO,IAAM,0BAA0B;AAAA,EACrC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,GAAG;AACL;AA0CO,IAAM,2CAAuC;AAAA,EAAc,UAChE;AAAA,IACE,cAAE,OAAO;AAAA,MACP,SAAS,cACN;AAAA,QACC,cAAE,KAAK;AAAA,UACL;AAAA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH,EACC,QAAQ;AAAA,MACX,cAAc,cAAE,OAAO,EAAE,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAcjC,UAAU,cACP,MAAM,CAAC,cAAE,QAAQ,GAAG,cAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,gBAAgB,CAAC,CAAC,EAC5D,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOZ,cAAc,cAAE,OAAO,EAAE,QAAQ;AAAA,MAEjC,UAAU,cAAE,IAAI,EAAE,QAAQ;AAAA,MAC1B,mBAAmB,cAAE,QAAQ,EAAE,QAAQ;AAAA,MACvC,oBAAoB,cAAE,OAAO,EAAE,QAAQ;AAAA,MACvC,gBAAgB,cAAE,OAAO,EAAE,QAAQ;AAAA,MACnC,iBAAiB,cAAE,OAAO,EAAE,QAAQ;AAAA,MACpC,kBAAkB,cAAE,OAAO,EAAE,QAAQ;AAAA,MACrC,kBAAkB,cAAE,OAAO,EAAE,QAAQ;AAAA,MACrC,aAAa,cAAE,KAAK,CAAC,QAAQ,QAAQ,YAAY,SAAS,CAAC,EAAE,QAAQ;AAAA,MACrE,OAAO,cAAE,QAAQ,EAAE,QAAQ;AAAA,MAC3B,kBAAkB,cAAE,QAAQ,EAAE,QAAQ;AAAA,MACtC,eAAe,cAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,QAAQ;AAAA,MACzD,YAAY,cAAE,KAAK,CAAC,QAAQ,UAAU,CAAC,EAAE,QAAQ;AAAA,MACjD,MAAM,cAAE,OAAO,EAAE,QAAQ;AAAA,IAC3B,CAAC;AAAA,EACH;AACF;;;ACvKA,IAAAC,mBAIO;AAOP,IAAAC,0BAA8B;AAE9B,eAAsB,sBAAsB;AAAA,EAC1C;AAAA,EACA;AAAA,EACA;AACF,GAiBG;AAED,WAAQ,+BAAO,UAAS,QAAQ;AAEhC,QAAM,eAA6C,CAAC;AAEpD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;AAAA,EACjE;AAEA,QAAMC,eAA0C,CAAC;AAEjD,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;AAAA,MACjB,KAAK;AACH,QAAAA,aAAY,KAAK;AAAA,UACf,MAAM;AAAA,UACN,MAAM,KAAK;AAAA,UACX,aAAa,KAAK;AAAA,UAClB,YAAY,KAAK;AAAA,UACjB,QAAQ;AAAA,QACV,CAAC;AACD;AAAA,MACF,KAAK,oBAAoB;AACvB,gBAAQ,KAAK,IAAI;AAAA,UACf,KAAK,sBAAsB;AACzB,kBAAM,OAAO,UAAM,uCAAc;AAAA,cAC/B,OAAO,KAAK;AAAA,cACZ,QAAQ;AAAA,YACV,CAAC;AAED,YAAAA,aAAY,KAAK;AAAA,cACf,MAAM;AAAA,cACN,kBAAkB,KAAK;AAAA,cACvB,iBAAiB,KAAK;AAAA,cACtB,iBAAiB,KAAK,UAClB;AAAA,gBACE,QAAQ,KAAK,QAAQ;AAAA,gBACrB,iBAAiB,KAAK,QAAQ;AAAA,cAChC,IACA;AAAA,cACJ,SAAS,KAAK;AAAA,YAChB,CAAC;AAED;AAAA,UACF;AAAA,UACA,KAAK,sBAAsB;AACzB,YAAAA,aAAY,KAAK;AAAA,cACf,MAAM;AAAA,YACR,CAAC;AACD;AAAA,UACF;AAAA,UACA,KAAK,6BAA6B;AAChC,kBAAM,OAAO,UAAM,uCAAc;AAAA,cAC/B,OAAO,KAAK;AAAA,cACZ,QAAQ;AAAA,YACV,CAAC;AACD,YAAAA,aAAY,KAAK;AAAA,cACf,MAAM;AAAA,cACN,qBAAqB,KAAK;AAAA,cAC1B,eAAe,KAAK;AAAA,YACtB,CAAC;AACD;AAAA,UACF;AAAA,UACA,KAAK,qBAAqB;AACxB,kBAAM,OAAO,UAAM,uCAAc;AAAA,cAC/B,OAAO,KAAK;AAAA,cACZ,QAAQ;AAAA,YACV,CAAC;AACD,YAAAA,aAAY,KAAK;AAAA,cACf,MAAM;AAAA,cACN,SACE,KAAK,WAAW,OACZ,EAAE,iBAAiB,KAAK,QAAQ,eAAe,IAC/C;AAAA,cACN,qBAAqB,KAAK;AAAA,cAC1B,eAAe,KAAK;AAAA,YACtB,CAAC;AACD;AAAA,UACF;AAAA,UACA,KAAK,2BAA2B;AAC9B,kBAAM,OAAO,UAAM,uCAAc;AAAA,cAC/B,OAAO,KAAK;AAAA,cACZ,QAAQ;AAAA,YACV,CAAC;AAED,YAAAA,aAAY,KAAK;AAAA,cACf,MAAM;AAAA,cACN,WACE,KAAK,aAAa,OACd,EAAE,MAAM,QAAQ,UAAU,OAAU,IACpC,OAAO,KAAK,cAAc,WACxB,KAAK,YACL,EAAE,MAAM,QAAQ,UAAU,KAAK,UAAU,QAAQ;AAAA,YAC3D,CAAC;AACD;AAAA,UACF;AAAA,UACA,KAAK,2BAA2B;AAC9B,kBAAM,OAAO,UAAM,uCAAc;AAAA,cAC/B,OAAO,KAAK;AAAA,cACZ,QAAQ;AAAA,YACV,CAAC;AAED,YAAAA,aAAY,KAAK;AAAA,cACf,MAAM;AAAA,cACN,YAAY,KAAK;AAAA,cACjB,gBAAgB,KAAK;AAAA,cACrB,kBAAkB,KAAK,iBACnB;AAAA,gBACE,SAAS,KAAK,eAAe;AAAA,gBAC7B,WAAW,KAAK,eAAe;AAAA,cACjC,IACA;AAAA,cACJ,OAAO,KAAK;AAAA,cACZ,MAAM,KAAK;AAAA,cACX,SAAS,KAAK;AAAA,cACd,YAAY,KAAK;AAAA,cACjB,eAAe,KAAK;AAAA,cACpB,oBAAoB,KAAK;AAAA,YAC3B,CAAC;AACD;AAAA,UACF;AAAA,QACF;AACA;AAAA,MACF;AAAA,MACA;AACE,qBAAa,KAAK,EAAE,MAAM,oBAAoB,KAAK,CAAC;AACpD;AAAA,IACJ;AAAA,EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAOA,cAAa,YAAY,QAAW,aAAa;AAAA,EACnE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;AAAA,IACZ,KAAK;AAAA,IACL,KAAK;AAAA,IACL,KAAK;AACH,aAAO,EAAE,OAAOA,cAAa,YAAY,MAAM,aAAa;AAAA,IAC9D,KAAK;AACH,aAAO;AAAA,QACL,OAAOA;AAAA,QACP,YACE,WAAW,aAAa,sBACxB,WAAW,aAAa,iBACxB,WAAW,aAAa,sBACxB,WAAW,aAAa,wBACxB,WAAW,aAAa,eACpB,EAAE,MAAM,WAAW,SAAS,IAC5B,EAAE,MAAM,YAAY,MAAM,WAAW,SAAS;AAAA,QACpD;AAAA,MACF;AAAA,IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAI,+CAA8B;AAAA,QACtC,eAAe,qBAAqB,gBAAgB;AAAA,MACtD,CAAC;AAAA,IACH;AAAA,EACF;AACF;;;ALnJO,IAAM,+BAAN,MAA8D;AAAA,EAOnE,YAAY,SAAiC,QAAsB;AANnE,SAAS,uBAAuB;AAWhC,SAAS,gBAA0C;AAAA,MACjD,WAAW,CAAC,iBAAiB;AAAA,MAC7B,mBAAmB,CAAC,iBAAiB;AAAA,IACvC;AAPE,SAAK,UAAU;AACf,SAAK,SAAS;AAAA,EAChB;AAAA,EAOA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,MAAc,QAAQ;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAAiD;AApFnD;AAqFI,UAAM,WAAyC,CAAC;AAChD,UAAM,cAAc,wBAAwB,KAAK,OAAO;AAExD,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;AAAA,IAChE;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;AAAA,IAChE;AAEA,QAAI,mBAAmB,MAAM;AAC3B,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAEA,QAAI,oBAAoB,MAAM;AAC5B,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAEA,QAAI,iBAAiB,MAAM;AACzB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,gBAAgB,CAAC;AAAA,IACzE;AAEA,UAAM,gBAAgB,UAAM,8CAAqB;AAAA,MAC/C,UAAU;AAAA,MACV;AAAA,MACA,QAAQ;AAAA,IACV,CAAC;AAED,UAAM,EAAE,OAAO,UAAU,cAAc,IACrC,MAAM,8BAA8B;AAAA,MAClC;AAAA,MACA,mBAAmB,YAAY;AAAA,MAC/B,gBAAgB,KAAK,OAAO;AAAA,MAC5B,QAAO,oDAAe,UAAf,YAAwB;AAAA,MAC/B,mBAAmB,cAAc,oBAAoB;AAAA,IACvD,CAAC;AAEH,aAAS,KAAK,GAAG,aAAa;AAE9B,UAAM,oBAAmB,oDAAe,qBAAf,YAAmC;AAE5D,QAAI,UAAyC,+CAAe;AAE5D,aAAS,WAAW,KAAkC;AACpD,UAAI,WAAW,MAAM;AACnB,kBAAU,CAAC,GAAG;AAAA,MAChB,WAAW,CAAC,QAAQ,SAAS,GAAG,GAAG;AACjC,kBAAU,CAAC,GAAG,SAAS,GAAG;AAAA,MAC5B;AAAA,IACF;AAEA,aAAS,cAAc,IAAY;AACjC,cACE,+BAAO;AAAA,QACL,UAAQ,KAAK,SAAS,sBAAsB,KAAK,OAAO;AAAA,YACrD;AAAA,IAET;AAGA,UAAM,cACJ,QAAO,+CAAe,cAAa,WAC/B,+CAAe,YACf,+CAAe,cAAa,OAC1B,mBACA;AAER,QAAI,aAAa;AACf,iBAAW,8BAA8B;AAAA,IAC3C;AAGA,UAAM,qBACJ,oCAAO;AAAA,MACL,UACE,KAAK,SAAS,uBACb,KAAK,OAAO,uBACX,KAAK,OAAO;AAAA,UAJlB,mBAMC;AAEH,QAAI,mBAAmB;AACrB,iBAAW,gCAAgC;AAAA,IAC7C;AAGA,QAAI,cAAc,yBAAyB,GAAG;AAC5C,iBAAW,+BAA+B;AAAA,IAC5C;AAEA,UAAM,QAAQ,+CAAe;AAG7B,QAAI,UAAU,SAAS,YAAY,kBAAkB;AACnD,iBAAW,6BAA6B;AAAA,IAC1C;AAEA,UAAM,WAAW;AAAA,MACf,OAAO,KAAK;AAAA,MACZ;AAAA,MACA;AAAA,MACA,OAAO;AAAA,MACP,mBAAmB;AAAA,MAEnB,KAAK,iDAAgB,UAAS,WAAU,+CAAe,mBAAkB;AAAA,QACvE,MAAM;AAAA,UACJ,IAAI,iDAAgB,UAAS,UAAU;AAAA,YACrC,QACE,eAAe,UAAU,OACrB;AAAA,cACE,MAAM;AAAA,cACN,QAAQ;AAAA,cACR,OAAM,oBAAe,SAAf,YAAuB;AAAA,cAC7B,aAAa,eAAe;AAAA,cAC5B,QAAQ,eAAe;AAAA,YACzB,IACA,EAAE,MAAM,cAAc;AAAA,UAC9B;AAAA,UACA,IAAI,+CAAe,kBAAiB;AAAA,YAClC,WAAW,cAAc;AAAA,UAC3B;AAAA,QACF;AAAA,MACF;AAAA;AAAA,MAGA,gBAAgB,+CAAe;AAAA,MAC/B,UAAU,+CAAe;AAAA,MACzB,qBAAqB,+CAAe;AAAA,MACpC,sBAAsB,+CAAe;AAAA,MACrC;AAAA,MACA,MAAM,+CAAe;AAAA,MACrB,cAAc,+CAAe;AAAA,MAC7B,cAAc,+CAAe;AAAA,MAC7B;AAAA,MACA,kBAAkB,+CAAe;AAAA,MACjC,mBAAmB,+CAAe;AAAA,MAClC,cAAc;AAAA,MACd,YAAY,+CAAe;AAAA;AAAA,MAG3B,GAAI,YAAY,sBACb,+CAAe,oBAAmB,SACjC,+CAAe,qBAAoB,SAAS;AAAA,QAC5C,WAAW;AAAA,UACT,IAAI,+CAAe,oBAAmB,QAAQ;AAAA,YAC5C,QAAQ,cAAc;AAAA,UACxB;AAAA,UACA,IAAI,+CAAe,qBAAoB,QAAQ;AAAA,YAC7C,SAAS,cAAc;AAAA,UACzB;AAAA,QACF;AAAA,MACF;AAAA,IACJ;AAEA,QAAI,YAAY,kBAAkB;AAGhC,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAEA,UAAI,SAAS,SAAS,MAAM;AAC1B,iBAAS,QAAQ;AACjB,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAAA,IACF,OAAO;AACL,WAAI,+CAAe,oBAAmB,MAAM;AAC1C,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAEA,WAAI,+CAAe,qBAAoB,MAAM;AAC3C,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAAA,IACF;AAGA,SACE,+CAAe,iBAAgB,UAC/B,CAAC,YAAY,wBACb;AACA,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACE;AAAA,MACJ,CAAC;AAED,aAAQ,SAAiB;AAAA,IAC3B;AAGA,SACE,+CAAe,iBAAgB,cAC/B,CAAC,YAAY,4BACb;AACA,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACE;AAAA,MACJ,CAAC;AAED,aAAQ,SAAiB;AAAA,IAC3B;AAEA,UAAM;AAAA,MACJ,OAAOC;AAAA,MACP,YAAY;AAAA,MACZ;AAAA,IACF,IAAI,MAAM,sBAAsB;AAAA,MAC9B;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAED,WAAO;AAAA,MACL;AAAA,MACA,MAAM;AAAA,QACJ,GAAG;AAAA,QACH,OAAOA;AAAA,QACP,aAAa;AAAA,MACf;AAAA,MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;AAAA,MACvC;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,WACJ,SAC6D;AAlVjE;AAmVI,UAAM;AAAA,MACJ,MAAM;AAAA,MACN;AAAA,MACA;AAAA,IACF,IAAI,MAAM,KAAK,QAAQ,OAAO;AAC9B,UAAM,MAAM,KAAK,OAAO,IAAI;AAAA,MAC1B,MAAM;AAAA,MACN,SAAS,KAAK;AAAA,IAChB,CAAC;AAED,UAAM;AAAA,MACJ;AAAA,MACA,OAAO;AAAA,MACP,UAAU;AAAA,IACZ,IAAI,UAAM,uCAAc;AAAA,MACtB;AAAA,MACA,aAAS,wCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,QAAI,SAAS,OAAO;AAClB,YAAM,IAAI,8BAAa;AAAA,QACrB,SAAS,SAAS,MAAM;AAAA,QACxB;AAAA,QACA,mBAAmB;AAAA,QACnB,YAAY;AAAA,QACZ;AAAA,QACA,cAAc;AAAA,QACd,aAAa;AAAA,MACf,CAAC;AAAA,IACH;AAEA,UAAM,UAAyC,CAAC;AAChD,UAAM,WAA2C,CAAC;AAGlD,QAAI,kBAAkB;AAGtB,eAAW,QAAQ,SAAS,QAAQ;AAClC,cAAQ,KAAK,MAAM;AAAA,QACjB,KAAK,aAAa;AAEhB,cAAI,KAAK,QAAQ,WAAW,GAAG;AAC7B,iBAAK,QAAQ,KAAK,EAAE,MAAM,gBAAgB,MAAM,GAAG,CAAC;AAAA,UACtD;AAEA,qBAAW,WAAW,KAAK,SAAS;AAClC,oBAAQ,KAAK;AAAA,cACX,MAAM;AAAA,cACN,MAAM,QAAQ;AAAA,cACd,kBAAkB;AAAA,gBAChB,QAAQ;AAAA,kBACN,QAAQ,KAAK;AAAA,kBACb,4BAA2B,UAAK,sBAAL,YAA0B;AAAA,gBACvD;AAAA,cACF;AAAA,YACF,CAAC;AAAA,UACH;AACA;AAAA,QACF;AAAA,QAEA,KAAK,yBAAyB;AAC5B,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,OAAO;AAAA,YACP,kBAAkB;AAAA,UACpB,CAAC;AAED,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,QAAQ;AAAA,cACN,QAAQ,KAAK;AAAA,YACf;AAAA,YACA,kBAAkB;AAAA,UACpB,CAAC;AAED;AAAA,QACF;AAAA,QAEA,KAAK,oBAAoB;AACvB,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,OAAO,KAAK,UAAU;AAAA,cACpB,QAAQ,KAAK;AAAA,YACf,CAAwD;AAAA,YACxD,kBAAkB;AAAA,cAChB,QAAQ;AAAA,gBACN,QAAQ,KAAK;AAAA,cACf;AAAA,YACF;AAAA,UACF,CAAC;AAED;AAAA,QACF;AAAA,QAEA,KAAK,WAAW;AACd,qBAAW,eAAe,KAAK,SAAS;AACtC,kBACE,mBAAQ,oBAAR,mBAAyB,WAAzB,mBAAiC,aACjC,YAAY,UACZ;AACA,uBAAS,KAAK,YAAY,QAAQ;AAAA,YACpC;AAEA,oBAAQ,KAAK;AAAA,cACX,MAAM;AAAA,cACN,MAAM,YAAY;AAAA,cAClB,kBAAkB;AAAA,gBAChB,QAAQ;AAAA,kBACN,QAAQ,KAAK;AAAA,gBACf;AAAA,cACF;AAAA,YACF,CAAC;AAED,uBAAW,cAAc,YAAY,aAAa;AAChD,kBAAI,WAAW,SAAS,gBAAgB;AACtC,wBAAQ,KAAK;AAAA,kBACX,MAAM;AAAA,kBACN,YAAY;AAAA,kBACZ,KAAI,sBAAK,QAAO,eAAZ,gDAA8B,oCAAW;AAAA,kBAC7C,KAAK,WAAW;AAAA,kBAChB,OAAO,WAAW;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,WAAW,SAAS,iBAAiB;AAC9C,wBAAQ,KAAK;AAAA,kBACX,MAAM;AAAA,kBACN,YAAY;AAAA,kBACZ,KAAI,sBAAK,QAAO,eAAZ,gDAA8B,oCAAW;AAAA,kBAC7C,WAAW;AAAA,kBACX,QAAO,sBAAW,UAAX,YAAoB,WAAW,aAA/B,YAA2C;AAAA,kBAClD,WAAU,gBAAW,aAAX,YAAuB,WAAW;AAAA,gBAC9C,CAAC;AAAA,cACH;AAAA,YACF;AAAA,UACF;AAEA;AAAA,QACF;AAAA,QAEA,KAAK,iBAAiB;AACpB,4BAAkB;AAElB,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU,KAAK;AAAA,YACf,OAAO,KAAK;AAAA,YACZ,kBAAkB;AAAA,cAChB,QAAQ;AAAA,gBACN,QAAQ,KAAK;AAAA,cACf;AAAA,YACF;AAAA,UACF,CAAC;AACD;AAAA,QACF;AAAA,QAEA,KAAK,mBAAmB;AACtB,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU,gDAAqB;AAAA,YAC/B,OAAO,KAAK,UAAU,CAAC,CAAC;AAAA,YACxB,kBAAkB;AAAA,UACpB,CAAC;AAED,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU,gDAAqB;AAAA,YAC/B,QAAQ,mBAAmB,KAAK,MAAM;AAAA,YACtC,kBAAkB;AAAA,UACpB,CAAC;AAED;AAAA,QACF;AAAA,QAEA,KAAK,iBAAiB;AACpB,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,OAAO;AAAA,YACP,kBAAkB;AAAA,UACpB,CAAC;AAED,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,QAAQ;AAAA,cACN,MAAM;AAAA,cACN,QAAQ,KAAK,UAAU;AAAA,YACzB;AAAA,YACA,kBAAkB;AAAA,UACpB,CAAC;AACD;AAAA,QACF;AAAA,QAEA,KAAK,oBAAoB;AACvB,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,OAAO;AAAA,YACP,kBAAkB;AAAA,UACpB,CAAC;AAED,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,QAAQ;AAAA,cACN,SAAS,KAAK;AAAA,cACd,UACE,gBAAK,YAAL,mBAAc,IAAI,aAAW;AAAA,gBAC3B,YAAY,OAAO;AAAA,gBACnB,QAAQ,OAAO;AAAA,gBACf,UAAU,OAAO;AAAA,gBACjB,OAAO,OAAO;AAAA,gBACd,MAAM,OAAO;AAAA,cACf,QANA,YAMO;AAAA,YACX;AAAA,YACA,kBAAkB;AAAA,UACpB,CAAC;AACD;AAAA,QACF;AAAA,QAEA,KAAK,yBAAyB;AAC5B,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,OAAO,KAAK,UAAU;AAAA,cACpB,MAAM,KAAK;AAAA,cACX,aAAa,KAAK;AAAA,YACpB,CAA6D;AAAA,YAC7D,kBAAkB;AAAA,UACpB,CAAC;AAED,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,YAAY,KAAK;AAAA,YACjB,UAAU;AAAA,YACV,QAAQ;AAAA,cACN,SAAS,KAAK;AAAA,YAChB;AAAA,YACA,kBAAkB;AAAA,UACpB,CAAC;AACD;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,UAAM,mBAA6C;AAAA,MACjD,QAAQ,EAAE,YAAY,SAAS,GAAG;AAAA,IACpC;AAEA,QAAI,SAAS,SAAS,GAAG;AACvB,uBAAiB,OAAO,WAAW;AAAA,IACrC;AAEA,QAAI,OAAO,SAAS,iBAAiB,UAAU;AAC7C,uBAAiB,OAAO,cAAc,SAAS;AAAA,IACjD;AAEA,WAAO;AAAA,MACL;AAAA,MACA,cAAc,8BAA8B;AAAA,QAC1C,eAAc,cAAS,uBAAT,mBAA6B;AAAA,QAC3C;AAAA,MACF,CAAC;AAAA,MACD,OAAO;AAAA,QACL,aAAa,SAAS,MAAM;AAAA,QAC5B,cAAc,SAAS,MAAM;AAAA,QAC7B,aAAa,SAAS,MAAM,eAAe,SAAS,MAAM;AAAA,QAC1D,kBACE,oBAAS,MAAM,0BAAf,mBAAsC,qBAAtC,YAA0D;AAAA,QAC5D,oBACE,oBAAS,MAAM,yBAAf,mBAAqC,kBAArC,YAAsD;AAAA,MAC1D;AAAA,MACA,SAAS,EAAE,KAAK;AAAA,MAChB,UAAU;AAAA,QACR,IAAI,SAAS;AAAA,QACb,WAAW,IAAI,KAAK,SAAS,aAAa,GAAI;AAAA,QAC9C,SAAS,SAAS;AAAA,QAClB,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM;AAAA,MACJ,MAAM;AAAA,MACN;AAAA,MACA;AAAA,MACA;AAAA,IACF,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE9B,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,UAAM,uCAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,wCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D,MAAM;AAAA,QACJ,GAAG;AAAA,QACH,QAAQ;AAAA,MACV;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,OAAO;AAEb,QAAI,eAA4C;AAChD,UAAM,QAA8B;AAAA,MAClC,aAAa;AAAA,MACb,cAAc;AAAA,MACd,aAAa;AAAA,IACf;AACA,UAAM,WAA2C,CAAC;AAClD,QAAI,aAA4B;AAChC,UAAM,mBAUF,CAAC;AAGL,QAAI,kBAAkB;AAEtB,UAAM,kBAOF,CAAC;AAEL,QAAI;AAEJ,WAAO;AAAA,MACL,QAAQ,SAAS;AAAA,QACf,IAAI,gBAGF;AAAA,UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;AAAA,UACvD;AAAA,UAEA,UAAU,OAAO,YAAY;AA/sBvC;AAgtBY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;AAAA,YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,kBAAM,QAAQ,MAAM;AAEpB,gBAAI,+BAA+B,KAAK,GAAG;AACzC,kBAAI,MAAM,KAAK,SAAS,iBAAiB;AACvC,iCAAiB,MAAM,YAAY,IAAI;AAAA,kBACrC,UAAU,MAAM,KAAK;AAAA,kBACrB,YAAY,MAAM,KAAK;AAAA,gBACzB;AAEA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,kBACf,UAAU,MAAM,KAAK;AAAA,gBACvB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,mBAAmB;AAChD,iCAAiB,MAAM,YAAY,IAAI;AAAA,kBACrC,UAAU,gDAAqB;AAAA,kBAC/B,YAAY,MAAM,KAAK;AAAA,gBACzB;AAEA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,kBACf,UAAU,gDAAqB;AAAA,kBAC/B,kBAAkB;AAAA,gBACpB,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,gBACjB,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,OAAO,KAAK,UAAU,CAAC,CAAC;AAAA,kBACxB,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;AAAA,kBACrC,UAAU;AAAA,kBACV,YAAY,MAAM,KAAK;AAAA,gBACzB;AAEA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,kBACf,UAAU;AAAA,kBACV,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,iCAAiB,MAAM,YAAY,IAAI;AAAA,kBACrC,UAAU;AAAA,kBACV,YAAY,MAAM,KAAK;AAAA,kBACvB,iBAAiB;AAAA,oBACf,aAAa,MAAM,KAAK;AAAA,kBAC1B;AAAA,gBACF;AAEA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,kBACf,UAAU;AAAA,kBACV,kBAAkB;AAAA,gBACpB,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,kBACf,OAAO,mBAAmB,MAAM,KAAK,YAAY;AAAA,gBACnD,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,OAAO;AAAA,kBACP,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,OAAO;AAAA,kBACP,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,WAAW;AACxC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,kBACf,kBAAkB;AAAA,oBAChB,QAAQ;AAAA,sBACN,QAAQ,MAAM,KAAK;AAAA,oBACrB;AAAA,kBACF;AAAA,gBACF,CAAC;AAAA,cACH,WACE,+BAA+B,KAAK,KACpC,MAAM,KAAK,SAAS,aACpB;AACA,gCAAgB,MAAM,KAAK,EAAE,IAAI;AAAA,kBAC/B,kBAAkB,MAAM,KAAK;AAAA,kBAC7B,cAAc,EAAE,GAAG,SAAS;AAAA,gBAC9B;AAEA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,GAAG,MAAM,KAAK,EAAE;AAAA,kBACpB,kBAAkB;AAAA,oBAChB,QAAQ;AAAA,sBACN,QAAQ,MAAM,KAAK;AAAA,sBACnB,4BACE,WAAM,KAAK,sBAAX,YAAgC;AAAA,oBACpC;AAAA,kBACF;AAAA,gBACF,CAAC;AAAA,cACH;AAAA,YACF,WAAW,8BAA8B,KAAK,GAAG;AAC/C,kBAAI,MAAM,KAAK,SAAS,iBAAiB;AACvC,iCAAiB,MAAM,YAAY,IAAI;AACvC,kCAAkB;AAElB,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,gBACjB,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU,MAAM,KAAK;AAAA,kBACrB,OAAO,MAAM,KAAK;AAAA,kBAClB,kBAAkB;AAAA,oBAChB,QAAQ;AAAA,sBACN,QAAQ,MAAM,KAAK;AAAA,oBACrB;AAAA,kBACF;AAAA,gBACF,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,mBAAmB;AAChD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,QAAQ,mBAAmB,MAAM,KAAK,MAAM;AAAA,kBAC5C,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,gBACjB,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,OAAO;AAAA,kBACP,kBAAkB;AAAA,gBACpB,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,QAAQ;AAAA,oBACN,MAAM;AAAA,oBACN,QAAQ,MAAM,KAAK,UAAU;AAAA,kBAC/B;AAAA,kBACA,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,QAAQ;AAAA,oBACN,SAAS,MAAM,KAAK;AAAA,oBACpB,UACE,iBAAM,KAAK,YAAX,mBAAoB,IAAI,aAAW;AAAA,sBACjC,YAAY,OAAO;AAAA,sBACnB,QAAQ,OAAO;AAAA,sBACf,UAAU,OAAO;AAAA,sBACjB,OAAO,OAAO;AAAA,sBACd,MAAM,OAAO;AAAA,oBACf,QANA,YAMO;AAAA,kBACX;AAAA,kBACA,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,QAAQ;AAAA,oBACN,SAAS,MAAM,KAAK;AAAA,kBACtB;AAAA,kBAGA,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,QAAQ;AAAA,oBACN,QAAQ,MAAM,KAAK;AAAA,kBACrB;AAAA,kBAGA,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,MAAM,KAAK;AAAA,kBACvB,UAAU;AAAA,kBACV,OAAO,KAAK,UAAU;AAAA,oBACpB,QAAQ;AAAA,sBACN,MAAM;AAAA,sBACN,SAAS,MAAM,KAAK,OAAO;AAAA,sBAC3B,WAAW,MAAM,KAAK,OAAO;AAAA,sBAC7B,MAAM,MAAM,KAAK,OAAO;AAAA,sBACxB,kBAAkB,MAAM,KAAK,OAAO;AAAA,sBACpC,KAAK,MAAM,KAAK,OAAO;AAAA,oBACzB;AAAA,kBACF,CAAwD;AAAA,kBACxD,kBAAkB;AAAA,oBAChB,QAAQ,EAAE,QAAQ,MAAM,KAAK,GAAG;AAAA,kBAClC;AAAA,gBACF,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,WAAW;AACxC,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,MAAM,KAAK;AAAA,gBACjB,CAAC;AAAA,cACH,WAAW,MAAM,KAAK,SAAS,aAAa;AAC1C,sBAAM,sBAAsB,gBAAgB,MAAM,KAAK,EAAE;AAIzD,sBAAM,qBAAqB,OAAO;AAAA,kBAChC,oBAAoB;AAAA,gBACtB,EACG;AAAA,kBACC,CAAC,CAAC,GAAG,MAAM,MACT,WAAW,YAAY,WAAW;AAAA,gBACtC,EACC,IAAI,CAAC,CAAC,YAAY,MAAM,YAAY;AAEvC,2BAAW,gBAAgB,oBAAoB;AAC7C,6BAAW,QAAQ;AAAA,oBACjB,MAAM;AAAA,oBACN,IAAI,GAAG,MAAM,KAAK,EAAE,IAAI,YAAY;AAAA,oBACpC,kBAAkB;AAAA,sBAChB,QAAQ;AAAA,wBACN,QAAQ,MAAM,KAAK;AAAA,wBACnB,4BACE,WAAM,KAAK,sBAAX,YAAgC;AAAA,sBACpC;AAAA,oBACF;AAAA,kBACF,CAAC;AAAA,gBACH;AAEA,uBAAO,gBAAgB,MAAM,KAAK,EAAE;AAAA,cACtC;AAAA,YACF,WAAW,0CAA0C,KAAK,GAAG;AAC3D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,SAAS;AAAA,kBACb,OAAO,MAAM;AAAA,gBACf,CAAC;AAAA,cACH;AAAA,YACF,WAAW,4CAA4C,KAAK,GAAG;AAC7D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,SAAS;AAAA;AAAA;AAAA,kBAGb,OAAO,KAAK,UAAU,MAAM,KAAK,EAAE,MAAM,GAAG,EAAE;AAAA,gBAChD,CAAC;AAAA,cACH;AAAA,YACF,WAAW,2CAA2C,KAAK,GAAG;AAC5D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,SAAS;AAAA,kBACb,OAAO;AAAA,gBACT,CAAC;AAED,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,SAAS;AAAA,gBACf,CAAC;AAGD,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY,SAAS;AAAA,kBACrB,UAAU;AAAA,kBACV,OAAO,KAAK,UAAU;AAAA,oBACpB,MAAM,MAAM;AAAA,oBACZ,aAAa,SAAS,gBAAiB;AAAA,kBACzC,CAEC;AAAA,kBACD,kBAAkB;AAAA,gBACpB,CAAC;AAAA,cACH;AAAA,YACF,WAAW,uBAAuB,KAAK,GAAG;AACxC,2BAAa,MAAM,SAAS;AAC5B,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,IAAI,MAAM,SAAS;AAAA,gBACnB,WAAW,IAAI,KAAK,MAAM,SAAS,aAAa,GAAI;AAAA,gBACpD,SAAS,MAAM,SAAS;AAAA,cAC1B,CAAC;AAAA,YACH,WAAW,iBAAiB,KAAK,GAAG;AAClC,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,IAAI,MAAM;AAAA,gBACV,OAAO,MAAM;AAAA,cACf,CAAC;AAED,oBAAI,mBAAQ,oBAAR,mBAAyB,WAAzB,mBAAiC,aAAY,MAAM,UAAU;AAC/D,yBAAS,KAAK,MAAM,QAAQ;AAAA,cAC9B;AAAA,YACF,WAAW,MAAM,SAAS,yCAAyC;AAEjE,kBAAI,MAAM,gBAAgB,GAAG;AAC3B,sBAAM,sBAAsB,gBAAgB,MAAM,OAAO;AAEzD,oCAAoB,aAAa,MAAM,aAAa,IAClD;AAGF,2BAAW,gBAAgB,OAAO;AAAA,kBAChC,oBAAoB;AAAA,gBACtB,GAAG;AACD,sBACE,oBAAoB,aAAa,YAAY,MAC7C,gBACA;AACA,+BAAW,QAAQ;AAAA,sBACjB,MAAM;AAAA,sBACN,IAAI,GAAG,MAAM,OAAO,IAAI,YAAY;AAAA,sBACpC,kBAAkB,EAAE,QAAQ,EAAE,QAAQ,MAAM,QAAQ,EAAE;AAAA,oBACxD,CAAC;AACD,wCAAoB,aAAa,YAAY,IAC3C;AAAA,kBACJ;AAAA,gBACF;AAEA,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;AAAA,kBAC3C,kBAAkB;AAAA,oBAChB,QAAQ;AAAA,sBACN,QAAQ,MAAM;AAAA,sBACd,4BACE,2BAAgB,MAAM,OAAO,MAA7B,mBAAgC,qBAAhC,YACA;AAAA,oBACJ;AAAA,kBACF;AAAA,gBACF,CAAC;AAAA,cACH;AAAA,YACF,WAAW,MAAM,SAAS,yCAAyC;AACjE,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;AAAA,gBAC3C,OAAO,MAAM;AAAA,gBACb,kBAAkB;AAAA,kBAChB,QAAQ;AAAA,oBACN,QAAQ,MAAM;AAAA,kBAChB;AAAA,gBACF;AAAA,cACF,CAAC;AAAA,YACH,WAAW,MAAM,SAAS,wCAAwC;AAGhE,kBAAI,OAAO;AACT,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;AAAA,kBAC3C,kBAAkB;AAAA,oBAChB,QAAQ,EAAE,QAAQ,MAAM,QAAQ;AAAA,kBAClC;AAAA,gBACF,CAAC;AAGD,gCAAgB,MAAM,OAAO,EAAG,aAC9B,MAAM,aACR,IAAI;AAAA,cACN,OAAO;AAGL,gCAAgB,MAAM,OAAO,EAAG,aAC9B,MAAM,aACR,IAAI;AAAA,cACN;AAAA,YACF,WAAW,wBAAwB,KAAK,GAAG;AACzC,6BAAe,8BAA8B;AAAA,gBAC3C,eAAc,WAAM,SAAS,uBAAf,mBAAmC;AAAA,gBACjD;AAAA,cACF,CAAC;AACD,oBAAM,cAAc,MAAM,SAAS,MAAM;AACzC,oBAAM,eAAe,MAAM,SAAS,MAAM;AAC1C,oBAAM,cACJ,MAAM,SAAS,MAAM,eACrB,MAAM,SAAS,MAAM;AACvB,oBAAM,mBACJ,iBAAM,SAAS,MAAM,0BAArB,mBAA4C,qBAA5C,YACA;AACF,oBAAM,qBACJ,iBAAM,SAAS,MAAM,yBAArB,mBAA2C,kBAA3C,YACA;AACF,kBAAI,OAAO,MAAM,SAAS,iBAAiB,UAAU;AACnD,8BAAc,MAAM,SAAS;AAAA,cAC/B;AAAA,YACF,WAAW,+BAA+B,KAAK,GAAG;AAChD,kBAAI,MAAM,WAAW,SAAS,gBAAgB;AAC5C,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY;AAAA,kBACZ,KAAI,sBAAK,QAAO,eAAZ,gDAA8B,oCAAW;AAAA,kBAC7C,KAAK,MAAM,WAAW;AAAA,kBACtB,OAAO,MAAM,WAAW;AAAA,gBAC1B,CAAC;AAAA,cACH,WAAW,MAAM,WAAW,SAAS,iBAAiB;AACpD,2BAAW,QAAQ;AAAA,kBACjB,MAAM;AAAA,kBACN,YAAY;AAAA,kBACZ,KAAI,sBAAK,QAAO,eAAZ,gDAA8B,oCAAW;AAAA,kBAC7C,WAAW;AAAA,kBACX,QACE,iBAAM,WAAW,UAAjB,YACA,MAAM,WAAW,aADjB,YAEA;AAAA,kBACF,WACE,WAAM,WAAW,aAAjB,YAA6B,MAAM,WAAW;AAAA,gBAClD,CAAC;AAAA,cACH;AAAA,YACF,WAAW,aAAa,KAAK,GAAG;AAC9B,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,CAAC;AAAA,YACpD;AAAA,UACF;AAAA,UAEA,MAAM,YAAY;AAChB,kBAAM,mBAA6C;AAAA,cACjD,QAAQ;AAAA,gBACN;AAAA,cACF;AAAA,YACF;AAEA,gBAAI,SAAS,SAAS,GAAG;AACvB,+BAAiB,OAAO,WAAW;AAAA,YACrC;AAEA,gBAAI,gBAAgB,QAAW;AAC7B,+BAAiB,OAAO,cAAc;AAAA,YACxC;AAEA,uBAAW,QAAQ;AAAA,cACjB,MAAM;AAAA,cACN;AAAA,cACA;AAAA,cACA;AAAA,YACF,CAAC;AAAA,UACH;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MACA,SAAS,EAAE,KAAK;AAAA,MAChB,UAAU,EAAE,SAAS,gBAAgB;AAAA,IACvC;AAAA,EACF;AACF;AAEA,SAAS,iBACP,OACwE;AACxE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,8BACP,OACuE;AACvE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,wBACP,OAGA;AACA,SACE,MAAM,SAAS,wBAAwB,MAAM,SAAS;AAE1D;AAEA,SAAS,uBACP,OAC8D;AAC9D,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,0CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,4CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,2CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,+BACP,OACwE;AACxE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,+BACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,aACP,OACmD;AACnD,SAAO,MAAM,SAAS;AACxB;AASA,SAAS,wBAAwB,SAAuC;AACtE,QAAMC,0BACJ,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS,KAC3B,QAAQ,WAAW,OAAO,KAAK,CAAC,QAAQ,WAAW,YAAY;AAClE,QAAMC,8BACJ,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,YAAY,KAC9B,QAAQ,WAAW,OAAO,KACzB,CAAC,QAAQ,WAAW,YAAY,KAChC,CAAC,QAAQ,WAAW,YAAY,KAClC,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS;AAC9B,QAAM,WAAW;AAAA,IACf,mBAAmB;AAAA,IACnB,wBAAAD;AAAA,IACA,4BAAAC;AAAA,EACF;AAGA,MAAI,QAAQ,WAAW,YAAY,GAAG;AACpC,WAAO;AAAA,MACL,GAAG;AAAA,MACH,kBAAkB;AAAA,IACpB;AAAA,EACF;AAGA,MACE,QAAQ,WAAW,GAAG,KACtB,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,QAAQ,KAC3B,QAAQ,WAAW,cAAc,GACjC;AACA,QAAI,QAAQ,WAAW,SAAS,KAAK,QAAQ,WAAW,YAAY,GAAG;AACrE,aAAO;AAAA,QACL,GAAG;AAAA,QACH,kBAAkB;AAAA,QAClB,mBAAmB;AAAA,MACrB;AAAA,IACF;AAEA,WAAO;AAAA,MACL,GAAG;AAAA,MACH,kBAAkB;AAAA,MAClB,mBAAmB;AAAA,IACrB;AAAA,EACF;AAGA,SAAO;AAAA,IACL,GAAG;AAAA,IACH,kBAAkB;AAAA,EACpB;AACF;AAEA,SAAS,mBACP,QAC8C;AAr1ChD;AAs1CE,UAAQ,OAAO,MAAM;AAAA,IACnB,KAAK;AACH,aAAO,EAAE,QAAQ,EAAE,MAAM,UAAU,QAAO,YAAO,UAAP,YAAgB,OAAU,EAAE;AAAA,IACxE,KAAK;AACH,aAAO,EAAE,QAAQ,EAAE,MAAM,YAAY,KAAK,OAAO,IAAI,EAAE;AAAA,IACzD,KAAK;AACH,aAAO;AAAA,QACL,QAAQ,EAAE,MAAM,QAAQ,KAAK,OAAO,KAAK,SAAS,OAAO,QAAQ;AAAA,MACnE;AAAA,EACJ;AACF;;;AM/1CA,IAAAC,0BAKO;;;ACNP,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AASX,IAAM,wCAAoC;AAAA,EAAc,UAC7D;AAAA,IACE,cAAE,OAAO;AAAA,MACP,cAAc,cAAE,OAAO,EAAE,QAAQ;AAAA,MACjC,OAAO,cAAE,OAAO,EAAE,IAAI,IAAI,EAAE,IAAI,CAAG,EAAE,QAAQ,CAAG,EAAE,QAAQ;AAAA,IAC5D,CAAC;AAAA,EACH;AACF;;;ADAO,IAAM,oBAAN,MAAiD;AAAA,EAOtD,YACW,SACQ,QACjB;AAFS;AACQ;AARnB,SAAS,uBAAuB;AAAA,EAS7B;AAAA,EAPH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAOA,MAAc,QAAQ;AAAA,IACpB;AAAA,IACA,QAAQ;AAAA,IACR,eAAe;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAA+C;AAC7C,UAAM,WAAuC,CAAC;AAG9C,UAAM,gBAAgB,UAAM,8CAAqB;AAAA,MAC/C,UAAU;AAAA,MACV;AAAA,MACA,QAAQ;AAAA,IACV,CAAC;AAGD,UAAM,cAAuC;AAAA,MAC3C,OAAO,KAAK;AAAA,MACZ,OAAO;AAAA,MACP;AAAA,MACA,iBAAiB;AAAA,MACjB;AAAA,MACA;AAAA,IACF;AAEA,QAAI,cAAc;AAChB,UAAI,CAAC,OAAO,QAAQ,OAAO,QAAQ,OAAO,KAAK,EAAE,SAAS,YAAY,GAAG;AACvE,oBAAY,kBAAkB;AAAA,MAChC,OAAO;AACL,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,UACT,SAAS,8BAA8B,YAAY;AAAA,QACrD,CAAC;AAAA,MACH;AAAA,IACF;AAGA,QAAI,eAAe;AACjB,YAAM,qBAA2C,CAAC;AAElD,iBAAW,OAAO,oBAAoB;AACpC,cAAM,QAAQ,mBAAmB,GAAiC;AAClE,YAAI,UAAU,QAAW;AACvB,sBAAY,GAAG,IAAI;AAAA,QACrB;AAAA,MACF;AAAA,IACF;AAEA,QAAI,UAAU;AACZ,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SAAS,+EAA+E,QAAQ;AAAA,MAClG,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,WACJ,SAC2D;AArG/D;AAsGI,UAAM,eAAc,sBAAK,OAAO,cAAZ,mBAAuB,gBAAvB,4CAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,aAAa,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE5D,UAAM;AAAA,MACJ,OAAO;AAAA,MACP;AAAA,MACA,UAAU;AAAA,IACZ,IAAI,UAAM,uCAAc;AAAA,MACtB,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,wCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D,MAAM;AAAA,MACN,uBAAuB;AAAA,MACvB,+BAA2B,qDAA4B;AAAA,MACvD,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA,SAAS;AAAA,QACP,MAAM,KAAK,UAAU,WAAW;AAAA,MAClC;AAAA,MACA,UAAU;AAAA,QACR,WAAW;AAAA,QACX,SAAS,KAAK;AAAA,QACd,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,IACF;AAAA,EACF;AACF;;;AEnIA,IAAAC,0BAOO;;;ACZP,IAAAC,0BAAyC;AACzC,IAAAC,cAAkB;AAEX,IAAM,wCAAoC;AAAA,EAAc,UAC7D;AAAA,IACE,cAAE,OAAO;AAAA,MACP,MAAM,cAAE,OAAO;AAAA,MACf,UAAU,cAAE,OAAO,EAAE,QAAQ;AAAA,MAC7B,UAAU,cAAE,OAAO,EAAE,QAAQ;AAAA,MAC7B,OAAO,cACJ;AAAA,QACC,cAAE,OAAO;AAAA,UACP,MAAM,cAAE,OAAO;AAAA,UACf,OAAO,cAAE,OAAO;AAAA,UAChB,KAAK,cAAE,OAAO;AAAA,QAChB,CAAC;AAAA,MACH,EACC,QAAQ;AAAA,MACX,UAAU,cACP;AAAA,QACC,cAAE,OAAO;AAAA,UACP,IAAI,cAAE,OAAO;AAAA,UACb,MAAM,cAAE,OAAO;AAAA,UACf,OAAO,cAAE,OAAO;AAAA,UAChB,KAAK,cAAE,OAAO;AAAA,UACd,MAAM,cAAE,OAAO;AAAA,UACf,QAAQ,cAAE,MAAM,cAAE,OAAO,CAAC;AAAA,UAC1B,aAAa,cAAE,OAAO;AAAA,UACtB,aAAa,cAAE,OAAO;AAAA,UACtB,mBAAmB,cAAE,OAAO;AAAA,UAC5B,gBAAgB,cAAE,OAAO;AAAA,QAC3B,CAAC;AAAA,MACH,EACC,QAAQ;AAAA,IACb,CAAC;AAAA,EACH;AACF;;;ACpCA,IAAAC,0BAIO;AACP,IAAAC,cAAkB;AASX,IAAM,yCAAqC;AAAA,EAAc,UAC9D;AAAA,IACE,cAAE,OAAO;AAAA;AAAA;AAAA;AAAA,MAKP,SAAS,cAAE,MAAM,cAAE,OAAO,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAKtC,UAAU,cAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA,MAK9B,QAAQ,cAAE,OAAO,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAM5B,aAAa,cAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,QAAQ,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,MAM1D,wBAAwB,cACrB,MAAM,cAAE,KAAK,CAAC,QAAQ,SAAS,CAAC,CAAC,EACjC,QAAQ,CAAC,SAAS,CAAC,EACnB,SAAS;AAAA,IACd,CAAC;AAAA,EACH;AACF;;;AFXA,IAAM,cAAc;AAAA,EAClB,WAAW;AAAA,EACX,QAAQ;AAAA,EACR,UAAU;AAAA,EACV,aAAa;AAAA,EACb,YAAY;AAAA,EACZ,SAAS;AAAA,EACT,WAAW;AAAA,EACX,SAAS;AAAA,EACT,SAAS;AAAA,EACT,UAAU;AAAA,EACV,OAAO;AAAA,EACP,QAAQ;AAAA,EACR,OAAO;AAAA,EACP,SAAS;AAAA,EACT,UAAU;AAAA,EACV,SAAS;AAAA,EACT,QAAQ;AAAA,EACR,UAAU;AAAA,EACV,QAAQ;AAAA,EACR,OAAO;AAAA,EACP,QAAQ;AAAA,EACR,OAAO;AAAA,EACP,WAAW;AAAA,EACX,WAAW;AAAA,EACX,YAAY;AAAA,EACZ,SAAS;AAAA,EACT,UAAU;AAAA,EACV,SAAS;AAAA,EACT,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,SAAS;AAAA,EACT,YAAY;AAAA,EACZ,YAAY;AAAA,EACZ,OAAO;AAAA,EACP,SAAS;AAAA,EACT,OAAO;AAAA,EACP,QAAQ;AAAA,EACR,WAAW;AAAA,EACX,SAAS;AAAA,EACT,QAAQ;AAAA,EACR,YAAY;AAAA,EACZ,UAAU;AAAA,EACV,SAAS;AAAA,EACT,SAAS;AAAA,EACT,QAAQ;AAAA,EACR,WAAW;AAAA,EACX,SAAS;AAAA,EACT,SAAS;AAAA,EACT,SAAS;AAAA,EACT,SAAS;AAAA,EACT,OAAO;AAAA,EACP,MAAM;AAAA,EACN,SAAS;AAAA,EACT,WAAW;AAAA,EACX,MAAM;AAAA,EACN,YAAY;AAAA,EACZ,OAAO;AACT;AAEO,IAAM,2BAAN,MAA+D;AAAA,EAOpE,YACW,SACQ,QACjB;AAFS;AACQ;AARnB,SAAS,uBAAuB;AAAA,EAS7B;AAAA,EAPH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAOA,MAAc,QAAQ;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAAmC;AACjC,UAAM,WAA8C,CAAC;AAGrD,UAAM,gBAAgB,UAAM,8CAAqB;AAAA,MAC/C,UAAU;AAAA,MACV;AAAA,MACA,QAAQ;AAAA,IACV,CAAC;AAGD,UAAM,WAAW,IAAI,SAAS;AAC9B,UAAM,OACJ,iBAAiB,aACb,IAAI,KAAK,CAAC,KAAK,CAAC,IAChB,IAAI,KAAK,KAAC,mDAA0B,KAAK,CAAC,CAAC;AAEjD,aAAS,OAAO,SAAS,KAAK,OAAO;AACrC,UAAM,oBAAgB,8CAAqB,SAAS;AACpD,aAAS;AAAA,MACP;AAAA,MACA,IAAI,KAAK,CAAC,IAAI,GAAG,SAAS,EAAE,MAAM,UAAU,CAAC;AAAA,MAC7C,SAAS,aAAa;AAAA,IACxB;AAGA,QAAI,eAAe;AACjB,YAAM,4BAA4B;AAAA,QAChC,SAAS,cAAc;AAAA,QACvB,UAAU,cAAc;AAAA,QACxB,QAAQ,cAAc;AAAA;AAAA;AAAA,QAGtB,iBAAiB;AAAA,UACf;AAAA,UACA;AAAA,QACF,EAAE,SAAS,KAAK,OAAO,IACnB,SACA;AAAA,QACJ,aAAa,cAAc;AAAA,QAC3B,yBAAyB,cAAc;AAAA,MACzC;AAEA,iBAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,yBAAyB,GAAG;AACpE,YAAI,SAAS,MAAM;AACjB,cAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,uBAAW,QAAQ,OAAO;AACxB,uBAAS,OAAO,GAAG,GAAG,MAAM,OAAO,IAAI,CAAC;AAAA,YAC1C;AAAA,UACF,OAAO;AACL,qBAAS,OAAO,KAAK,OAAO,KAAK,CAAC;AAAA,UACpC;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,WACJ,SACkE;AAlLtE;AAmLI,UAAM,eAAc,sBAAK,OAAO,cAAZ,mBAAuB,gBAAvB,4CAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,UAAU,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAEzD,UAAM;AAAA,MACJ,OAAO;AAAA,MACP;AAAA,MACA,UAAU;AAAA,IACZ,IAAI,UAAM,2CAAkB;AAAA,MAC1B,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,aAAS,wCAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,+BAA2B;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,WACJ,SAAS,YAAY,QAAQ,SAAS,YAAY,cAC9C,YAAY,SAAS,QAAoC,IACzD;AAEN,WAAO;AAAA,MACL,MAAM,SAAS;AAAA,MACf,WACE,0BAAS,aAAT,mBAAmB,IAAI,cAAY;AAAA,QACjC,MAAM,QAAQ;AAAA,QACd,aAAa,QAAQ;AAAA,QACrB,WAAW,QAAQ;AAAA,MACrB,QAJA,aAKA,cAAS,UAAT,mBAAgB,IAAI,WAAS;AAAA,QAC3B,MAAM,KAAK;AAAA,QACX,aAAa,KAAK;AAAA,QAClB,WAAW,KAAK;AAAA,MAClB,QATA,YAUA,CAAC;AAAA,MACH;AAAA,MACA,oBAAmB,cAAS,aAAT,YAAqB;AAAA,MACxC;AAAA,MACA,UAAU;AAAA,QACR,WAAW;AAAA,QACX,SAAS,KAAK;AAAA,QACd,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,IACF;AAAA,EACF;AACF;;;AGrOO,IAAM,UACX,OACI,WACA;;;AvCoIC,SAAS,aACd,UAAkC,CAAC,GACnB;AA3IlB;AA4IE,QAAM,WACJ;AAAA,QACE,6CAAoB;AAAA,MAClB,cAAc,QAAQ;AAAA,MACtB,yBAAyB;AAAA,IAC3B,CAAC;AAAA,EACH,MALA,YAKK;AAEP,QAAM,gBAAe,aAAQ,SAAR,YAAgB;AAErC,QAAM,aAAa,UACjB;AAAA,IACE;AAAA,MACE,eAAe,cAAU,oCAAW;AAAA,QAClC,QAAQ,QAAQ;AAAA,QAChB,yBAAyB;AAAA,QACzB,aAAa;AAAA,MACf,CAAC,CAAC;AAAA,MACF,uBAAuB,QAAQ;AAAA,MAC/B,kBAAkB,QAAQ;AAAA,MAC1B,GAAG,QAAQ;AAAA,IACb;AAAA,IACA,iBAAiB,OAAO;AAAA,EAC1B;AAEF,QAAM,kBAAkB,CAAC,YACvB,IAAI,wBAAwB,SAAS;AAAA,IACnC,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,wBAAwB,CAAC,YAC7B,IAAI,8BAA8B,SAAS;AAAA,IACzC,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,uBAAuB,CAAC,YAC5B,IAAI,qBAAqB,SAAS;AAAA,IAChC,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,mBAAmB,CAAC,YACxB,IAAI,iBAAiB,SAAS;AAAA,IAC5B,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,2BAA2B,CAAC,YAChC,IAAI,yBAAyB,SAAS;AAAA,IACpC,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,oBAAoB,CAAC,YACzB,IAAI,kBAAkB,SAAS;AAAA,IAC7B,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,sBAAsB,CAAC,YAAoC;AAC/D,QAAI,YAAY;AACd,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,qBAAqB,OAAO;AAAA,EACrC;AAEA,QAAM,uBAAuB,CAAC,YAAoC;AAChE,WAAO,IAAI,6BAA6B,SAAS;AAAA,MAC/C,UAAU,GAAG,YAAY;AAAA,MACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,MACpC,SAAS;AAAA,MACT,OAAO,QAAQ;AAAA,MACf,gBAAgB,CAAC,OAAO;AAAA,IAC1B,CAAC;AAAA,EACH;AAEA,QAAM,WAAW,SAAU,SAAiC;AAC1D,WAAO,oBAAoB,OAAO;AAAA,EACpC;AAEA,WAAS,gBAAgB;AACzB,WAAS,OAAO;AAChB,WAAS,aAAa;AACtB,WAAS,YAAY;AACrB,WAAS,YAAY;AACrB,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAE9B,WAAS,QAAQ;AACjB,WAAS,aAAa;AAEtB,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAE9B,WAAS,SAAS;AAClB,WAAS,cAAc;AAEvB,WAAS,QAAQ;AAEjB,SAAO;AACT;AAKO,IAAM,SAAS,aAAa;","names":["import_provider_utils","import_provider","import_provider_utils","import_provider_utils","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider","openaiTools","openaiTools","toolCall","import_provider_utils","import_provider","getResponseMetadata","mapOpenAIFinishReason","import_v4","import_provider_utils","import_provider_utils","import_v4","mapOpenAIFinishReason","getResponseMetadata","import_provider","import_provider_utils","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider_utils","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider","import_provider_utils","import_provider","import_provider_utils","import_v4","_a","_b","_c","import_provider_utils","import_v4","import_provider_utils","import_v4","import_provider","import_provider_utils","openaiTools","openaiTools","supportsFlexProcessing","supportsPriorityProcessing","import_provider_utils","import_provider_utils","import_v4","import_provider_utils","import_provider_utils","import_v4","import_provider_utils","import_v4"]}